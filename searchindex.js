Search.setIndex({"alltitles": {"01 - General Instructions": [[20, null]], "01 - INTRODUCTION": [[15, null]], "02 - NEURAL NETWORKS": [[16, null]], "03 - TENSORFLOW CORE": [[17, null]], "04 - CONVOLUTIONAL NETWORKS": [[18, null]], "05 - SEQUENCE MODELS": [[19, null]], "1)": [[69, "id1"]], "1. El gradiente": [[24, "el-gradiente"]], "1. Elegimos la forma del modelo": [[24, "elegimos-la-forma-del-modelo"]], "1. Introduction": [[33, "introduction"]], "1. Repository layout": [[20, "repository-layout"]], "1.1 - DL Overview": [[22, null]], "1.2 - Models derived from data": [[23, null]], "1.3 - ML algorithm design": [[24, null]], "2)": [[69, "id2"]], "2. Assembling and training an autoencoder": [[33, "assembling-and-training-an-autoencoder"]], "2. Definimos una medida de error": [[24, "definimos-una-medida-de-error"]], "2. LABS and autograders": [[20, "labs-and-autograders"]], "2. inspecting data in latent space (the encoder)": [[33, "inspecting-data-in-latent-space-the-encoder"]], "2. la optimizaci\u00f3n como proceso iterativo": [[24, "la-optimizacion-como-proceso-iterativo"]], "2.1 - The Perceptron": [[29, null]], "2.2 - The Multilayer Perceptron": [[30, null]], "2.3 - Overfitting and regularization": [[31, null]], "2.4 - Loss functions in Tensorflow": [[32, null]], "2.5 - Autoencoders": [[33, null]], "2.6 - Multimodal architectures": [[34, null]], "2.7 - Vanishing gradients": [[35, null]], "2.8 - Weights initialization": [[36, null]], "3) Convolutional LSTM": [[69, "convolutional-lstm"]], "3. Custom loss, unsupervised .fit(X) call \\rightarrow MSE": [[33, "custom-loss-unsupervised-fit-x-call-rightarrow-mse"]], "3. Obtenemos los par\u00e1metros que minimizan el error de predicci\u00f3n": [[24, "obtenemos-los-parametros-que-minimizan-el-error-de-prediccion"]], "3. Publishing": [[20, "publishing"]], "3.1 - Symbolic computing for ML": [[39, null]], "3.2 - TF symbolic engine": [[40, null]], "3.3 - Using tf.function": [[41, null]], "3.4 - Batch normalization": [[42, null]], "4. Autoencoder for image denoising": [[33, "autoencoder-for-image-denoising"]], "4. General remarks for LABS and graders": [[20, "general-remarks-for-labs-and-graders"]], "4.1 - Convolutions": [[47, null]], "4.2 - Convolutional Neural Networks": [[48, null]], "4.3 - Dropout, pooling": [[49, null]], "4.4 - CNN Architectures": [[50, null]], "4.5 - Transfer learning": [[51, null]], "4.6 - Object detection": [[52, null]], "4.7 - Transposed convolutions": [[53, null]], "4.8 - UNet Image segmentation": [[54, null]], "4.9 - Atrous convolutions": [[55, null]], "5. To create the publishable student version of a LAB notebook": [[20, "to-create-the-publishable-student-version-of-a-lab-notebook"]], "5.0 Crossvalidation in time series": [[60, null]], "5.1 Recurrent Neural Networks": [[61, null]], "5.2 LSTM and GRU": [[62, null]], "5.3 Truncated BPTT": [[63, null]], "5.4 Text processing": [[64, null]], "5.5 Sequences generation": [[65, null]], "5.6 Bidirectional RNNs": [[66, null]], "5.7 ELMo": [[67, null]], "5.8 Transformer": [[68, null]], "5.9  CNN-LSTM architectures": [[69, null]], "<span style=\"color:blue\">This is a neural network!</span>": [[29, "this-is-a-neural-network"]], "A RNN network with multiple outputs": [[61, "a-rnn-network-with-multiple-outputs"]], "A basic multi layered dense model": [[28, "a-basic-multi-layered-dense-model"], [35, "a-basic-multi-layered-dense-model"]], "A regular neural network for classification": [[34, "a-regular-neural-network-for-classification"]], "A sample dataset": [[32, "a-sample-dataset"]], "Abriendo la caja negra de la optimizaci\u00f3n": [[24, "abriendo-la-caja-negra-de-la-optimizacion"]], "Accessing model layers": [[33, "accessing-model-layers"]], "Accessing model weights": [[33, "accessing-model-weights"]], "Alternative activation functions": [[64, "alternative-activation-functions"]], "And how we sorted it out for linear regression using a generic optimization library": [[39, "and-how-we-sorted-it-out-for-linear-regression-using-a-generic-optimization-library"]], "And on test data": [[54, "and-on-test-data"]], "Approaches:": [[52, "approaches"]], "Architectures:": [[53, "architectures"]], "Arquitecturas CNN-LSTM": [[19, "arquitecturas-cnn-lstm"]], "Arquitecturas de redes convolucionales": [[18, "arquitecturas-de-redes-convolucionales"]], "Arquitecturas multimodales": [[16, "arquitecturas-multimodales"]], "Arquitecturas recurrentes": [[19, "arquitecturas-recurrentes"]], "Artificial Neural Networks": [[29, "artificial-neural-networks"]], "Autoencoders": [[16, "autoencoders"]], "BERT": [[68, "bert"]], "BUT, Is it possible that the LSTM may find dependencies between the sequences?": [[63, "but-is-it-possible-that-the-lstm-may-find-dependencies-between-the-sequences"]], "Backpropagation algorithm": [[29, "backpropagation-algorithm"]], "Backpropagation through time (BPTT)": [[61, "backpropagation-through-time-bptt"]], "Bag of words": [[64, "bag-of-words"]], "Batch normalization": [[17, "batch-normalization"]], "Batch, Minibatch and online learning": [[29, "batch-minibatch-and-online-learning"]], "Bidirectional RNN": [[66, "bidirectional-rnn"]], "Build and train our neural network": [[54, "build-and-train-our-neural-network"]], "Calendario y fechas": [[1, "calendario-y-fechas"], [2, "calendario-y-fechas"], [3, "calendario-y-fechas"], [4, "calendario-y-fechas"], [5, "calendario-y-fechas"], [6, "calendario-y-fechas"], [7, "calendario-y-fechas"], [8, "calendario-y-fechas"], [9, "calendario-y-fechas"], [10, "calendario-y-fechas"], [11, "calendario-y-fechas"], [12, "calendario-y-fechas"], [13, "calendario-y-fechas"], [14, "calendario-y-fechas"]], "Classical activation functions": [[29, "classical-activation-functions"]], "Classical time series analysis tools": [[60, "classical-time-series-analysis-tools"]], "Classifying Fashion-MNIST": [[30, "classifying-fashion-mnist"]], "Complejidad de los modelos vs. complejidad de los datos": [[23, "complejidad-de-los-modelos-vs-complejidad-de-los-datos"]], "Contacto": [[1, "contacto"], [2, "contacto"], [3, "contacto"], [4, "contacto"], [5, "contacto"], [6, "contacto"], [7, "contacto"], [8, "contacto"], [9, "contacto"], [10, "contacto"], [11, "contacto"], [12, "contacto"], [13, "contacto"], [14, "contacto"]], "Context": [[56, "context"]], "Context:": [[59, "context"]], "Convolution is just multiplication and adding": [[47, "convolution-is-just-multiplication-and-adding"]], "Convolution matrix": [[53, "convolution-matrix"]], "Convolution with images": [[47, "convolution-with-images"]], "Convolutional Neural Networks": [[48, "id1"]], "Convolutions of functions": [[47, "convolutions-of-functions"]], "Could also freeze weights to avoid being changed by training": [[51, "could-also-freeze-weights-to-avoid-being-changed-by-training"]], "Covariate shift": [[42, "covariate-shift"]], "Covariate shift during training": [[42, "covariate-shift-during-training"]], "Create a tf.data dataset": [[66, "create-a-tf-data-dataset"]], "Custom feeding data and extracting intermediate activations": [[33, "custom-feeding-data-and-extracting-intermediate-activations"]], "C\u00f3mo se dise\u00f1a un algoritmo ML": [[24, "como-se-disena-un-algoritmo-ml"]], "C\u00f3mputo simb\u00f3lico con Tensorflow": [[17, "computo-simbolico-con-tensorflow"]], "DL is suited for large datasets with highly dimensional input variables": [[22, "dl-is-suited-for-large-datasets-with-highly-dimensional-input-variables"]], "Dedicaci\u00f3n de tiempo sugerida": [[1, "dedicacion-de-tiempo-sugerida"]], "Deep Learning e Inteligencia Artificial": [[15, "deep-learning-e-inteligencia-artificial"]], "Define the network architecture using keras": [[30, "define-the-network-architecture-using-keras"]], "Depending on the task, it may be necessary to eliminate some words such as prepositions": [[64, "depending-on-the-task-it-may-be-necessary-to-eliminate-some-words-such-as-prepositions"]], "Detecci\u00f3n de objetos": [[18, "deteccion-de-objetos"]], "Discussion about GPU performance for Recurrent Networks": [[63, "discussion-about-gpu-performance-for-recurrent-networks"]], "Document representations": [[64, "document-representations"]], "Done!!": [[37, "done"]], "Download the model": [[67, "download-the-model"]], "Downsampling and upsampling": [[53, "downsampling-and-upsampling"]], "Drawbacks of the classical approaches": [[29, "drawbacks-of-the-classical-approaches"]], "Dropout": [[49, "dropout"]], "ELMo: Embeddings from Language Models": [[67, "elmo-embeddings-from-language-models"]], "Early stopping": [[31, "early-stopping"]], "Effects of different initializations": [[36, "effects-of-different-initializations"]], "Ejemplo": [[24, "ejemplo"]], "El modelo Transformer": [[19, "el-modelo-transformer"]], "Encoder-Decoder architecture (sequence-to-sequence)": [[61, "encoder-decoder-architecture-sequence-to-sequence"]], "Encoder-decoder": [[66, "encoder-decoder"]], "Entrega 1": [[1, "entrega-1"], [2, "entrega-1"], [3, "entrega-1"], [4, "entrega-1"], [6, "entrega-1"], [7, "entrega-1"], [8, "entrega-1"], [9, "entrega-1"], [10, "entrega-1"], [11, "entrega-1"], [12, "entrega-1"], [13, "entrega-1"], [14, "entrega-1"]], "Entrega 2": [[1, "entrega-2"], [2, "entrega-2"], [3, "entrega-2"], [4, "entrega-2"], [6, "entrega-2"], [7, "entrega-2"], [8, "entrega-2"], [9, "entrega-2"], [10, "entrega-2"], [11, "entrega-2"], [12, "entrega-2"], [13, "entrega-2"], [14, "entrega-2"]], "Entregas": [[8, "entregas"], [9, "entregas"], [9, "id1"], [10, "entregas"], [11, "entregas"], [12, "entregas"], [13, "entregas"], [14, "entregas"]], "Estructura del repositorio github": [[12, "estructura-del-repositorio-github"], [13, "estructura-del-repositorio-github"], [14, "estructura-del-repositorio-github"]], "Evaluaciones": [[1, "evaluaciones"], [2, "evaluaciones"], [3, "evaluaciones"], [4, "evaluaciones"], [6, "evaluaciones"], [7, "evaluaciones"], [8, "evaluaciones"], [9, "evaluaciones"], [10, "evaluaciones"], [11, "evaluaciones"], [12, "evaluaciones"], [13, "evaluaciones"], [14, "evaluaciones"]], "Evaluaci\u00f3n": [[1, "evaluacion"], [2, "evaluacion"], [3, "evaluacion"], [4, "evaluacion"], [5, "evaluacion"]], "Evaluaci\u00f3n del proyecto": [[6, "evaluacion-del-proyecto"], [7, "evaluacion-del-proyecto"], [8, "evaluacion-del-proyecto"], [9, "evaluacion-del-proyecto"], [10, "evaluacion-del-proyecto"], [11, "evaluacion-del-proyecto"], [12, "evaluacion-del-proyecto"], [13, "evaluacion-del-proyecto"], [14, "evaluacion-del-proyecto"]], "Example": [[63, "example"]], "Example using a toy dataset:": [[29, "example-using-a-toy-dataset"]], "Example:": [[58, "example"]], "Example: Sentiment analysis using a transformer block": [[68, "example-sentiment-analysis-using-a-transformer-block"]], "Excercise 1: Complete the model arquitecture": [[67, "excercise-1-complete-the-model-arquitecture"]], "Experiment observations, on Tensorboard": [[35, "experiment-observations-on-tensorboard"]], "Explore COCO Dataset": [[48, "explore-coco-dataset"]], "Feature learning": [[22, "feature-learning"]], "Fechas l\u00edmite para entregas": [[1, "fechas-limite-para-entregas"], [2, "fechas-limite-para-entregas"], [3, "fechas-limite-para-entregas"], [4, "fechas-limite-para-entregas"], [6, "fechas-limite-para-entregas"], [7, "fechas-limite-para-entregas"], [8, "fechas-limite-para-entregas"], [9, "fechas-limite-para-entregas"], [10, "fechas-limite-para-entregas"], [11, "fechas-limite-para-entregas"], [12, "fechas-limite-para-entregas"], [13, "fechas-limite-para-entregas"], [14, "fechas-limite-para-entregas"]], "Fechas oficiales facultad de ingenier\u00eda": [[7, "fechas-oficiales-facultad-de-ingenieria"], [12, "fechas-oficiales-facultad-de-ingenieria"], [13, "fechas-oficiales-facultad-de-ingenieria"], [14, "fechas-oficiales-facultad-de-ingenieria"]], "Fechas oficiales facutlad de ingenier\u00eda": [[2, "fechas-oficiales-facutlad-de-ingenieria"], [3, "fechas-oficiales-facutlad-de-ingenieria"], [4, "fechas-oficiales-facutlad-de-ingenieria"], [6, "fechas-oficiales-facutlad-de-ingenieria"], [8, "fechas-oficiales-facutlad-de-ingenieria"], [9, "fechas-oficiales-facutlad-de-ingenieria"], [10, "fechas-oficiales-facutlad-de-ingenieria"], [11, "fechas-oficiales-facutlad-de-ingenieria"]], "First level filters and activations maps": [[48, "first-level-filters-and-activations-maps"]], "Functional models": [[30, "functional-models"]], "Fundamentos de Deep Learning": [[0, null]], "Gated Recurrent Units": [[62, "gated-recurrent-units"]], "Get the data": [[54, "get-the-data"]], "Grupo de Whatsapp": [[6, "grupo-de-whatsapp"], [7, "grupo-de-whatsapp"], [8, "grupo-de-whatsapp"], [9, "grupo-de-whatsapp"], [10, "grupo-de-whatsapp"], [11, "grupo-de-whatsapp"], [12, "grupo-de-whatsapp"], [13, "grupo-de-whatsapp"], [14, "grupo-de-whatsapp"]], "Hierarchy of filters and activation maps": [[48, "hierarchy-of-filters-and-activation-maps"]], "How to split data for validation purposes?": [[60, "how-to-split-data-for-validation-purposes"]], "Hyperbolic tangent": [[29, "hyperbolic-tangent"]], "Image Segmentation": [[54, "image-segmentation"]], "Image analytics tasks": [[48, "image-analytics-tasks"]], "Implementing linear regresion in TF": [[40, "implementing-linear-regresion-in-tf"]], "In Tensorflow in just the same": [[47, "in-tensorflow-in-just-the-same"]], "Info 20212 - UdeA - Pregrado": [[2, null]], "Info 2022.1 - UdeA - Posgrado": [[3, null]], "Info 2022.2 - UdeA - Posgrado": [[4, null]], "Info 2023.1 - UdeA - Especializaci\u00f3n": [[5, null]], "Info 2023.1 - UdeA - Posgrado": [[6, null]], "Info 2023.1 - UdeA - Pregrado": [[7, null]], "Info 2023.2 - UdeA - Posgrado": [[8, null]], "Info 2023.2 - UdeA - Pregrado": [[9, null]], "Info 2024.1 - UdeA - Posgrado": [[10, null]], "Info 2024.1 - UdeA - Pregrado": [[11, null]], "Info 2024.2 - UdeA": [[12, null]], "Info 2025.1 - UdeA": [[13, null]], "Info 2025.2 - UdeA": [[14, null]], "Informaci\u00f3n 20211 - UdeA": [[1, null]], "Inicializaci\u00f3n de pesos": [[16, "inicializacion-de-pesos"]], "Intro": [[54, "intro"]], "Introducci\u00f3n": [[18, "introduccion"], [19, "introduccion"]], "Intuition": [[55, "intuition"]], "Keras Embedding": [[64, "keras-embedding"]], "LAB 01.01 - WARM UP": [[21, null]], "LAB 2.1 - Customized loss function": [[25, null]], "LAB 2.2 - Sparse Autoencoders": [[26, null]], "LAB 2.3 - Pairwise classification": [[27, null]], "LAB 2.4 - Model instrumentation": [[28, null]], "LAB 3.1 - TF model subclassing": [[37, null]], "LAB 3.2 - Low level tensorflow": [[38, null]], "LAB 4.1 - Convolutions": [[43, null]], "LAB 4.2 - Transfer learning": [[44, null]], "LAB 4.3 - Object detection": [[45, null]], "LAB 4.4 - Semantic segmentation": [[46, null]], "LAB 5.1 - Time series prediction": [[56, null]], "LAB 5.2 - Padding - Masking": [[57, null]], "LAB 5.3 - Transformer - BERT": [[58, null]], "LAB 5.4 - Video Classification": [[59, null]], "LAB SUMMARY": [[26, "lab-summary"], [27, "lab-summary"], [28, "lab-summary"]], "LABORATORIO": [[15, "laboratorio"], [19, "laboratorio"]], "LABORATORIO 1": [[16, "laboratorio-1"], [18, "laboratorio-1"], [19, "laboratorio-1"]], "LABORATORIO 2": [[16, "laboratorio-2"], [18, "laboratorio-2"], [19, "laboratorio-2"]], "LABORATORIO 3": [[16, "laboratorio-3"], [18, "laboratorio-3"], [19, "laboratorio-3"]], "LABORATORIO 4": [[16, "laboratorio-4"], [18, "laboratorio-4"]], "LABORATORIOS": [[17, "laboratorios"]], "Leaky RELU activation": [[35, "leaky-relu-activation"]], "Leaky ReLU (Rectified Linear Unit)": [[35, "leaky-relu-rectified-linear-unit"]], "Lest\u2019s compare the result with a simple Embedding layer instead of ELMo": [[67, "lest-s-compare-the-result-with-a-simple-embedding-layer-instead-of-elmo"]], "Lets do some examples of Time series using conventional MLPs": [[61, "lets-do-some-examples-of-time-series-using-conventional-mlps"]], "Lets make more complex architectures": [[61, "lets-make-more-complex-architectures"]], "Let\u2019s build a word2vec model using tf": [[64, "let-s-build-a-word2vec-model-using-tf"]], "Let\u2019s define formaly the Recurrent Neural Networks": [[61, "let-s-define-formaly-the-recurrent-neural-networks"]], "Let\u2019s get the data": [[59, "let-s-get-the-data"]], "Let\u2019s see how the encoder models perform for a 2 times ahead prediction:": [[56, "let-s-see-how-the-encoder-models-perform-for-a-2-times-ahead-prediction"]], "Let\u2019s see how the models perform for a 2 times ahead prediction:": [[56, "let-s-see-how-the-models-perform-for-a-2-times-ahead-prediction"]], "Let\u2019s see how the real and predicted time series look like:": [[56, "let-s-see-how-the-real-and-predicted-time-series-look-like"]], "Let\u2019s see how to define a simplified ELMo version from scratch:": [[67, "let-s-see-how-to-define-a-simplified-elmo-version-from-scratch"]], "Let\u2019s test the model:": [[57, "let-s-test-the-model"], [57, "id1"], [57, "id2"], [58, "let-s-test-the-model"], [59, "let-s-test-the-model"]], "Let\u2019s train a regular LSTM network": [[63, "let-s-train-a-regular-lstm-network"]], "Let\u2019s train the models:": [[56, "let-s-train-the-models"], [56, "id1"], [56, "id2"]], "Let\u2019s try a more complex network": [[48, "let-s-try-a-more-complex-network"]], "Linear regression with Tensorflow Functional API": [[32, "linear-regression-with-tensorflow-functional-api"]], "Linear regression with Tensorflow Sequential API": [[32, "linear-regression-with-tensorflow-sequential-api"]], "Loading the Fashion MNIST database\u2026": [[25, "loading-the-fashion-mnist-database"]], "Logistic": [[29, "logistic"]], "Los algoritmos de machine learning:": [[23, "los-algoritmos-de-machine-learning"]], "Loss function": [[52, "loss-function"]], "Loss function and perceptron training": [[29, "loss-function-and-perceptron-training"]], "Machine Learning": [[15, "machine-learning"]], "Machine learning como dise\u00f1ador de algoritmos": [[15, "machine-learning-como-disenador-de-algoritmos"]], "Machine learning como usuario de modelos": [[15, "machine-learning-como-usuario-de-modelos"]], "Make predictions": [[54, "make-predictions"]], "Making predictions": [[33, "making-predictions"]], "Metrics in a real context": [[66, "metrics-in-a-real-context"]], "Multi-layer perceptron (MLP)": [[29, "multi-layer-perceptron-mlp"]], "Multidimensionalidad (>2D)": [[23, "multidimensionalidad-2d"]], "Multimodal network": [[34, "multimodal-network"]], "Name Entity Recognition (NER)": [[67, "name-entity-recognition-ner"]], "Neural Machine Translation": [[66, "neural-machine-translation"]], "Neural machine translation with attention": [[66, "neural-machine-translation-with-attention"]], "Non maximum suppression": [[52, "non-maximum-suppression"]], "Now let\u2019s thing about the following problem:": [[29, "now-let-s-thing-about-the-following-problem"]], "Now using a RNN layer instead of a Dense layer:": [[61, "now-using-a-rnn-layer-instead-of-a-dense-layer"]], "Object detection": [[52, "id1"]], "Observe AlexNet filters for the first two convolutional layers": [[51, "observe-alexnet-filters-for-the-first-two-convolutional-layers"]], "Observe how an image is annotated for detection": [[52, "observe-how-an-image-is-annotated-for-detection"]], "One single perceptron is not able to solve the problem!": [[29, "one-single-perceptron-is-not-able-to-solve-the-problem"]], "One stage detectors": [[52, "one-stage-detectors"]], "Optional": [[66, "optional"]], "Otra forma de modelo": [[24, "otra-forma-de-modelo"]], "Overfitting": [[31, "overfitting"]], "Patch classification, with InceptionV3 from Keras": [[52, "patch-classification-with-inceptionv3-from-keras"]], "Patch classification, with ResNet model published on TensorFlow Hub": [[52, "patch-classification-with-resnet-model-published-on-tensorflow-hub"]], "Pooling": [[49, "pooling"]], "Predicting several times ahead": [[61, "predicting-several-times-ahead"]], "Predictions": [[52, "predictions"]], "Procesamiento de texto": [[19, "procesamiento-de-texto"]], "Proyecto": [[1, "proyecto"], [2, "proyecto"], [3, "proyecto"], [4, "proyecto"], [6, "proyecto"], [7, "proyecto"], [8, "proyecto"], [9, "proyecto"], [10, "proyecto"], [11, "proyecto"], [12, "proyecto"], [13, "proyecto"], [14, "proyecto"]], "RECOMMENDATION": [[48, "recommendation"]], "REGISTRO": [[12, "registro"], [13, "registro"], [14, "registro"]], "RELU activation": [[35, "relu-activation"]], "ReLU (Rectified Linear Unit)": [[35, "relu-rectified-linear-unit"]], "Recall the machine learning algorithm design process": [[39, "recall-the-machine-learning-algorithm-design-process"]], "Redes Neuronales Recurrentes": [[19, "redes-neuronales-recurrentes"]], "Redes Neuronales Recurrentes Bidirecionales": [[19, "redes-neuronales-recurrentes-bidirecionales"]], "Redes convolucionales": [[18, "redes-convolucionales"]], "Redes de neuronas artificiales": [[16, "redes-de-neuronas-artificiales"]], "References": [[60, "references"]], "Referencias": [[1, "referencias"], [2, "referencias"], [3, "referencias"], [4, "referencias"], [5, "referencias"], [6, "referencias"], [7, "referencias"], [8, "referencias"], [9, "referencias"], [10, "referencias"], [11, "referencias"], [12, "referencias"], [13, "referencias"], [14, "referencias"]], "Region priors": [[52, "region-priors"]], "Regularization": [[31, "regularization"]], "SIGMOID activation": [[35, "sigmoid-activation"]], "SIGMOID activation but longer run (epochs)": [[35, "sigmoid-activation-but-longer-run-epochs"]], "STATEFUL Model": [[63, "stateful-model"]], "Sampling": [[65, "sampling"]], "Segmentaci\u00f3n sem\u00e1ntica": [[18, "segmentacion-semantica"]], "Self-attention": [[68, "self-attention"]], "Sequential models": [[30, "sequential-models"]], "Sesiones sincr\u00f3nicas": [[1, "sesiones-sincronicas"], [2, "sesiones-sincronicas"], [3, "sesiones-sincronicas"], [4, "sesiones-sincronicas"], [6, "sesiones-sincronicas"], [7, "sesiones-sincronicas"], [8, "sesiones-sincronicas"], [9, "sesiones-sincronicas"], [10, "sesiones-sincronicas"], [11, "sesiones-sincronicas"], [12, "sesiones-sincronicas"], [13, "sesiones-sincronicas"], [14, "sesiones-sincronicas"]], "Set up a model with Keras and train": [[42, "set-up-a-model-with-keras-and-train"]], "Simple RNN network": [[66, "simple-rnn-network"]], "Softmax": [[29, "softmax"]], "Solo tenemos un dataset": [[23, "solo-tenemos-un-dataset"]], "Some general references on segmentation": [[54, "some-general-references-on-segmentation"]], "Some types of Neural Networks": [[22, "some-types-of-neural-networks"]], "Stemming": [[64, "stemming"]], "Sympy to Python and Numpy": [[39, "sympy-to-python-and-numpy"]], "TASK 01: Handcrafted sparse autoencoder": [[26, "task-01-handcrafted-sparse-autoencoder"]], "TASK 02: Sparse autoencoder model": [[26, "task-02-sparse-autoencoder-model"]], "TASK 1.": [[56, "task-1"]], "TASK 1. Basic model": [[25, "task-1-basic-model"]], "TASK 1: Create anchor boxes": [[45, "task-1-create-anchor-boxes"]], "TASK 1: Implement convolutions": [[43, "task-1-implement-convolutions"]], "TASK 1: Model build": [[37, "task-1-model-build"]], "TASK 1: Multi-input model": [[27, "task-1-multi-input-model"]], "TASK 1: Naive CNN for segmentation": [[46, "task-1-naive-cnn-for-segmentation"]], "TASK 1: Obtain layer output": [[38, "task-1-obtain-layer-output"]], "TASK 1: Weights monitoring callback": [[28, "task-1-weights-monitoring-callback"]], "TASK 1: tensorflow hub classification model": [[44, "task-1-tensorflow-hub-classification-model"]], "TASK 2: Activations monitoring callback": [[28, "task-2-activations-monitoring-callback"]], "TASK 2: Get closest anchor": [[45, "task-2-get-closest-anchor"]], "TASK 2: Implement batch normalization": [[38, "task-2-implement-batch-normalization"]], "TASK 2: L_2 regularization": [[25, "task-2-l-2-regularization"]], "TASK 2: Measure per-class accuracy": [[27, "task-2-measure-per-class-accuracy"]], "TASK 2: Naive CNN for segmentation with skipped connections": [[46, "task-2-naive-cnn-for-segmentation-with-skipped-connections"]], "TASK 2: Prepare image for one-shot convolution": [[43, "task-2-prepare-image-for-one-shot-convolution"]], "TASK 2: tensorflow hub feature extraction model": [[44, "task-2-tensorflow-hub-feature-extraction-model"]], "TASK 3: Compute desired model bounding box predictions": [[45, "task-3-compute-desired-model-bounding-box-predictions"]], "TASK 3: Compute number of weights": [[43, "task-3-compute-number-of-weights"]], "TASK 3: Compute the Hessian": [[38, "task-3-compute-the-hessian"]], "TASK 3: L_1+L_2 regularization": [[25, "task-3-l-1-l-2-regularization"]], "TASK 3: Model for fine tuning": [[44, "task-3-model-for-fine-tuning"]], "TASK 3: UNET no skipped connections": [[46, "task-3-unet-no-skipped-connections"]], "TASK 4: Customized loss function": [[25, "task-4-customized-loss-function"]], "TF is a symbolic computing + optimization library for machine learning problems": [[40, "tf-is-a-symbolic-computing-optimization-library-for-machine-learning-problems"]], "Task 1": [[57, "task-1"]], "Task 1.": [[59, "task-1"]], "Task 1:": [[58, "task-1"]], "Task 1: An operation with matrices": [[21, "task-1-an-operation-with-matrices"]], "Task 2": [[57, "task-2"]], "Task 2.": [[56, "task-2"]], "Task 2:": [[58, "task-2"]], "Task 2: Function argmax": [[21, "task-2-function-argmax"]], "Task 2: Model call": [[37, "task-2-model-call"]], "Task 3": [[56, "task-3"], [57, "task-3"]], "Task 3: Loss function": [[37, "task-3-loss-function"]], "Task 4": [[56, "task-4"], [57, "task-4"]], "Taxonom\u00eda de problemas de machine learning": [[23, "taxonomia-de-problemas-de-machine-learning"]], "Tensorflow Dev Summit": [[40, "tensorflow-dev-summit"]], "Tensorflow Hub": [[50, "tensorflow-hub"]], "Tensors": [[40, "tensors"]], "The  <b><tt>content</tt></b> folder": [[20, "the-content-folder"]], "The Vanishing Gradient": [[16, "the-vanishing-gradient"]], "The aim of this lab is to build a system for sentiment analysis on a dataset of tweets.": [[57, "the-aim-of-this-lab-is-to-build-a-system-for-sentiment-analysis-on-a-dataset-of-tweets"]], "The curse of dimensionality": [[31, "the-curse-of-dimensionality"]], "The perceptron": [[29, "id1"]], "The result is not what we expected mainly because of three resons:": [[65, "the-result-is-not-what-we-expected-mainly-because-of-three-resons"]], "There are Three ways to define the network:": [[69, "there-are-three-ways-to-define-the-network"]], "There are other two widely used representations based on Matrix factorization:": [[64, "there-are-other-two-widely-used-representations-based-on-matrix-factorization"]], "Time series": [[60, "time-series"]], "Tipolog\u00eda de algoritmos": [[24, "tipologia-de-algoritmos"]], "Tipos de tareas de machine learning": [[24, "tipos-de-tareas-de-machine-learning"]], "Tokenization": [[64, "tokenization"]], "Tokenize": [[66, "tokenize"]], "Trabajando con los materiales del curso": [[1, "trabajando-con-los-materiales-del-curso"], [2, "trabajando-con-los-materiales-del-curso"], [3, "trabajando-con-los-materiales-del-curso"], [4, "trabajando-con-los-materiales-del-curso"], [6, "trabajando-con-los-materiales-del-curso"], [7, "trabajando-con-los-materiales-del-curso"], [8, "trabajando-con-los-materiales-del-curso"], [9, "trabajando-con-los-materiales-del-curso"], [10, "trabajando-con-los-materiales-del-curso"], [11, "trabajando-con-los-materiales-del-curso"], [12, "trabajando-con-los-materiales-del-curso"], [13, "trabajando-con-los-materiales-del-curso"], [14, "trabajando-con-los-materiales-del-curso"], [70, "trabajando-con-los-materiales-del-curso"]], "Train from scratch": [[51, "train-from-scratch"]], "Transfer learning!": [[64, "transfer-learning"]], "Transfer learning!!!": [[51, "id1"]], "Transposed convolutions": [[53, "id1"]], "Two recurrent layers:": [[61, "two-recurrent-layers"]], "Types of convolutions": [[53, "types-of-convolutions"]], "U5.02 - Long Short Term Memory RNN": [[62, "u5-02-long-short-term-memory-rnn"]], "Underlying concrete functions are actual TF graphs with no polymorphism, tied to specific input types": [[41, "underlying-concrete-functions-are-actual-tf-graphs-with-no-polymorphism-tied-to-specific-input-types"]], "Use GPU runtime!!!": [[54, "use-gpu-runtime"]], "Using a more complex model with the whole dataset": [[65, "using-a-more-complex-model-with-the-whole-dataset"]], "Using multiple times as features": [[61, "using-multiple-times-as-features"]], "Using multiple times as multiple times!": [[61, "using-multiple-times-as-multiple-times"]], "Using sympy computer algebra system (CAS)": [[39, "using-sympy-computer-algebra-system-cas"]], "Using sympy to obtain the gradient.": [[39, "using-sympy-to-obtain-the-gradient"]], "Using the original sequences:": [[63, "using-the-original-sequences"]], "Using the splitted sequences:": [[63, "using-the-splitted-sequences"]], "Using three steps backward to predict one step ahead:": [[61, "using-three-steps-backward-to-predict-one-step-ahead"]], "Using word2vec": [[66, "using-word2vec"]], "Version 1: raw low level with gradient descent": [[40, "version-1-raw-low-level-with-gradient-descent"]], "Version 2: using tf.function to speed up": [[40, "version-2-using-tf-function-to-speed-up"]], "Version 3: using batches with random shuffling (stochastic gradient descent)": [[40, "version-3-using-batches-with-random-shuffling-stochastic-gradient-descent"]], "Version 4: packing up with Keras class API  and custom SGD": [[40, "version-4-packing-up-with-keras-class-api-and-custom-sgd"]], "Version 5: Sequential Keras model with standard loop": [[40, "version-5-sequential-keras-model-with-standard-loop"]], "Version 6: Custom model with Keras class API  and standard loop": [[40, "version-6-custom-model-with-keras-class-api-and-standard-loop"]], "Version 7: Using train_step \\rightarrow control loss and gradients on a custom model.": [[40, "version-7-using-train-step-rightarrow-control-loss-and-gradients-on-a-custom-model"]], "Version 8: Using train_step \\rightarrow control loss and gradients on a standard model.": [[40, "version-8-using-train-step-rightarrow-control-loss-and-gradients-on-a-standard-model"]], "Visualizing and understanding vanishing gradients": [[35, "visualizing-and-understanding-vanishing-gradients"]], "Walk forward using a RNN": [[61, "walk-forward-using-a-rnn"]], "We will use them as starting point for training our network": [[51, "we-will-use-them-as-starting-point-for-training-our-network"]], "Welcome": [[70, null]], "What happened?": [[63, "what-happened"]], "What you must do": [[20, "what-you-must-do"]], "What you must know": [[20, "what-you-must-know"]], "Why DL now?": [[22, "why-dl-now"]], "Word embeddings": [[64, "word-embeddings"]], "and we are still using black box optimization!!!!": [[39, "and-we-are-still-using-black-box-optimization"]], "create the model": [[34, "create-the-model"]], "c\u00e1lculo anal\u00edtico de los errores de clasificaci\u00f3n": [[23, "calculo-analitico-de-los-errores-de-clasificacion"]], "encoder activations": [[33, "encoder-activations"]], "fit and display losses": [[34, "fit-and-display-losses"]], "follow the explanation here": [[36, "follow-the-explanation-here"]], "in a more real scenario we only have noisy data to train the model": [[33, "in-a-more-real-scenario-we-only-have-noisy-data-to-train-the-model"]], "including graphs in upstream functions.": [[41, "including-graphs-in-upstream-functions"]], "initializing with a large \\sigma": [[36, "initializing-with-a-large-sigma"]], "initializing with a small \\sigma": [[36, "initializing-with-a-small-sigma"]], "initializing with a small \\sigma but with large values for input data": [[36, "initializing-with-a-small-sigma-but-with-large-values-for-input-data"]], "initializing with a standard normal (\\mu=0 and \\sigma=1)": [[36, "initializing-with-a-standard-normal-mu-0-and-sigma-1"]], "load data and train a simple model": [[36, "load-data-and-train-a-simple-model"]], "load sample MNIST data as customary": [[28, "load-sample-mnist-data-as-customary"], [35, "load-sample-mnist-data-as-customary"]], "measure accuracies": [[34, "measure-accuracies"]], "observa c\u00f3mo un clasificador lineal aproxima la frontera con diferentes tama\u00f1os de muestras": [[23, "observa-como-un-clasificador-lineal-aproxima-la-frontera-con-diferentes-tamanos-de-muestras"]], "observe distribution of activations at the encoder": [[33, "observe-distribution-of-activations-at-the-encoder"]], "or with larger filters": [[48, "or-with-larger-filters"]], "performance of tf.function": [[41, "performance-of-tf-function"]], "performance on selected validation data": [[54, "performance-on-selected-validation-data"]], "sigmoid": [[35, "sigmoid"]], "tanh": [[35, "tanh"]], "test the reconstruction": [[26, "test-the-reconstruction"]], "tf-idf representation": [[64, "tf-idf-representation"]], "tf.function automatically converts pythonic code to a computational graph, using Tensors": [[41, "tf-function-automatically-converts-pythonic-code-to-a-computational-graph-using-tensors"]], "tf.function with keras layers": [[41, "tf-function-with-keras-layers"]], "word2vec": [[64, "word2vec"]], "you may skip this step by downloading directly the pretrained weights": [[54, "you-may-skip-this-step-by-downloading-directly-the-pretrained-weights"]], "\u00bfQu\u00e9 es Machine Learning (ML)?": [[23, "que-es-machine-learning-ml"]], "\u00bfQu\u00e9 es el c\u00f3mputo simb\u00f3lico?": [[17, "que-es-el-computo-simbolico"]], "\u00bfQu\u00e9 es un modelo derivado de los datos?": [[23, "que-es-un-modelo-derivado-de-los-datos"]]}, "docnames": ["README", "content/M00_20211", "content/M00_20212_pre", "content/M00_20221_pos", "content/M00_20222_pos", "content/M00_20231_esp", "content/M00_20231_pos", "content/M00_20231_pre", "content/M00_20232_pos", "content/M00_20232_pre", "content/M00_20241_pos", "content/M00_20241_pre", "content/M00_20242_prepos", "content/M00_20251_pre", "content/M00_20252_pre", "content/M01", "content/M02", "content/M03", "content/M04", "content/M05", "content/NOTES 01.01 - GENERAL INSTRUCTIONS", "content/U1 LAB 01 - WARMUP", "content/U1.01 - DL Overview", "content/U1.02 - Modelos derivados de los datos", "content/U1.03 - Como se disena un algoritmo de Machine Learning", "content/U2 LAB 01 - Customized loss functions and regularization", "content/U2 LAB 02 - Autoencoders", "content/U2 LAB 03 - Pairwise image classification", "content/U2 LAB 04 - Model instrumentation and monitoring", "content/U2.01 - The Perceptron", "content/U2.02 - The Multilayer Perceptron", "content/U2.03 - Overfitting and regularization", "content/U2.04 - Loss functions", "content/U2.05 - Network Architectures - Autoencoders", "content/U2.06 - Network Architectures - Multimodal information", "content/U2.07 - Vanishing gradients", "content/U2.08 - Weights initialization", "content/U3 LAB 01 - Tensorflow model subclassing", "content/U3 LAB 02 - Low level Tensorflow", "content/U3.01 - Simbolic computing for ML", "content/U3.02 - TF for symbolic computing", "content/U3.03 - Using tf.function", "content/U3.04 - Batch Normalization", "content/U4 LAB 01 - Convolutions", "content/U4 LAB 02 - Transfer Learning", "content/U4 LAB 03 - Object Detection", "content/U4 LAB 04 - Semantic segmentation", "content/U4.01 - Convolutions", "content/U4.02 - Convolutional Neural Networks", "content/U4.03 - Dropout, pooling", "content/U4.04 - CNN Architectures", "content/U4.05 - Transfer learning", "content/U4.06 - Object Detection", "content/U4.07 - Transposed convolutions", "content/U4.08 - UNet image segmentation", "content/U4.09 - Atrous convolutions", "content/U5 LAB 01 - Multivariate time series prediction", "content/U5 LAB 02 - Padding, Masking - Sentiment Analysis", "content/U5 LAB 03 - Sentiment Analysis using BERT", "content/U5 LAB 04 - Video Classification", "content/U5.00 - Intro time series", "content/U5.01 - Recurrent Neural Networks", "content/U5.02 - Long Short Term Memory RNN", "content/U5.03 - Truncated BPTT", "content/U5.04 - Basic concepts of text processing", "content/U5.05 - Sequences generation using LSTM", "content/U5.06 - Bidirectional RNNs - Attention Model", "content/U5.07 - ELMo - NER", "content/U5.08 - Self-Attention - Transformer - BERT", "content/U5.09 - CNN-LSTM architectures", "intro"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["README.md", "content/M00_20211.md", "content/M00_20212_pre.md", "content/M00_20221_pos.md", "content/M00_20222_pos.md", "content/M00_20231_esp.md", "content/M00_20231_pos.md", "content/M00_20231_pre.md", "content/M00_20232_pos.md", "content/M00_20232_pre.md", "content/M00_20241_pos.md", "content/M00_20241_pre.md", "content/M00_20242_prepos.md", "content/M00_20251_pre.md", "content/M00_20252_pre.md", "content/M01.md", "content/M02.md", "content/M03.md", "content/M04.md", "content/M05.md", "content/NOTES 01.01 - GENERAL INSTRUCTIONS.ipynb", "content/U1 LAB 01 - WARMUP.ipynb", "content/U1.01 - DL Overview.ipynb", "content/U1.02 - Modelos derivados de los datos.ipynb", "content/U1.03 - Como se disena un algoritmo de Machine Learning.ipynb", "content/U2 LAB 01 - Customized loss functions and regularization.ipynb", "content/U2 LAB 02 - Autoencoders.ipynb", "content/U2 LAB 03 - Pairwise image classification.ipynb", "content/U2 LAB 04 - Model instrumentation and monitoring.ipynb", "content/U2.01 - The Perceptron.ipynb", "content/U2.02 - The Multilayer Perceptron.ipynb", "content/U2.03 - Overfitting and regularization.ipynb", "content/U2.04 - Loss functions.ipynb", "content/U2.05 - Network Architectures - Autoencoders.ipynb", "content/U2.06 - Network Architectures - Multimodal information.ipynb", "content/U2.07 - Vanishing gradients.ipynb", "content/U2.08 - Weights initialization.ipynb", "content/U3 LAB 01 - Tensorflow model subclassing.ipynb", "content/U3 LAB 02 - Low level Tensorflow.ipynb", "content/U3.01 - Simbolic computing for ML.ipynb", "content/U3.02 - TF for symbolic computing.ipynb", "content/U3.03 - Using tf.function.ipynb", "content/U3.04 - Batch Normalization.ipynb", "content/U4 LAB 01 - Convolutions.ipynb", "content/U4 LAB 02 - Transfer Learning.ipynb", "content/U4 LAB 03 - Object Detection.ipynb", "content/U4 LAB 04 - Semantic segmentation.ipynb", "content/U4.01 - Convolutions.ipynb", "content/U4.02 - Convolutional Neural Networks.ipynb", "content/U4.03 - Dropout, pooling.ipynb", "content/U4.04 - CNN Architectures.ipynb", "content/U4.05 - Transfer learning.ipynb", "content/U4.06 - Object Detection.ipynb", "content/U4.07 - Transposed convolutions.ipynb", "content/U4.08 - UNet image segmentation.ipynb", "content/U4.09 - Atrous convolutions.ipynb", "content/U5 LAB 01 - Multivariate time series prediction.ipynb", "content/U5 LAB 02 - Padding, Masking - Sentiment Analysis.ipynb", "content/U5 LAB 03 - Sentiment Analysis using BERT.ipynb", "content/U5 LAB 04 - Video Classification.ipynb", "content/U5.00 - Intro time series.ipynb", "content/U5.01 - Recurrent Neural Networks.ipynb", "content/U5.02 - Long Short Term Memory RNN.ipynb", "content/U5.03 - Truncated BPTT.ipynb", "content/U5.04 - Basic concepts of text processing.ipynb", "content/U5.05 - Sequences generation using LSTM.ipynb", "content/U5.06 - Bidirectional RNNs - Attention Model.ipynb", "content/U5.07 - ELMo - NER.ipynb", "content/U5.08 - Self-Attention - Transformer - BERT.ipynb", "content/U5.09 - CNN-LSTM architectures.ipynb", "intro.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 24, 25, 28, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 49, 50, 51, 52, 53, 54, 62, 65, 66, 68, 69], "0": [5, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "00": [23, 27, 30, 33, 34, 36, 40, 42, 44, 48, 49, 50, 51, 53, 54, 56, 57, 62, 64, 66, 67, 69], "000": [34, 50, 67], "0000": [63, 69], "000000": 52, "00000000": 54, "0000001": 52, "0001": [57, 58], "0002": 35, "00037578": 53, "0003bb040a62c86f": 52, "0004": 35, "0009": 35, "001": [23, 25, 29, 44, 62, 66, 68], "0010": [34, 62], "0010000000474974513": 51, "0011": [34, 62], "00111854": 53, "0012": [34, 62, 63, 65], "0013": [34, 62], "0014": [34, 62], "0015": [34, 62], "00151799": 44, "0016": [34, 62], "0017": [34, 62], "00177": 44, "0018": [34, 62], "00188202": 31, "0019": [34, 62], "0019352": 44, "0020": [34, 62], "0021": [34, 62], "00216343": 44, "00219825": 44, "0022": [34, 62], "0023": 62, "0023157": 44, "00232": 44, "0024": [34, 62], "0025": [34, 35, 62], "00259226": 31, "0026": [34, 62], "00263431": 44, "00264549": 47, "002645502645502562": 47, "00264993": 44, "0027": [34, 62], "0028": [34, 62], "00286247": 44, "00286377": 31, "0029": 62, "00293583": 53, "00299914": 44, "0030": [34, 62], "00306441": 31, "00308137": 44, "0031": [35, 62], "003199": 33, "0032": 62, "00320563": 44, "0033": [34, 62], "00333721": 44, "0034": 34, "0035": [34, 62], "00354484": 53, "0036": 62, "0037": [62, 65], "0038": [34, 62], "0039": 62, "0040": [35, 62], "00405932": 53, "0041": 34, "0042": 33, "00421986": 31, "0043": [33, 34, 62], "0044": [33, 34], "0045": [33, 34], "0046": [33, 62], "0047": 33, "00476574e": 33, "00476938e": 33, "0048": [33, 34, 62], "0049": [33, 69], "005": [37, 42], "0050": 33, "0051": [33, 34], "0052": 33, "005241": 40, "0053": [33, 34], "0054": 33, "005403": 52, "0055": [33, 62], "0056": 33, "0057": 33, "0058": 33, "0059": 33, "0060": [33, 34], "0061": [33, 34], "0062": 33, "0063": 34, "00630359": 53, "0064": [33, 34, 62], "0065": 33, "0066": [33, 34, 62], "0067": [33, 53], "0068": [34, 35, 53], "0069": [33, 34], "0070": [33, 34], "0071": [33, 53], "00716837": 64, "0072": [33, 34], "0073": 33, "0074": [33, 34], "0075": [33, 34], "0076": 33, "007624": 32, "0077": [33, 53], "0078": [33, 34], "00784516": 50, "0079": 33, "008": 64, "0080": [33, 53], "0081": 33, "0082": [33, 34], "0083": [33, 34], "0084": [33, 34, 53], "0085": [33, 34, 35], "0086": 33, "0087": 33, "0088": 34, "0089": 33, "0090": [33, 34, 36], "0091": 33, "0092": [33, 34, 53], "0093": [33, 34], "0094": [33, 34, 35], "0095": 33, "00957584": 64, "0096": 33, "0097": 53, "0098": [33, 34], "0099": [34, 53], "01": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 23, 25, 29, 30, 32, 37, 40, 42, 43, 56, 60, 61, 62, 64, 70], "010": 69, "0101": 33, "01020408": 25, "0103": [33, 34], "0104": [33, 34], "010421": 53, "0105": 33, "0106": 33, "0107": [33, 34, 35, 69], "010810": 52, "0109": 33, "0110": [33, 34], "01107952": 31, "0112": 69, "0113": [33, 34], "0114": 53, "0115": 33, "0116": [33, 34], "0117": 33, "0118": [33, 34], "0119": 34, "011k07": 52, "011q46kg": 52, "0120": 33, "012074": 52, "0120dh": 52, "0121": 35, "01226z": 52, "0123": 35, "0125": [33, 35], "0125475": 33, "0126": 33, "0127": 53, "0128": 33, "0129": [33, 34], "01294528": 53, "0131": 33, "0132": [33, 35], "01345906": 53, "0135": 33, "0136": 33, "0137": 33, "013824365101754665": 63, "01385765": 40, "0139": 33, "0141": 34, "0142": [33, 34], "0143": [34, 35, 53], "014368715": 50, "014368754": 50, "0144": 33, "0145": [33, 35], "0147": 34, "0148": 33, "0149": 34, "0152": 33, "015431100502610207": 63, "01549073": 31, "0156": [33, 34], "0159": 33, "01590205": 64, "01590626": 31, "016": [48, 49], "0160": [33, 34], "0161382": 53, "016192": 52, "0163": 33, "0164": [34, 53, 65], "0165": 33, "016528": 52, "0166": 34, "0169": 33, "016952": 52, "0172": 34, "0173": 35, "017347801476716995": 63, "0174": 33, "017429": 52, "0175": [33, 69], "0176": 34, "01763293": 26, "01764613": 31, "0179": [33, 35], "0183": 34, "0184": 34, "0185": [33, 34, 63], "0187": 35, "0189": 33, "0190": 33, "0191": 34, "0193": 35, "0195": 33, "0197": [33, 51, 53], "0199": 34, "01990842": 31, "019974345341324806": 63, "01_to_2018": [60, 61, 62], "01g317": 52, "01mqdt": 52, "01prl": 52, "02": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 33, 38, 40, 44, 45, 54, 56, 57, 70], "020": [48, 51], "0200": 33, "0207": [33, 34], "0209": [33, 35], "021174": 52, "021387": 52, "0215": 33, "02158": 44, "0216": [34, 36, 44], "0217": 35, "02194051": 51, "0220": [33, 35], "0222": 33, "0224": 33, "02248449": 64, "0226": [34, 35], "02270105": 64, "02285376": 64, "023273712024092674": 63, "02332435": 31, "0235": 34, "02371303": 64, "0238": [33, 53, 69], "0240": 34, "0241": 35, "02411834": 40, "0242": 34, "0246": 33, "02503325": 64, "0251": 63, "0253": 33, "02541249": 38, "0255": [33, 34, 66], "02588999": 61, "02593034": 31, "0260": 35, "026169779": 44, "02624173": 40, "0264": 33, "0265": 34, "02655962": 31, "0266": 66, "0267": [33, 34], "02717": 32, "0276": 36, "0277": 33, "0278": 35, "0280": 65, "0281": 63, "02832924574613571": 63, "0285": 33, "0289": 65, "0290082": 33, "0291": 34, "0292887": 51, "0293": 34, "0295": 34, "0296": [33, 35, 69], "0298": [33, 53], "0298858": 64, "02d_hidden": [28, 35, 36], "02d_input": [28, 35, 36], "02d_output": [28, 35, 36], "03": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 27, 45, 48, 49, 51, 52, 56, 58, 62], "030096276": 44, "0302": 35, "0305": 35, "0306": [34, 66], "03063363": 61, "0308": 66, "0309": 33, "0312": 66, "031471": 52, "0316": 36, "0320": [33, 69], "0321": 34, "0330": 35, "0331": 35, "03328232": 50, "0333": 33, "0339": 66, "033921164": 50, "03392129": 50, "0343": 35, "0345": 34, "0346": 66, "035": 40, "0350": [33, 35, 65], "0351": 33, "03524965": 61, "03531878814101219": 63, "0354": 66, "0355": 34, "0357": [35, 66], "0357714": 53, "035877": 52, "0359": 66, "0360": 66, "0361": 34, "03612632": 45, "036139373": 44, "0364": 33, "0368": 53, "0369": 34, "0371": 65, "03776747": 61, "03780845": 32, "03807591": 31, "03807782": 64, "0384": 33, "0386": 66, "038643": 33, "03873321": 31, "039": 69, "0390": 33, "0390263": 33, "03906215": 31, "0391": 69, "03944606": 61, "03949338": 31, "0396": 66, "039948": 52, "04": [15, 17, 19, 28, 33, 34, 46, 54, 56, 59, 62, 63], "040": [46, 54], "0400": 34, "040118206": 50, "04028529": 61, "0403": 66, "04070497": 61, "0409": 33, "0410": 66, "0415": 34, "04170844": 31, "0417094": 33, "04179534": 64, "04196388": 61, "0421": [34, 66], "0422": 69, "04230769": 51, "0424": 66, "0425": 66, "04253836": 64, "04261405": 64, "04280317": 61, "042827234": 50, "04284886": 44, "0429": 33, "043": 44, "0430": 65, "0431": 33, "043169715": 50, "0432": 63, "043379": 33, "0434": [66, 69], "0436424": 61, "0438": 66, "0440": 36, "044055": 33, "0444": 33, "04445121": 31, "0445": 33, "04452837": 31, "0446": 33, "04464164": 31, "0447": [33, 66], "0448": 33, "044866074": 50, "04490137": 61, "045": 46, "0450": [33, 65], "0451": 66, "0452": 33, "0453": 33, "04530746": 61, "0454": 33, "04547248": 31, "0455": 33, "0456": 33, "04574066": 61, "0458": 66, "0459": 33, "046": 66, "0460": 33, "0461": 33, "04616028": 61, "0462": 33, "0463": 53, "04639038": 50, "0464": [33, 34], "0465": 33, "0465799": 61, "0466": 33, "046685826": 50, "0467": 33, "0468": [33, 36], "04687948": 31, "0469": 33, "04699951": 61, "0470": 33, "04706873": 39, "0471": 66, "0472": 33, "0473": [33, 66], "0475": [33, 34], "0476": 33, "0477": [34, 66], "04783881": 61, "0479": 33, "0480": 33, "0481": [33, 66], "0482": [33, 34], "04825848": 61, "0483": 33, "0484": 33, "0485": 66, "04854369": 61, "0486": [35, 66], "0486781": 61, "0487": 33, "048978641629219055": 63, "04909778": 61, "0491": [33, 69], "04911455": 50, "04911469": 50, "04916687": 41, "0493": [33, 66], "0495": 66, "04951739": 61, "0496": 33, "04993707": 61, "05": [3, 10, 15, 17, 18, 20, 23, 26, 29, 33, 45, 57, 61, 62, 63, 69], "0500": 33, "05019305": 48, "05020921": 51, "05025544": 45, "0503": 33, "05068012": 31, "0507": [33, 63], "0507763": 61, "0511": 33, "05119592": 61, "0512": [33, 66], "0514": [33, 34, 66], "05147406": 31, "0515": 35, "0517": 33, "0520": [33, 34], "05203521": 61, "0523": 33, "0525": 33, "0527": 65, "0528": 33, "05287451": 61, "0531": 66, "05329418": 61, "0533": 33, "0537": 33, "0538": 33, "05413342": 61, "0544": [33, 66], "05442021141063": 20, "0545": 66, "05455303": 61, "054701": 52, "05501619": 61, "0552": 33, "0553": 33, "0555": [34, 66], "0557": 65, "05594416": 38, "0562": 33, "05623162": 61, "0564": 66, "05665129": 61, "0569": [33, 66], "0572": 33, "0576": 35, "0577": 67, "05773516274534907": 23, "0579": 67, "05791014": 61, "0582": 66, "0584": 33, "0587": 33, "05874944": 61, "05882353": 25, "05885772": 38, "0590": 66, "0590334": 33, "05916911": 61, "0593": 65, "0595": 33, "05958873": 61, "059597": 33, "0597": [36, 66, 69], "0599": 66, "06": [15, 17, 18, 19, 24, 33, 39, 62], "0600": 66, "06042802": 61, "0605": 33, "0607": 66, "0609": 35, "0611": [62, 66], "06126726": 61, "0613": 33, "06153846": 51, "06168693": 61, "06169621": 31, "0618": 33, "0620": 66, "0621": 67, "06210655": 61, "0627": [33, 34, 35], "0627093": 33, "06294584": 61, "0633": 35, "06349206": 51, "063523": 52, "0635482": 41, "06378514": 61, "0639": 33, "064": 54, "0640": 66, "0642": 67, "06420469": 61, "0644": [33, 66], "0645": 67, "0646": 34, "0648": [33, 34], "0649": 33, "06546366": 61, "0658": [33, 66], "06588334": 61, "066": 64, "0663": 66, "06630296": 61, "06644621": 50, "06672263": 61, "0669": 35, "06694561": 51, "0674": [33, 34], "0676": [35, 66], "0678": 48, "0679": 66, "0680": 66, "0681": 65, "0683": 33, "06832974": 31, "068628": 33, "0687": 66, "06882077": 61, "0690": 35, "0692": 66, "0694": 66, "0696": 66, "06966007": 61, "07": [15, 17, 18, 19, 24, 33, 39, 41, 42, 51, 54, 58], "0701": 35, "07091904": 61, "0710": [65, 69], "0711": 33, "071250": 52, "0713": 67, "07133859": 61, "07136850e": 33, "07153446": 50, "071947": 33, "0720": [33, 34, 67], "07217789": 61, "0727": 66, "0728": [33, 66], "0730303": 31, "07307052612304688": 63, "0733": 35, "0734": 33, "0742": 66, "0746": 34, "07469571": 61, "0747": 33, "075535": 61, "07595462": 61, "0760": 36, "0761": 35, "07612074421712434": 32, "0763": 33, "07637429": 61, "0766": 36, "07679397": 61, "07714226": 23, "0772": 66, "07721359": 61, "0780": 33, "07805282": 61, "078125": 52, "07820677": 40, "07832256": 21, "0785": 69, "0787": 66, "07889211": 61, "0796": 34, "0797314": 61, "0799": 34, "07j7r": 52, "08": [15, 17, 18, 19, 24, 33, 40, 54, 58, 62], "080": [30, 50, 54, 69], "0800": 34, "0801": 66, "0802": 66, "0804": 65, "0805": 54, "0806": 65, "080847": 52, "08090615": 61, "0810": 33, "08108108": 48, "0811": 35, "0812": 54, "0813": 54, "08140875": 32, "0817": 66, "0819": 65, "08198048": 41, "0822": 66, "0828": 35, "083": 44, "0831": [33, 66], "08333333": 51, "0834": 54, "0835": 54, "08376142": 41, "08435032": 44, "0847": 53, "0848": 66, "0850": [36, 54], "08503": 54, "0851": 54, "0852": 54, "08529891": 31, "0853": 54, "0854": 66, "0861": 67, "0863285": 33, "086721": 33, "0868": 65, "0869": 54, "087079": 52, "0871": 54, "0871943": 24, "0872": 34, "0874": 54, "0875": [33, 54], "0876": 54, "0876915": 41, "0877": 54, "0878": 54, "0879": 36, "0880": 66, "0881": 36, "0882": 54, "0883": 54, "0886": 54, "0887": 54, "08873": 54, "08881704": 50, "08887": 54, "0889": 54, "089032": 32, "0893": 54, "0898": [35, 66], "09": [15, 17, 18, 19, 33, 40, 48, 49, 51, 52, 54, 62, 67], "0900": 54, "0904": [54, 63], "0906": 69, "09061491": 61, "0908": 66, "09086733": 39, "090892": 52, "0913": 67, "09143846": 24, "0914388": 24, "0917": 66, "0917153": 41, "09184708": 39, "09197429": 24, "09220405": 31, "0924": 33, "0926": 35, "0929": 66, "0932": [36, 66], "09340045": 26, "09348275": 21, "0937": 34, "094": 66, "0940": 34, "0941": 54, "0943": 62, "0945": [54, 66], "0946155": 26, "095": 23, "09507": 54, "0951": 54, "0952": 34, "0954": 54, "0956e": 62, "0963511": 41, "0967": 36, "097": 50, "0974": 54, "097791": 33, "0979": 33, "0982887": 45, "0990": 54, "0991": 65, "09920635": 51, "09957961739117976": 23, "0998": 66, "0hnnb": 52, "0k": 51, "0m": [30, 32, 33, 34, 35, 36, 37, 40, 48, 49, 50, 51, 52, 53, 54, 62, 63, 64, 65, 66, 67, 68, 69], "0m100": [40, 54], "0mib": 54, "0u": [50, 52, 68], "0x1592bb4c0": 30, "0x1774afbe0": 63, "0x17a028b80": 69, "0x17e851dc0": 69, "0x17f2929a0": 66, "0x32387a0a0": 30, "0x3244fa3d0": 30, "0x3251b8730": 67, "0x32b78d6a0": 62, "0x32ce9a190": 62, "0x32cf73e20": 62, "0x34f9d8430": 67, "0x785c086c7260": 33, "0x785c0873bec0": 33, "0x785c0b33a090": 33, "0x79008c3bc530": 65, "0x790125ece0f0": 65, "0x798223eab620": 52, "0x7982598908f0": 52, "0x79c5944704d0": 53, "0x79c594472fc0": 53, "0x7a4bd84d6000": 40, "0x7a4bd8c86000": 40, "0x7a4bd8e636e0": 40, "0x7a4c66216030": 40, "0x7cc6adfae9f0": 34, "0x7cc6dc036960": 34, "0x7d11c3910530": 37, "0x7d11c3910830": 37, "0x7d11dcfabba0": 37, "0x7d78da73cef0": 50, "0x7d78e044f140": 50, "0x7da22420c5c0": 36, "0x7f02c94e9490": 44, "0x7f0849fd9d90": 66, "0x7f08eb5d0cd0": 66, "0x7f09d45b0390": 66, "0x7f1e015a4250": 47, "0x7f35edb6ab10": 35, "0x7f360e0ccec0": 35, "0x7f3615ceb3b0": 35, "0x7f36176a0320": 35, "0x7f36197145f0": 35, "0x7f36197690a0": 35, "0x7f36197d90a0": 35, "0x7f406a8ba660": 41, "0x7f406a8bb7d0": 41, "0x7f406b9e01d0": 41, "0x7f6836374fd0": 31, "0x7f6f68cd1790": 23, "0x7fb4259a4550": 35, "0x7fb9302c3a30": 47, "0x7fb930373be0": 47, "0x7fb9304afa30": 47, "0x7fb9304e6280": 47, "0x7fb930518160": 47, "0x7fb948229b80": 47, "0x7fb948308430": 47, "0x7fb948568190": 47, "0x7fb949422130": 47, "0x7fbdb9f5d198": 23, "0x7fbdba102ac8": 23, "0x7fbdba1885c0": 23, "1": [17, 26, 30, 31, 32, 34, 35, 41, 42, 48, 49, 50, 51, 52, 53, 54, 55, 60, 62, 63, 64, 65, 66, 68, 70], "10": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69], "100": [21, 23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 40, 41, 42, 43, 44, 48, 49, 51, 52, 54, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68], "1000": [23, 25, 29, 39, 41, 44, 46, 47, 50, 52, 53, 54, 60, 61, 63, 64, 65, 66], "10000": [23, 29, 30, 39, 41, 53, 58, 67], "100000": [29, 39, 64], "1000000": 39, "1001": [44, 52], "10025": 54, "1003": 54, "10032365": 61, "10041841": 51, "100480": 25, "1008": 54, "1009": 54, "100u": 35, "101": [27, 35, 49, 61, 65, 69], "1010": 35, "1011": 35, "10138249": 25, "1016": 35, "1017": 66, "102": [35, 50, 65, 66], "1020": 56, "10204082": 25, "1021": 56, "1022": 56, "1024": [44, 54, 65, 66, 67, 68], "10240038": 21, "1028": 35, "1029": 68, "102u": 35, "103": [35, 65, 68], "1031": 54, "10311": 68, "1032": [33, 54], "1033": 36, "10355988": 61, "1037": [35, 66], "103u": 35, "104": [35, 54, 65, 67, 68], "1040": 54, "1042": 65, "10425693e": 33, "10426493e": 33, "1048563": 67, "1048564": 67, "1048565": 67, "1048566": 67, "1048567": 67, "1048568": 67, "1048569": 67, "1048570": 67, "1048571": 67, "1048572": 67, "1048573": 67, "1048574": 67, "104u": 35, "105": [23, 35, 54, 65], "1050": 27, "1052": 35, "1054": [34, 35], "1055": 33, "105u": 35, "106": [35, 65, 68], "1061": 54, "10615": 54, "1062": 54, "1063": 36, "10630373": 26, "1066": 65, "1067": 35, "10688835e": 33, "1069": 69, "107": [35, 65, 68], "1070": 54, "1071": 54, "1074": 36, "1076": 66, "10793716": 21, "108": [35, 65, 66], "1080": 66, "1083": 35, "1088": [52, 63], "109": [35, 39, 65, 67], "109361306": 50, "109362334": 50, "10970464": 48, "109u": 35, "10m": [34, 54, 65], "10min": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "11": [1, 3, 11, 15, 17, 18, 19, 27, 33, 34, 35, 36, 38, 39, 48, 49, 51, 52, 53, 54, 56, 60, 62, 63, 64, 65, 66, 67, 69], "110": [35, 64, 65, 67], "1100": 66, "110m": [48, 68], "110u": 35, "111": [25, 35, 45, 52, 65], "1111": 68, "111314": 33, "1116": 33, "111u": 35, "112": [35, 50, 65, 68], "1121": 67, "11249518": 32, "1126": 51, "1129": 68, "113": [35, 65, 68], "1130": 36, "11301": 67, "1133": 34, "113750": 52, "11392405": 48, "114": [35, 65], "1143": 66, "1145": 34, "1146": 66, "1147": 66, "1148": 54, "11482": 54, "114m": 48, "114u": 35, "115": [35, 65, 69], "1153": [34, 35], "1156": 66, "115m": 48, "115u": 35, "116": [35, 65, 67], "1160": 66, "1166": 54, "1168": 69, "116u": 35, "117": [35, 51, 55, 65, 68], "1171": 66, "1172": 66, "1175": 35, "11783641": 50, "118": [35, 65], "1180": 35, "1185": 35, "11863178e": 24, "11876": 53, "118964": 66, "118m": 67, "119": [35, 48, 49, 65, 69], "1190": 35, "11913009": 45, "1196": 35, "11981567": 25, "11min": [16, 17, 18, 19], "12": [6, 10, 11, 12, 13, 14, 15, 17, 18, 19, 24, 27, 28, 32, 33, 34, 35, 36, 39, 40, 45, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "120": [29, 35, 40, 60, 65], "1200": [28, 33, 35, 36, 61, 62, 63, 66, 67], "12011": 52, "1204317": 64, "1205": 35, "12050": 53, "1208": 35, "120m": 48, "120u": 35, "121": [21, 23, 24, 27, 28, 30, 35, 44, 47, 52, 53, 65], "1211": 66, "121164": 32, "12118": 68, "12123711": 39, "1213": [35, 67], "1214": 48, "1215": 35, "1216": 35, "121825": 23, "122": [21, 23, 24, 27, 28, 30, 35, 44, 47, 52, 53, 65], "1224": 35, "1226": 51, "12271578e": 33, "1229": 36, "123": [35, 65], "12310158e": 33, "12313627e": 33, "1233": [35, 36], "1234": 34, "1236": 67, "12389752": 26, "1239": 36, "123u": 35, "124": [35, 65, 68], "1240e": 62, "1241": 35, "12413400e": 33, "12413509e": 33, "1247": [35, 68], "124u": 35, "125": [35, 39, 65, 67], "1250": [37, 49], "1254": 66, "1255": 35, "126": [35, 65], "1261": 35, "1261086": 33, "1262": 35, "12650597": 21, "1268": 36, "12698413": 51, "127": [35, 65], "1272": 62, "1275": 67, "1275133": 41, "127783": 33, "127u": 35, "128": [25, 35, 36, 46, 50, 52, 54, 55, 57, 58, 65, 66, 67], "1284": 66, "1286898": 41, "1287": 35, "1289": 36, "129": [35, 56, 65], "12933": 66, "12934": 66, "12970711": 51, "12978902": 24, "1299": 35, "12999585": 38, "12k": 52, "12m": [35, 36, 42, 48, 49, 51], "12min": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 70], "12w": 54, "13": [3, 6, 7, 12, 13, 15, 18, 19, 23, 27, 33, 34, 35, 36, 38, 39, 40, 45, 48, 51, 52, 53, 54, 56, 60, 62, 63, 64, 65, 66, 68, 69], "130": [35, 49, 51, 54, 65, 68, 69], "1300": [36, 66], "1302": 69, "13033159": 24, "1309": 35, "131": [35, 54, 55, 65], "1310": 64, "131200": 46, "1314": 35, "1316": 66, "1319": 36, "132": [35, 55, 65], "1320": 35, "1321": 65, "1328": 65, "1329": 66, "132u": 35, "133": [35, 55, 65], "1330": 35, "1332": 35, "1334": 68, "1338": [35, 69], "134": [35, 65, 68], "134186": 52, "1342": 36, "135": [35, 65, 67, 68], "135199": 40, "1355": 66, "136": [31, 35, 53, 65], "1361": 66, "1362": 35, "1363": 35, "13640800": 62, "1367": 35, "136u": 35, "137": [35, 65, 67], "13771319": 26, "13780": 53, "138": [35, 50, 56, 65], "13819800": 62, "1383": 35, "1386": 35, "1387894": 41, "1388": 54, "139": [35, 65], "1392435": 45, "1394": 54, "1396": 65, "1397": 66, "13m": [34, 35, 67], "13min": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 70], "13x13": 52, "14": [1, 4, 13, 14, 15, 18, 19, 27, 29, 30, 33, 34, 35, 36, 40, 41, 42, 45, 48, 49, 50, 51, 52, 53, 54, 56, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "140": [23, 35, 48, 49, 65, 66], "1400": 66, "1408": 34, "1409": 66, "141": [35, 36, 50, 51, 65, 68], "1410127": 41, "1412": [33, 35], "1414": [35, 66], "1415": 68, "1418": 66, "1419": 65, "142": [35, 36, 49, 50, 65], "14239484": 61, "1426": 66, "142835": 33, "14285714": 25, "1429": [34, 35, 65], "143": [35, 36, 50, 65], "1433": 36, "144": [33, 35, 36, 42, 50, 61, 65, 67, 68], "14407603": 41, "1442747": 53, "1445": 66, "1447377": 32, "1449": 66, "145": [35, 65], "1450": 65, "14509804": 48, "145u": 35, "146": [35, 65], "1460": 36, "1463": 69, "1467": 35, "1468": 34, "146m": 67, "146u": 35, "147": [35, 50, 54, 65, 68], "147584": 46, "148": [35, 56, 65], "14803609": [42, 48, 49, 51], "1481947": 41, "1482": 36, "1486": 66, "1487": [33, 66], "1488": 54, "14883": 54, "149": [35, 65, 67], "14914677": 26, "149177": 33, "14924584": 49, "1499e": 62, "14m": [35, 42, 45, 48, 49, 51], "14min": [15, 16, 17, 18], "14prakash": 35, "15": [3, 11, 12, 13, 18, 19, 23, 24, 27, 29, 33, 34, 35, 36, 40, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "150": [24, 32, 35, 39, 40, 41, 52, 53, 65, 67, 68], "1500": [27, 28, 29, 33, 34, 35, 36, 69], "1500525": 41, "1501": 66, "1502": 66, "151": [35, 65], "15141407": 41, "1518": 69, "152": [35, 41, 49, 64, 65, 69], "1520": 69, "1527": 69, "1528": 65, "1529": 65, "152m": 67, "153": [35, 41, 65], "1530": 34, "1535": 66, "1536": [52, 66], "15360": 48, "15360mib": 54, "1538": 69, "154": [35, 65], "1540": 69, "15409659": 26, "1543": 36, "1545": 36, "1548": 35, "155": [35, 65, 67], "1554": 34, "1559": 67, "156": [35, 49, 65], "15605706": 26, "1562": 65, "1568": 69, "156976": 41, "157": [35, 65], "1572": 66, "15786946": 26, "158": [35, 65], "15848": 21, "1586816": 66, "1588": 66, "159": [35, 56, 65], "1591": [36, 67], "1596": 66, "1597": 66, "1599": 35, "15998353": 26, "15min": [16, 17, 18, 19], "16": [2, 4, 6, 10, 14, 18, 19, 24, 25, 27, 30, 32, 33, 34, 35, 36, 37, 40, 44, 46, 48, 49, 50, 51, 52, 53, 54, 56, 60, 62, 64, 65, 66, 67, 68, 69], "160": [35, 36, 49, 50, 52, 65], "1604": 67, "16056": 53, "161": [35, 65], "16109684e": 33, "16109906e": 33, "1614": 66, "16172": 33, "1619": 69, "162": [34, 35, 65], "1621": 34, "1622": 66, "162563": 33, "1627": 54, "1628": 54, "163": [35, 52, 65], "163750": 52, "16384": 46, "164": [35, 65], "16400384": 46, "1646": 69, "1649": 67, "165": [35, 65], "16530943e": 33, "1654": 66, "1656": 69, "1656923": 64, "166": [35, 65], "1661": 66, "16613400": 62, "167": [35, 65, 68], "16731707": 26, "1677": 67, "168": [35, 50, 54, 65], "1682": 66, "168376": 33, "16846594": 64, "169": [35, 65], "1699": 65, "16m": 34, "16min": [15, 17, 18, 19], "17": [2, 3, 5, 7, 9, 11, 14, 18, 19, 23, 24, 27, 33, 34, 35, 36, 39, 40, 46, 52, 53, 54, 56, 60, 61, 62, 64, 65, 66, 67, 68, 69], "170": [25, 35, 65, 68], "1700": 36, "170137": 40, "170442": 32, "171": [35, 41, 65], "17122800": 62, "17182042": 21, "1719694": 33, "172": [35, 48, 65, 68], "1720": [66, 67], "17217433": 38, "1724": [35, 69], "172500": 52, "173": [35, 52, 65], "1733871": 25, "17346939": 25, "1735": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "1739": 66, "173m": 54, "174": [35, 65], "17407847": 26, "17464789": 68, "1746856": 21, "17474882": 50, "175": [35, 65], "1753": 67, "1754": 36, "1755": 34, "176": [35, 65], "1765113": 32, "1767": 35, "1768": 35, "177": [27, 35, 65], "1770": 65, "1771": 69, "1772": 54, "1773": 69, "17730": 53, "17737": 54, "1774": 54, "1775858": 33, "178": [35, 52, 65, 68], "1780": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 69], "1783": 66, "1789": 36, "179": [35, 65], "1791": 66, "1792": 69, "17924839740742132": 31, "17979412": 24, "17m": [32, 34, 35, 48], "17min": [15, 16, 18, 19], "18": [2, 8, 9, 18, 27, 33, 34, 35, 36, 40, 41, 44, 51, 52, 53, 54, 56, 60, 62, 64, 65, 66, 68, 69], "180": [35, 50, 52, 65], "1800": 35, "18017292": 38, "1803": 65, "1806": 34, "18068483": 26, "181": [33, 35, 56, 65], "1813": 66, "181303": 33, "181875": 52, "182": [35, 54, 65], "1820": 54, "1821": 66, "18221927": 64, "1829": 69, "183": [35, 65], "1833": [35, 36], "184": [35, 65], "1843": 66, "18461538": 51, "1848": 66, "18496": 46, "185": [35, 65], "1850": 65, "1852": 69, "1855": 66, "1858": 66, "186": [35, 44, 46, 65], "1861": 34, "18659553e": 39, "1867": [35, 36], "186819": 33, "187": [35, 65], "1871": 65, "1872": 35, "18770038": 41, "1879454": 33, "188": [35, 64, 65], "1880": [33, 66], "188125": 52, "1882": 66, "18828452": 51, "18874274": 45, "189": [35, 65], "1890": [36, 66, 67], "189086": 32, "1892": [35, 68], "18936073": 64, "1899": 35, "18m": [34, 35, 64], "18min": [15, 16, 17, 18], "19": [1, 2, 4, 6, 8, 9, 13, 18, 27, 30, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 46, 49, 50, 52, 53, 54, 60, 62, 64, 65, 66, 68, 69], "190": [35, 52, 65], "1900": 35, "1901": 66, "1902": [66, 69], "19036": 53, "191": [35, 65], "1913": 66, "1919": 34, "19193": 68, "192": [35, 49, 52, 65, 68], "1920": 68, "19209": 53, "1925": 66, "1926": 66, "193": [35, 65], "1933": 35, "1934": 66, "1936": 66, "193m": [54, 69], "194": [35, 52, 65, 68], "1942": 35, "1945": 66, "1949": 60, "195": [35, 65], "1953": 66, "196": [35, 54, 65], "1961": 60, "1962": 36, "1963": 69, "1966": 35, "1967": 35, "1968": 66, "197": [35, 65], "1975": 66, "19758065": 25, "1976": 69, "197632": 66, "19781611": 43, "198": [35, 65], "1980": 36, "19800": 53, "1982": 66, "1983": 36, "1985": 66, "1988": 66, "199": [35, 65], "1990": 65, "1993": [66, 69], "1997": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 62], "19993200": 62, "19m": [34, 35, 48], "19min": 19, "1_w": 25, "1d": [15, 18, 69], "1e": [25, 30, 38, 42, 51, 58, 68], "1glhwdtjbua6_7gixygaedkrtbcgsuqqt": 59, "1m": [54, 62, 63], "1m0": [30, 32, 33, 34, 35, 36, 37, 40, 48, 49, 52, 53, 54, 62, 63, 64, 67], "1m1": [32, 33, 34, 35, 36, 37, 40, 48, 50, 51, 52, 54, 62, 63, 64, 67, 68, 69], "1m10": [34, 48, 49, 51, 65, 69], "1m1000": [53, 63], "1m11": [48, 51, 69], "1m1124": 67, "1m12": 51, "1m1213": 67, "1m1250": [37, 49], "1m13": 51, "1m141": 51, "1m143": 67, "1m1487": 66, "1m149": 67, "1m1562": 65, "1m16": 62, "1m17464789": 68, "1m177": 67, "1m184": 67, "1m19": 54, "1m2": [33, 34, 35, 36, 48, 49, 50, 53, 54, 67], "1m2000": 63, "1m23985": 67, "1m24": [48, 51], "1m27": 68, "1m29": 68, "1m3": [48, 50, 52, 53, 54, 69], "1m31": 68, "1m313": 30, "1m32": [53, 65], "1m33": 65, "1m34": 63, "1m35363": 52, "1m38": [33, 34, 35, 36], "1m4": [35, 48, 49, 51, 67], "1m42": 54, "1m5": [35, 51, 65], "1m521": 65, "1m553467096": 50, "1m565": 66, "1m6": [51, 54], "1m7": [37, 48, 54, 65, 69], "1m71": 48, "1m74": 54, "1m75": [33, 54, 67], "1m76": 54, "1m782": 68, "1m79": [62, 67], "1m8": [48, 51, 69], "1m87": 67, "1m88": 67, "1m89": 67, "1m9": [51, 69], "1m91": 63, "1m96112376": 52, "1mb": 54, "1x1": [18, 46], "1x8x6x1": 43, "2": [5, 17, 39, 41, 42, 47, 49, 50, 51, 52, 53, 54, 55, 59, 60, 61, 63, 64, 65, 66, 67, 68], "20": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 20, 23, 24, 26, 27, 29, 33, 34, 35, 36, 39, 41, 42, 43, 49, 52, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "200": [23, 24, 27, 29, 33, 35, 37, 42, 44, 48, 49, 51, 52, 54, 58, 61, 62, 63, 64, 65, 66, 67, 68], "2000": [22, 23, 27, 29, 35, 36, 57, 63], "20000": 68, "200000": 65, "20001": 45, "2003": [35, 66], "2004": 35, "2006": 62, "2009": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 29], "201": [27, 35], "2010": 56, "2012": [18, 51], "2014": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "2015": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 49, 62], "2016": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 62], "2017": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 35, 62], "2018": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 54, 57, 58, 59, 60, 67], "201875": 52, "2019": [44, 54, 68], "202": [35, 49, 52], "2020": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 51, 54], "20201": 20, "2021": [0, 2, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "2022": [2, 7], "2023": [10, 12, 13, 14], "2024": 69, "2025": [35, 48, 49, 51, 52, 54, 68], "20252": [27, 28], "20280": 53, "2029": 66, "203": [35, 52, 64], "2033": [35, 36], "2034": 35, "203750": 52, "204": 35, "2042": 35, "2047": 66, "205": [30, 35, 66], "2054": 66, "205625": 52, "206": 35, "2061": 67, "2063": 66, "2064": 46, "2067": 35, "20674506": 23, "20686978": 41, "206926": 33, "207": [35, 52], "2070": 34, "2071": 68, "2074": 66, "2075": 35, "2075872": 33, "208": 35, "2080": [25, 52], "2083": 35, "2083e": 63, "2084": 69, "2085": 66, "20899463": 26, "209": 35, "2092": 35, "2097": 66, "20977061": 64, "2098": 66, "20k": [45, 68], "20m": [34, 35, 54, 65], "20min": [15, 18], "21": [1, 6, 14, 18, 33, 34, 35, 36, 45, 48, 50, 52, 54, 55, 56, 61, 62, 65, 66, 67, 68, 69], "210": [34, 35], "2100": 35, "21006155": 38, "210482": 33, "210780": 52, "2108": [35, 66], "211": 35, "2117": 35, "211729": 33, "212": 35, "2124": 48, "2125": 35, "2128": 35, "213": 35, "2131": 69, "2133": 35, "214": 35, "21405369": 41, "2142": 35, "2144": 66, "2148": 67, "215": [35, 68], "2150": 35, "2154": 66, "2155": 66, "2158": [35, 66, 69], "21588690e": 24, "21590781": 38, "216": [35, 42, 54], "2167": 35, "2168": 66, "2169": 69, "21690": 53, "217": [35, 48, 49, 51], "21730722": 38, "21747205": 41, "2175": 35, "2179": 69, "218": [35, 49], "2180": 34, "218125": 52, "2182": 36, "2183": 35, "2189": 66, "219": 35, "2192": 35, "219375": 52, "21960784": 25, "21m": [34, 35, 48, 54, 65], "21min": [15, 17], "22": [1, 8, 9, 12, 18, 24, 33, 34, 35, 36, 42, 48, 49, 51, 52, 54, 55, 56, 61, 62, 64, 65, 66, 67, 68, 69], "220": [35, 52], "2200": [35, 66], "2203e": 62, "2204": 65, "2206": 36, "2208": 35, "221": 35, "2216": 66, "2217": 35, "222": 35, "2221": 69, "2223": 68, "2224": 65, "2225": 35, "2227": 63, "22270943e": 33, "22298": 33, "223": [35, 50], "2230": [65, 66], "223292": 52, "2233": [35, 36], "2238": 65, "224": [35, 44, 50, 52, 54, 59, 68], "22401306e": 33, "2242": 35, "2244021": 38, "2245": 66, "225": 35, "2250": 35, "22509325": 38, "2253": [42, 48, 49, 51], "22544098e": 24, "2256": 66, "2258": 35, "226": [35, 68], "2261": 69, "2264": 35, "227": 35, "2272": 35, "2274": 35, "227500": 52, "228": 35, "2282": 66, "2286": 66, "228750": 52, "22892199": 26, "229": [35, 42], "22920": 53, "2293": 33, "22m": [34, 35, 54], "22min": [16, 19], "23": [2, 6, 10, 12, 18, 33, 34, 35, 36, 42, 52, 56, 61, 62, 65, 66, 67, 69], "230": [34, 35, 69], "2300": 36, "2301": 66, "2304": 67, "2305": 35, "231": [35, 42, 43, 54], "23107885": 26, "2315": 66, "2316": 35, "232": [35, 42, 43], "2320": 46, "23217": 54, "2322": 54, "2327": 67, "232916": 52, "233": [35, 42, 43], "233125": 52, "2332": 69, "2335": [36, 66], "233517217172232": 29, "2337": 69, "23388037": 24, "233u": 30, "234": [33, 35, 44], "2343": 66, "23434848": 39, "23443488": 39, "23448575": 24, "23464049": 64, "23472038": 24, "23472045": 24, "23478876": 21, "235": [35, 42, 43], "235000": 52, "23524888": 54, "2353": 69, "2354": 36, "2357": 66, "2358": 34, "235m": 54, "236": [35, 42, 43, 66], "2360": 66, "23629359900951385": 63, "23664391": 38, "2367": 69, "237": [35, 42, 44, 48], "2378": 30, "23793": 66, "238": [35, 66], "23846835": 45, "2389": 66, "239": [35, 51], "2394": 65, "2395": 34, "2396": 66, "2397": [30, 36], "2399": 69, "23m": [34, 35, 54], "23min": 19, "24": [3, 5, 6, 8, 10, 11, 18, 19, 24, 33, 34, 35, 36, 48, 49, 51, 52, 54, 56, 57, 61, 62, 64, 65, 66, 67, 68, 69], "240": [30, 35, 36], "2405": [35, 69], "2407": 69, "2408932": 41, "241": [33, 35, 36, 50, 64], "2414048": 53, "2419": 49, "24193548": 25, "242": 35, "2423": 65, "24230769": 51, "243": [35, 40], "2430": 69, "24313725": 25, "2432": 65, "24330": 53, "2436": 67, "244": [35, 64], "2445": 63, "2449": 69, "245": [35, 48], "2455": 63, "2456": [53, 69], "2458": 66, "24596774": 25, "246": [35, 48, 64], "2468": 66, "247": [35, 48], "2472": 34, "2477": 69, "2479": 36, "24793": 66, "248": [33, 35, 54], "2484": [30, 34], "2486": 36, "2487": 36, "2489866": 64, "249": 35, "2493": 66, "249375": 52, "2495": 30, "249715": 33, "2499": 69, "24m": [34, 54], "24min": 19, "25": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 23, 33, 34, 35, 36, 42, 45, 48, 49, 51, 56, 57, 62, 63, 64, 65, 66, 68, 69], "250": [33, 34, 35], "25000": 68, "2503": 63, "2507": 62, "2507583326384995": 31, "25088": 50, "250u": 30, "250x250": 43, "251": 35, "251183": 33, "2519339": 64, "252": [35, 51], "2522": 30, "2524": 35, "2529": [35, 66], "253": 35, "2531": 69, "25332093": 37, "25347843": 45, "25372971": 26, "254": [35, 42], "25403226": 25, "254375": 52, "255": [26, 27, 28, 33, 34, 35, 36, 40, 42, 46, 48, 50, 54, 59, 69], "2552": 66, "255625": 52, "2557": 66, "25599527": 38, "256": [35, 44, 46, 50, 51, 52, 54, 65, 66, 67, 68], "2560": [36, 44], "2566": 35, "2569": 67, "256978": 52, "257": 35, "2571": 69, "258": 35, "25806452": 25, "258125": 52, "25844944": 26, "2585": 35, "259": [35, 48], "2592": 36, "259375": 52, "2595": 69, "2599": [30, 66], "25m": [34, 51, 54, 64], "25min": 19, "26": [6, 7, 10, 11, 13, 14, 18, 24, 33, 34, 35, 36, 39, 54, 56, 61, 62, 65, 66, 67, 68, 69], "260": [35, 42, 44, 51], "2600": 36, "2601": 30, "26024526": 38, "26060": 53, "260625": 52, "261": 35, "2612": 30, "2612314224243": 66, "2613": 69, "26190476": 51, "262": 35, "262166": 33, "263": 35, "2633": 36, "2635": 66, "2638": 36, "264": 35, "264375": 52, "2645": 34, "265": [35, 44, 46], "2651": 65, "2652": 34, "266": 35, "2665": 66, "26667854": 38, "2667": [35, 36], "2668": 65, "267": 35, "2674127": 33, "268": 35, "2680": 30, "2682": 66, "2683": 35, "2686": 36, "268750": 52, "269": 35, "26928138e": 39, "2694": 69, "26m": [34, 51, 54], "27": [2, 3, 7, 13, 18, 33, 34, 35, 36, 49, 54, 61, 62, 64, 65, 66, 69], "270": [35, 52], "2700": 36, "27011786": 64, "27021": 33, "2705": [36, 66], "27092433": 38, "271": 35, "272": 35, "2721": 35, "2724": 35, "2727": 35, "273": 35, "2730": 66, "27307624": 38, "273125": 52, "2732": 30, "2733": 35, "273750": 52, "2739": 65, "274": 35, "2744": 30, "275": [35, 47], "2754307": 33, "2755": 65, "276": [35, 47], "2763": 36, "277": [35, 54], "27733624": 38, "2779": 30, "278": [35, 47], "2782": 65, "27824593": 50, "2789": 69, "279": 35, "2794": 66, "2794511": 41, "27959607": 21, "2798": 66, "27m": [34, 51, 54, 67], "28": [1, 4, 12, 18, 26, 27, 30, 33, 34, 35, 36, 48, 49, 50, 55, 56, 61, 62, 65, 66, 68, 69], "280": 35, "2800": 36, "28030543": 26, "2806": 36, "28061224": 25, "280625": 52, "281": 35, "2810": 66, "281039": 52, "2811": 66, "2814": 36, "282": 35, "2823": [36, 66], "2824": 34, "28249571": 26, "282500": 52, "2827": [65, 69], "2829": 35, "282964": 52, "283": [35, 66, 68], "2831": 69, "2833": 36, "2834": 35, "2836732": 41, "2838602": 38, "284": [35, 68], "2844": 35, "2845": 67, "2848": 51, "285": 35, "285000": 52, "28577818": 45, "2858": 30, "28591832": 26, "286": [35, 53], "2861": [68, 69], "2862": 65, "2863": 36, "2867": 35, "286814": 52, "286908": 33, "287": [35, 61], "2871": 66, "2872": 30, "2875": 35, "2876820724517808": 64, "2877": 30, "288": [35, 52], "2884": 36, "2885": 36, "289": 35, "2890505": 43, "2893": 66, "289375": 52, "28m": [34, 51], "28x28": 30, "29": [7, 8, 9, 12, 14, 18, 33, 34, 35, 36, 54, 61, 62, 64, 65, 66, 69], "290": [35, 52], "2901": 66, "2902102470398": 66, "29028185": 32, "2903": 35, "29032258": 25, "2909": [36, 66], "291": 35, "2911": [35, 65], "29143506": 21, "2916": 69, "2917": 65, "292": 35, "292589": 52, "2927": 66, "292715": 33, "2928": 69, "293": 35, "2931": 36, "2931943": 33, "2933": 36, "29354581": 26, "2936": 69, "2937": 35, "293750": 52, "2939": 35, "294": 35, "29403063e": 33, "29403497e": 33, "294111": 64, "29411765": 48, "2942": 35, "2943": 64, "29435484": 25, "2944": 64, "2945": 69, "2946": 67, "2947": 35, "2948": [65, 66], "295": [35, 50, 54], "2950": 35, "295168": 46, "29520": 53, "2954": 34, "2956": 35, "2959": [35, 36], "29591286": 38, "296": 35, "2960": 35, "2961": 35, "29613388": 38, "2965": 35, "29692343": 41, "297": [35, 68], "2970": 35, "2974": 35, "2975": 35, "297500": 52, "2979": [30, 35], "298": 35, "2981": 35, "2984": 35, "2985": 35, "2986": [35, 69], "2987": 35, "298750": 52, "2988": 35, "2989": 35, "299": [35, 52], "2990": 35, "2991": 35, "2992": [35, 36], "2993": 35, "2994": 35, "2997": 35, "2998": 35, "2999": [35, 66], "29m": [34, 67], "2_": 37, "2d": [15, 18, 47, 49, 52], "2f": [23, 24, 25, 27, 33, 36, 37], "2i": 58, "2k": 51, "2m": [33, 34, 49, 53, 62, 63], "2x": [24, 39], "2x2": [47, 55], "2x3": 43, "2x3x1": 43, "2x3x1x2": 43, "2xy": 38, "2y": 38, "3": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 26, 28, 29, 30, 32, 34, 35, 36, 47, 48, 50, 51, 52, 53, 54, 55, 60, 61, 62, 64, 65, 66, 67, 68], "30": [1, 2, 7, 12, 13, 14, 18, 19, 23, 24, 29, 33, 34, 35, 36, 40, 44, 52, 53, 54, 55, 56, 59, 61, 62, 65, 66, 67, 68, 69], "300": [29, 33, 34, 35, 45, 49, 52, 66], "3000": [35, 36], "30000": 66, "30017424": 26, "3002": 35, "3003": 35, "3004": 35, "3004911": 41, "3005": 35, "3006": 35, "3007": 35, "30073246": 26, "3008": 35, "3009": 35, "300px": 65, "301": 41, "3010": 35, "3011": 35, "3012": 35, "3013": 35, "3014": 35, "3015": 35, "3016": 35, "3017": 35, "3017530441284": 66, "3018": 35, "3019": 35, "3020": [35, 66, 67], "3021": 35, "3022": 35, "302214": 52, "3023": 35, "3024": 35, "30241935": 25, "3025": 35, "3028": 35, "3029": 64, "303": 44, "3030": 35, "3032": 66, "3033": 36, "3035": 35, "30352163": 33, "3036": 30, "3039": 35, "3042": 35, "3044": 30, "30482780e": 33, "30483029e": 33, "3049": 35, "3051": 69, "305101": 52, "3052": 35, "3053": 35, "3056": 53, "3061": 35, "307": 44, "307036": 41, "3072": 42, "3073528": 64, "3074": 69, "3076": 66, "30769231": 51, "3083": 67, "30835241": 26, "3084": 53, "30849894597834": 24, "30852405": 64, "308951": 52, "309": 33, "3091": 35, "3093": 35, "31": [1, 7, 18, 33, 34, 35, 56, 61, 62, 65, 66, 69], "3100": 69, "3104": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "3105": 35, "31070882": 38, "311": 47, "3112": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "3116813": 64, "3117": 66, "311875": 52, "312": [47, 50], "3124": 69, "3126": 68, "312801": 52, "31282": 44, "31288": 44, "313": [30, 47], "3130": 35, "3133": [36, 66], "3134": 67, "3140": 35, "3143": 36, "3147": 69, "314726": 52, "314m": 54, "315": 36, "3153002": 26, "31530074": 26, "3155": 30, "3156": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "315625": 52, "315u": 30, "316": 68, "3161": 69, "31610265": 26, "3161621": 41, "3164": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "316651": 52, "316875": 52, "3169": 35, "317": 68, "3170": 69, "3173": 67, "3185": 35, "31851983": 38, "31860155": 47, "318u": 30, "31915": 67, "3192": [65, 66], "3193": 65, "3195488": 31, "319u": 30, "31m": [34, 51], "32": [18, 25, 26, 28, 30, 33, 34, 35, 36, 42, 44, 46, 48, 49, 51, 52, 53, 54, 56, 57, 58, 61, 62, 64, 65, 66, 67, 68, 69], "320": [52, 54], "3200": [35, 67], "3203": [35, 65], "3204": 35, "320u": 30, "3214": 69, "3219": 30, "321u": 30, "3223": 69, "3225": 36, "3228": 35, "322859": 41, "323388": 52, "3239": 66, "324350": 52, "32483895": 26, "324u": 30, "325": 52, "3250": 30, "325313": 52, "32558449": 26, "3261": 69, "326250": 52, "326275": 52, "3265": 66, "3265834": 33, "326u": 30, "3274": 66, "32768": 46, "32769000": 46, "32814753e": 33, "32816141e": 33, "328200": 52, "32828997": 26, "3283": 69, "32832": 46, "328809": 33, "3289": 69, "32936508": 51, "32945173": 45, "3299": 36, "32m": [30, 32, 33, 34, 35, 36, 37, 40, 48, 49, 50, 51, 52, 53, 54, 62, 63, 64, 65, 66, 67, 68, 69], "32x32x3": 48, "33": [18, 33, 34, 35, 39, 41, 49, 56, 62, 64, 65, 66, 67, 68, 69], "330": [30, 52], "3301": [66, 69], "330125": 52, "33030961": 26, "33053004": 26, "331088": 52, "33116959": 26, "3319": 35, "332": 64, "332050": 52, "3321": 35, "33221543": 26, "3324038": 66, "3325": 30, "3328": 30, "332u": 30, "333013": 52, "3333": 35, "3333e": 62, "3336241": 38, "3336737": 38, "33367577": 49, "333975": 52, "3345": 67, "334u": 30, "3353": 35, "3355": 35, "33551139": 32, "3358723": 33, "3359": 69, "335900": 52, "336": 68, "3360": 30, "33604518076771783": 31, "336250": 52, "3364": 30, "3365": 30, "336862": 52, "336875": 52, "336u": 30, "3370": 30, "3370885": 64, "3371772": 49, "3373647": 38, "3374": 30, "3375": 30, "3376": 34, "3377": 69, "337825": 52, "337u": 30, "3382": 34, "3386": 66, "3389": 69, "3393": 30, "33930275": 41, "339375": 52, "339612": 33, "33m": [48, 51], "34": [18, 33, 34, 35, 48, 49, 51, 56, 62, 63, 65, 66, 67, 69], "3403": 35, "34075492": 26, "3408": 30, "340m": 68, "3413": 36, "3416": [65, 69], "341m": 69, "3422": [66, 69], "34251866": 38, "342637": 52, "3428": [36, 65], "3429": 30, "3429204": 38, "342m": 69, "3431": 30, "3433": 35, "343412": 32, "343m": 69, "3442": 30, "344375": 52, "3444": 30, "344562": 52, "3447": 30, "34470552": 21, "3447949": 38, "345": 69, "3451": 35, "3454": 36, "34542735": 26, "34560": 49, "3458172692": 69, "34581753": 21, "3461": 67, "3464": 69, "346487": 52, "3469": 36, "3472": [30, 69], "3474": 69, "347449": 52, "3476": 36, "347u": 30, "3481": 30, "348125": 52, "34816": 53, "3483": [35, 36], "348412": 52, "3484329": 32, "3488": 69, "348m": 69, "349374": 52, "349375": 52, "3498": 36, "3499": 30, "34m": [48, 51, 68], "35": [18, 20, 33, 34, 35, 37, 51, 56, 61, 62, 65, 66, 67, 68, 69], "350": 67, "3500": 35, "35006344e": 33, "35006601e": 33, "3503": 30, "350337": 52, "3509": 30, "350m": 69, "3510": 69, "3511226": 38, "351299": 52, "35172211e": 33, "35173043e": 33, "35178": 67, "3519": 30, "351m": 69, "3524": 30, "353": 44, "3530846": 33, "3531": 36, "353125": 52, "35363": 52, "353m": 69, "354": 44, "354187": 52, "3542": 66, "35434369": 43, "354m": 69, "355": 66, "35517252": 64, "3552": 65, "3553": 30, "3557": 69, "3558": 35, "355m": 69, "356": 67, "3564": 69, "356m": 69, "356u": 30, "357": 50, "35731": 32, "3576": [36, 63], "3577": 34, "357m": 69, "358037": 52, "35849794": 26, "3587": [36, 69], "359": 50, "3591": 69, "359m": 69, "35m": [48, 51], "36": [33, 34, 35, 50, 51, 54, 56, 62, 64, 65, 66, 68, 69], "360": 52, "36000061035156": 41, "3603": 30, "360924": 52, "360m": 69, "3610": 36, "3615": 65, "3617": 30, "3618054": 33, "361m": 69, "36222705": 38, "3626": 65, "362849": 52, "3629": 66, "362m": 69, "363": 44, "363811": 52, "363m": 69, "3645931": 66, "364702": 33, "364m": 69, "3651": 30, "3654": 30, "3655": [48, 69], "3659": 30, "365m": 69, "366579": 33, "366699": 52, "3668": 30, "366m": 69, "3670022": 41, "3674": 35, "3676374": 38, "3676615": 33, "3678827": 33, "367m": 69, "3685": 30, "368624": 52, "369": 67, "36905685": 41, "36928": 46, "3693": 66, "3696": 35, "369m": 69, "36gb": 54, "36m": 34, "37": [33, 34, 35, 62, 65, 66, 67, 69], "37035694": 26, "370m": 69, "3710": 69, "3713": 69, "3716": 66, "3717937": 41, "3720": 67, "3721": 69, "37238857": 38, "3731": 35, "3740": 51, "3744": 51, "3746": 69, "37500166e": 33, "37500294e": 33, "37530": 53, "3766": 68, "3768": 69, "37754067": 43, "3776": 67, "3777": 69, "377u": 30, "3780": 69, "37816707": 21, "3785": 68, "378648": 33, "3787": 67, "379211": 52, "3792427": 38, "3793": 34, "3799": 30, "379m": 66, "37m": [30, 32, 33, 34, 35, 36, 37, 40, 48, 49, 50, 51, 52, 53, 54, 62, 63, 64, 65, 66, 67, 68, 69], "38": [20, 33, 34, 35, 36, 39, 40, 54, 62, 65, 66, 67, 68, 69], "38007": 44, "380173": 52, "3803": 44, "3807557": 38, "381": 68, "381m": 69, "3825173": 41, "3829": 65, "383": 67, "3830": 30, "3833": 35, "3837": 69, "384": [52, 64], "384081": 33, "3844": 36, "3846": 69, "3847": 34, "3849": 35, "385": 68, "3854": 69, "38578104": 26, "386": 68, "3863": 66, "3873854": 33, "3876": [30, 68], "3879274": 38, "3884647": 38, "3894663": 33, "38981165": 39, "39": [33, 34, 35, 54, 62, 64, 65, 66, 68, 69], "390": 67, "3900": 66, "3903": 69, "390760": 52, "3916": 30, "391723": 52, "39250": 34, "39341073848662333": 31, "3945": 30, "3958": 34, "3963": 65, "3966": 35, "3967103": 41, "3972e": 34, "397498": 52, "397500": 52, "39802428": 45, "39850916": 21, "3988": 35, "3989": 35, "39m": [33, 40, 51, 54, 68], "3d": [19, 69], "3f": [23, 33, 34, 40, 42], "3m": [33, 34, 49, 62], "3mb": 49, "3ra": 29, "3x": 38, "3x3x1": 43, "3z3": 55, "4": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 21, 23, 24, 26, 27, 29, 30, 34, 35, 36, 37, 38, 39, 41, 58, 60, 62, 63, 65, 66, 67, 68, 69], "40": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24, 29, 33, 34, 35, 39, 40, 52, 53, 54, 56, 61, 62, 65, 66, 69], "400": [32, 33, 37, 40, 45, 52, 56, 62, 63, 64, 66, 68], "4000": 40, "40015721": 41, "40036": 53, "40049763": 24, "40059814": 41, "400m": 69, "401250": 52, "40131234": 43, "401347": 52, "4015": 65, "40167658": 26, "4023608": 64, "4028": 35, "40293482": 26, "403": 44, "4030": 51, "4032": 66, "4034": 35, "4046358": 41, "4047": 69, "4060": 35, "406250": 52, "4065292": 38, "40657878": 50, "4066": 25, "4067": 35, "407": 68, "408": 31, "4080": 35, "40857522": 26, "40873016": 51, "40878": 33, "409047": 52, "4093": 65, "4096": 50, "41": [33, 34, 35, 61, 62, 65, 66, 67, 69], "41160962": 49, "41202902793884": 66, "41209546": 26, "4122": 66, "4123": 35, "41239464": 38, "41249585": 26, "4127903": 53, "4137": 51, "4140": 66, "41412": 32, "415": 36, "415784": 52, "4160": 48, "41610": 34, "4163": 35, "41630": 34, "416875": 52, "4168954": 41, "4180": 30, "41m": 51, "42": [20, 33, 34, 35, 49, 54, 61, 62, 64, 65, 66, 67, 69], "420": 48, "4204114153": 69, "42082405": 32, "42086142": 21, "4209": 30, "4211483": 38, "4216": 34, "42321322": 26, "424375": 52, "42555748": 43, "4256522": 47, "425m": 69, "426": 64, "4267": 35, "4272": 65, "427222": 33, "42812613": 26, "4288": 65, "42964391": 26, "4298": 67, "42m": [48, 66], "43": [23, 24, 33, 34, 35, 48, 62, 65, 66, 67, 68, 69], "43006826": 26, "430221": 52, "4308": 66, "43102843": 26, "4312": 35, "431612": 38, "43215844e": 33, "43216640e": 33, "43307521": 32, "433109": 52, "4332554": 65, "433677": 33, "435034": 52, "436": [44, 50, 67], "4367": 35, "436959": 52, "43724881e": 39, "4373": 66, "4374": 66, "439757": 33, "43986821": 50, "43m": [54, 66], "44": [33, 34, 35, 48, 61, 62, 65, 66, 69], "440": 64, "4405": 65, "4411987": 26, "4418": 51, "44194868": 21, "442": 66, "44245022": 26, "442733": 52, "443": [42, 48, 49, 51, 52, 54, 66], "443226": 32, "444": 66, "445572": 33, "4456015": 33, "4465276": 26, "446583": 52, "447": [66, 68], "4472": 68, "4473": 48, "448": [46, 52, 54], "4481": 66, "448508": 52, "44m": [34, 66], "45": [25, 30, 33, 34, 35, 48, 62, 65, 66, 67, 69], "450": 27, "450166": 43, "45021895": 38, "4504": 65, "4508": 35, "45081097": 47, "451": [41, 62, 66], "4534": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "4536": 68, "453750": 52, "4542": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "4546": 64, "45464871": 39, "454m": 69, "45506799": 45, "455775": 49, "45580951e": 33, "45581626e": 33, "4579": 34, "458708": 38, "4599": 30, "45m": [34, 66], "46": [33, 34, 35, 61, 62, 64, 65, 66, 67, 68, 69], "4607": 66, "4608": 54, "46099615097046": 66, "461": 41, "4613": 68, "46140969": 26, "4617": 65, "461875": 52, "461983": 52, "4625": 54, "4630": 51, "464": 54, "4640": [46, 51], "4649": 34, "4651794": 41, "46536898": 21, "4655": 65, "4663906": 38, "466875": 52, "467": [48, 49], "46776438e": 24, "468125": 52, "4688": 69, "469": 68, "4692": 65, "4697": 35, "46m": [34, 66], "47": [33, 34, 35, 41, 62, 65, 66, 67, 69], "470": 66, "4700062": 41, "47034836e": 24, "471": 31, "471607": 52, "4723947": 64, "47312685": 21, "4733": 35, "4737": 35, "47407": 33, "4748868942261": 66, "475": 66, "47563": 33, "476": [66, 68], "4763": 35, "4767": 35, "4774": 63, "4775": 63, "4776": 63, "4777": 63, "4778": [35, 63], "4779": 63, "4779847": 64, "4781": 63, "47843137": 25, "4785": 63, "4786": 63, "4787": 63, "4788": 63, "4789": 63, "479": 52, "4791": 63, "4792": 63, "4794": 63, "47940": 53, "47958": 67, "47959": 67, "4798": 63, "4799": 65, "47m": 66, "48": [30, 33, 34, 35, 40, 48, 49, 51, 52, 61, 62, 65, 66, 67, 68, 69], "480": [68, 69], "48021984": 41, "4807": 63, "481": 66, "48191568": 32, "482756": 32, "48391975": 26, "4853": 69, "48533997": 32, "4858": 35, "486": 66, "4862": 35, "48821399": 32, "48914381": 45, "4892": 66, "48m": [34, 66], "49": [33, 34, 35, 39, 46, 54, 62, 65, 66, 67, 69], "490": 47, "4900": 35, "490000": 52, "49053686e": 33, "4909": 66, "491": 47, "4912": 51, "492": 44, "4922": 69, "493": 47, "4936": 34, "4944277": 33, "49583768844604": 66, "4959702": 33, "496": 54, "49606568": 64, "4963": 49, "4967": 35, "4973": 34, "4978": 35, "4987": 51, "49952987": 21, "4997": 65, "4998707": 50, "49m": [34, 66], "4_h": 58, "4f": 66, "4i": 45, "4m": [33, 49, 51, 62], "4min": [15, 16], "4x": 38, "4xy": 38, "4y": 38, "5": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55], "50": [6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 26, 27, 29, 30, 33, 34, 35, 36, 40, 57, 61, 62, 64, 65, 66, 67, 68, 69], "500": [20, 23, 25, 27, 29, 52, 61, 65, 66], "5000": 69, "50094410e": 33, "50094751e": 33, "501250": 52, "5014334": 33, "5016826": 41, "5021": 36, "5037": 49, "504": [41, 69], "5043": 65, "5047": 69, "505000": 52, "5058": 35, "5066283": 41, "5067": 35, "50693361e": 33, "5070": 65, "50710814": 31, "50731617": 32, "5079": 65, "50889206": 41, "5090": 66, "50968820e": 33, "50969122e": 33, "50c": 54, "50m": [34, 66], "51": [33, 34, 35, 48, 49, 51, 61, 62, 65, 66, 67, 68, 69], "5100": 35, "5117": 69, "512": [50, 54, 66, 67], "513": 62, "51326483": 38, "514": [25, 69], "5140": 48, "515": 68, "51589807": 45, "5163": 66, "5166": 35, "516776": 33, "51694816": 26, "517": 64, "5184": 53, "5187": 65, "5193": 51, "519375": 52, "5199": 66, "51m": [33, 34, 66], "52": [30, 33, 34, 35, 42, 48, 49, 51, 64, 65, 67, 68, 69], "520": 54, "5200": 35, "520226": 33, "5203411": 38, "52073733": 25, "521": 65, "5217": 66, "52174768": 26, "5218644": 33, "5219": 48, "5227": 65, "5228426": 41, "5237631": 41, "5238": 48, "5244": 68, "5245": 51, "5246674": 32, "5252": 35, "5258": 65, "5261": 51, "526536": 33, "5267": 35, "527": 50, "528": 25, "5286": 35, "52m": 48, "52x52": 52, "53": [33, 34, 35, 61, 62, 65, 66, 67, 69], "530": [34, 68], "5300": 51, "5308": 65, "5312": 65, "53277874": 38, "53309876": 38, "533125": 52, "53319740e": 24, "5342": [51, 68], "5342975": 33, "5345": 68, "5348": 35, "5348973": 33, "5367": 35, "53674316e": 24, "537": 64, "53840065": 50, "53992624": 26, "53m": 48, "54": [33, 34, 35, 54, 61, 62, 65, 69], "5402": 65, "5403": 35, "54059637": 26, "5409565": 41, "54127547": 26, "54182448": 32, "543": 67, "543750": 52, "5438": 66, "544": [33, 50, 53], "544225": 49, "5444031": 38, "545000": 52, "5454": 35, "5455": 65, "54561913": 38, "546": 68, "5462": 51, "54624164": 38, "546250": 52, "5476": 35, "547659": 33, "5478": 65, "5487": 66, "548782": 33, "5495": 66, "55": [24, 33, 34, 35, 61, 65, 67, 69], "550": 54, "5500": 35, "550000": 52, "55012488": 26, "5504": 30, "5511": 35, "551250": 52, "552": 49, "5524": 51, "552898": 53, "5529312": 38, "553307673053737": 24, "553467096": 50, "5535": 68, "55369234": 24, "553750": 52, "5539543": 45, "555000": 52, "5552": 66, "5562": 30, "55635373": 26, "55644989": 50, "5567": 35, "557195": 33, "55769231": 51, "557u": 63, "5582415": 41, "5585": 48, "558u": [62, 63], "5595789": 38, "559u": 62, "55m": 51, "56": [33, 34, 35, 50, 61, 62, 64, 65, 67, 68, 69], "560": [48, 49, 66], "5600": 49, "560000": 52, "5603": 48, "56031686": 41, "5606": 51, "56078431": 48, "560u": 62, "561u": [62, 63], "5626": 51, "562u": 62, "5631733": 33, "5633": 35, "563u": 62, "5649": 48, "5650": 35, "5660": 34, "566715": 41, "566u": [62, 63], "5677154": 41, "5684": 48, "5686": 51, "5696": 34, "5696809": 38, "5699": 67, "56m": 51, "57": [33, 34, 35, 44, 56, 65, 67, 69], "5700": [35, 51], "57056": 39, "570728": 33, "570741": 52, "5708": 35, "570u": [62, 63], "571u": 63, "5723349282191469": 26, "572358": 33, "5729": 35, "572u": 62, "5732207": 41, "5733": 35, "5734": 69, "5736552": 24, "573u": 63, "5741": 65, "57425906": 39, "57455133": 39, "5748": 48, "574u": 63, "57513616": 24, "57513794": 24, "5755": 65, "576": 49, "57627869e": 24, "5767": 35, "577485": 32, "577u": [62, 63], "5781": 51, "5795": 35, "579u": 62, "57m": 51, "58": [31, 33, 34, 35, 38, 42, 64, 65, 67, 69], "5800": 35, "580101": 26, "5803": 35, "580519": 38, "580u": 63, "581176": 52, "5816": 48, "5816872": 64, "581u": 63, "5828": 69, "582u": [62, 63], "583": 67, "5833": 35, "5836": 53, "584": [50, 54], "5842": 66, "584u": 62, "5850": 34, "5864": 34, "5865188837051392": 41, "5867": 34, "5869": 34, "5872": 34, "588125": 52, "5882": 34, "58839035": 49, "5885": 48, "588u": 62, "589": 67, "58902": 44, "58917": 44, "5897": 34, "589u": [62, 63], "58m": 51, "59": [33, 34, 35, 51, 54, 61, 65, 69], "590": [50, 54], "5900": 48, "590080": 46, "59040517": 32, "591": 53, "5910": 53, "5911": 34, "59128": 53, "5913": 34, "5919": 34, "5924": 63, "5925": 34, "5929": [34, 65], "592u": 63, "593": 42, "5930": 34, "5931": [34, 48], "5933": 35, "5939": 34, "593u": 62, "5940933": 33, "5942338": 38, "5944": 34, "5946": 48, "5947": 48, "5949": 34, "5950": 35, "59509962": 26, "5952": 68, "5957": 65, "595m": 50, "5961": 34, "5962": 35, "59628955e": 33, "59632223e": 33, "5965": [34, 35, 48, 66], "5966": 69, "5967": [34, 35], "596u": 63, "5971": 51, "5972": 65, "5973353": 32, "5979": 51, "597u": 62, "59832582": 26, "5986": 65, "59868766": 43, "5987": 34, "5988": 34, "5991": 65, "5992": 51, "5993": [34, 66], "5999": 34, "59m": 51, "5f": 23, "5k": [26, 27, 28, 33, 34, 35, 36], "5m": [33, 36, 49, 51], "5min": [17, 18, 19], "5x": 68, "5x5x1": 43, "6": [5, 13, 14, 16, 21, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 69], "60": [23, 33, 34, 35, 48, 49, 51, 61, 65, 66, 67, 69], "600": [23, 27, 29, 45, 48, 52, 53, 54, 57, 58, 61, 62, 64, 66, 68, 69], "6000": [34, 35, 48, 49], "60000": 30, "6002": 34, "6004": 34, "60072369": 26, "6011": 34, "6015": 34, "6016": 34, "6021": [34, 66], "602u": 63, "603": 54, "6033": 35, "6039": 65, "6041": 65, "6042": 34, "6043": 35, "6045": 51, "6049213": 33, "605": 69, "6050": 65, "6051": 51, "6052": 35, "6054": [34, 69], "6059": 34, "6071": 34, "60714286": 25, "6074": 34, "6076": 34, "6077": 51, "6085": 51, "609": 50, "6090": 34, "6097": 63, "6099": [51, 65], "60m": 67, "61": [33, 34, 35, 54, 61, 64, 65, 69], "610": 34, "6100": [34, 35], "6101": 65, "6103829145431519": 48, "6104": [35, 48], "6105435": 24, "610553466924376": 24, "6109": [34, 35], "6113": 65, "6119": 51, "6121": [51, 65], "6123": 34, "6125": 48, "6127": 34, "612u": 62, "6132": 65, "6133": 35, "6138": 48, "6139": 34, "614": 53, "6140": 53, "6143": 65, "614u": 62, "6152": [34, 51], "6164": 34, "6167": [35, 65], "6169": 48, "616u": 62, "617": 64, "6172": 34, "6173": 48, "6177": 35, "61791": 64, "617u": 62, "618": 41, "61804": 64, "61812": 64, "61815": 64, "61822": 64, "61836": 64, "6184": [35, 65], "61845": 64, "61854": 64, "61870": 64, "61879": 64, "6189": 34, "61898": 64, "618u": 62, "619": 68, "6190": 34, "6191": 34, "61911": 64, "6192": 51, "61933": 64, "6195": 63, "61957": 64, "6197": 35, "61987": 64, "61m": 51, "62": [33, 34, 35, 39, 55, 62, 65, 66, 67, 68, 69], "620": 34, "6200": [34, 35], "620000": 52, "6203": [34, 65], "62031": 64, "62036": 33, "62112": 64, "621250": 52, "6213": 48, "621372": 33, "62155216": 26, "62178687": 26, "6218": [51, 65], "6219": 34, "6222": 34, "622u": 62, "6230": 66, "6231691241264343": 51, "6232": 51, "6233": 35, "6235": 51, "62350": 64, "6237": 34, "6238": 34, "624": 54, "6240": 34, "62407879": 26, "6241": 34, "6249": 48, "6252": 48, "6252090930938721": 48, "626": 68, "6264": [34, 35], "6267": 35, "6269": 65, "6269636": 33, "6270": 34, "6274": [34, 35], "6277": 34, "627u": 62, "62813387": 26, "6284": 34, "628489": 52, "628u": 63, "6290": 51, "6293": 65, "6297": 65, "62m": 51, "63": [20, 33, 34, 35, 45, 65, 67, 69], "630": 34, "630000": 52, "6301": 69, "6301328": 38, "6302": 35, "6304": [65, 67], "6306": 34, "6307": 35, "63076923": 51, "6308": 34, "63097": 64, "631": 52, "6313": 34, "6314": [34, 51], "632u": 62, "6330": 48, "6334": 34, "6335": 48, "6339": 34, "633u": 62, "6340": 51, "63432008": 32, "63442165": 40, "6344426": 38, "6345": 35, "6347": 51, "6349": 51, "6352": 34, "6353": 34, "6359": 34, "635u": 62, "6360": 35, "6367": 35, "6368": 51, "636945": 40, "63716257": 32, "6374": 35, "6378": 51, "6379": 48, "6380": 48, "6386e": 63, "6388": 34, "6394": 34, "639795": 33, "6398": 66, "63m": 51, "63u": 35, "64": [25, 26, 30, 33, 34, 35, 42, 44, 46, 49, 50, 52, 54, 57, 65, 66, 67, 69], "640": 54, "6400": 35, "6403": 65, "6405": [48, 51], "6406": 34, "6407": 35, "640781": 32, "640u": 62, "6414": 34, "6417": 51, "641875": 52, "6419": 34, "641u": 62, "642": 49, "6420": 65, "6428": 34, "64287394": 50, "6429": 34, "6431": [34, 48, 51], "64484": 44, "64508": 44, "6452": 34, "6454": 35, "64565631": 43, "645u": 62, "6460906": 64, "6462": 65, "6464": 51, "64647": 33, "646801": 38, "6470": 48, "64705882": 49, "6471": [48, 51], "6473": 35, "6477": 69, "64782345": 64, "6485": 48, "648u": 62, "6491": 35, "6493": 65, "64935404": 38, "649u": 62, "64m": [51, 67], "65": [33, 34, 35, 54, 61, 65, 66, 68, 69], "650": [30, 41], "6505": 65, "650625": 52, "651": 62, "6510": 48, "651111": 33, "65115": 32, "6519": 35, "651u": 35, "652": 41, "6521": 67, "6522": 34, "6523975729942322": 51, "6524": [48, 51], "6527": 48, "6534214": 33, "6538": 66, "6539": 48, "654": 50, "6545": 65, "65490196": 49, "6551": 48, "6551265120506287": 48, "6554": 51, "6559": 48, "6559416": 38, "656": 50, "6560": 35, "656386": 32, "6567": 35, "6571": 34, "6572": 48, "6574": 48, "657408": 66, "65771514": 38, "6578": 48, "657u": 62, "658065": 53, "658125": 52, "6585": 65, "6592": 48, "6596": 48, "65980244": 38, "6599": 48, "65m": [51, 67], "65u": 35, "66": [20, 30, 33, 34, 35, 48, 65, 66, 68, 69], "660": [23, 53], "66013083": 39, "660625": 52, "6608": 65, "6609": 48, "66122985": 38, "6622": 65, "6626": 35, "6628": 51, "66282284": 49, "6629": 35, "6630": 35, "663545": 33, "6640": 48, "6641": 35, "664248": 32, "6643": 65, "66435313": 38, "6643627250332145": 39, "664362725033482": 39, "66471749e": 33, "66506994": 32, "6651": 65, "6655": 51, "665625": 33, "6657": 35, "6658": 48, "66632426": 49, "66647": 65, "6665": 51, "666668": 40, "6674": 51, "6676": 51, "667u": 37, "668": [64, 66], "66818777": 43, "6687": 65, "668750": 52, "66893005e": 24, "6691": 32, "66m": 51, "66u": 35, "67": [33, 34, 35, 56, 61, 65, 66, 69], "670": [52, 54, 68], "6703": 51, "6706": 51, "6707": 35, "670u": 37, "671171": 32, "671206": 33, "671250": 52, "6714": 65, "6718": 35, "6722": 35, "67224115": 32, "672345": 40, "6726": 51, "6732": 51, "6733": 51, "6737": 51, "6763": 48, "67634726": 41, "67660165": 38, "6768923": 33, "6770": 51, "6771": 51, "677157": 40, "6776": 51, "6782841": 47, "6791": 51, "679218": 40, "67m": 51, "68": [33, 34, 35, 39, 56, 61, 65, 66, 67, 69], "6801": 65, "6802": 34, "6803274": 38, "6813": 48, "681424": 52, "682": 42, "6822": [51, 65], "6823": 51, "6825": 51, "68266": 32, "6830041": 33, "6831": 51, "6833": 35, "6835": 65, "68367347": 25, "6842": 51, "6845": 63, "6848": 51, "6849": 65, "6853": 51, "6854": 65, "6858": 51, "685972": 33, "6860": 51, "68627451": 49, "6871": [51, 66], "6874": 65, "6875": 34, "6876": 35, "6881": 35, "6883": 34, "6886": 68, "6894827": 53, "6896": 34, "6897": 48, "689997": 32, "68999713": 24, "68999789": 39, "689998055222224": 24, "68999806": 24, "6899981": 39, "68999875": 24, "689999": 40, "68m": [33, 51], "69": [33, 34, 35, 52, 61, 65, 66, 69], "69000401": 24, "6904": [65, 66], "6905": 51, "6911": 48, "6915356": 64, "6918": 35, "692": 27, "692241": 32, "6931471805599454": 64, "6934": 65, "6937": 48, "693m": 54, "6942": 48, "6945": 35, "6946": 34, "6950": 48, "6954": 51, "696": 54, "69603944": 41, "6968": 65, "697": [48, 51], "69751": 64, "6976": 51, "697786": 52, "6978": 65, "69886017": 38, "6998": 48, "6999": 48, "69m": 51, "6be4f42d4b47": 53, "6f": 52, "6m": [33, 36, 49], "6min": [16, 18, 19], "6osmmj5azg58ksye8z6ctkr3tl3z1mflv0wndsm0": 45, "7": [4, 16, 23, 24, 27, 29, 30, 32, 33, 34, 36, 37, 38, 39, 41, 43, 45, 48, 49, 50, 51, 52, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 68, 69], "70": [24, 33, 34, 35, 60, 61, 62, 65, 66, 67, 69], "700": [29, 36, 52, 61, 66], "7001": 65, "7017": 51, "7020": 65, "7023": 48, "7024": 34, "7027": [34, 35], "7029": 65, "7031": 48, "7033": 35, "703561": 52, "7037": 65, "7044": [48, 51], "7046": 34, "704618": 32, "7047": 35, "7052": 51, "7065": 51, "707": 64, "70704436": 32, "707076": 32, "7078": 69, "7078032": 41, "7084": 51, "7089": [48, 65], "709459": 40, "7095": 65, "70m": 51, "70u": 35, "70w": 54, "71": [33, 34, 35, 48, 61, 65, 66, 67, 68, 69], "7103": 48, "7104304": 38, "7106": 48, "7109495": 43, "711": 41, "7120": 35, "7126": 35, "7130857635072282": 62, "7137": 48, "7145": 48, "7149": 51, "715": 48, "7150": 51, "715343": 33, "7155362": 40, "7159409": 40, "7162": 34, "7163": 35, "7170": [48, 51], "7173": [48, 65], "7175": 34, "7179": 51, "718": 66, "7180587": 32, "71805891": 24, "71805905": 24, "71805906": 40, "71805908": 24, "7180591": 39, "71805919": 39, "71806026": 24, "7181": 34, "7187": 51, "7192": 51, "7193": 35, "71m": [33, 51], "71u": 35, "72": [33, 34, 35, 61, 65, 66, 69], "720": 69, "7206": [48, 51], "7208": 48, "7210": 51, "7212": 34, "72156863": 49, "7216": [35, 65], "7217": 48, "7222": [34, 65], "7227": [65, 69], "7229": [34, 48], "722mb": 54, "723": 68, "7230": 51, "723127": 32, "7234": 69, "7235": 51, "7237": 65, "72399567e": 33, "72400988e": 33, "7241": 51, "7246": 51, "7251613": 40, "7254": 34, "7255": 34, "7257": 51, "7261": 35, "726250": 52, "7263": 35, "7265": 35, "7269": 51, "727": 49, "7272": 65, "72798944": 39, "7282": 34, "7284": 51, "7289": 34, "7293": 65, "7294": 65, "72941176": 49, "7296937704086304": 51, "7297": 51, "72m": [40, 67], "72u": 35, "73": [33, 34, 35, 44, 50, 54, 55, 65, 66, 67, 69], "7307": 35, "7310": 51, "7311": 34, "7317": 35, "732": [48, 51], "7320347": 33, "7328": 48, "7333": 69, "733750": 52, "734": 50, "734360": 52, "7344": 69, "7346": 66, "7349": [34, 48], "7349284": 50, "7349299": 50, "735": [51, 66], "7350": 48, "7350199818611145": 48, "7354": 69, "735523": 33, "7359": 69, "7361": 66, "7365e": 62, "7366": 51, "7369": 65, "7369032": 33, "737": 42, "7372": 51, "7374": 48, "7377": 48, "73778293e": 39, "7378": 65, "7383": 69, "73856": 46, "7387": 48, "7394": 65, "7397": 65, "73976785": 40, "73k": 52, "73m": 67, "73u": 35, "74": [24, 33, 34, 35, 51, 62, 65, 69], "7401": 51, "7401493787765503": 51, "74028038978577": 66, "7403": 48, "7405": 35, "7406": 51, "7412": 66, "741250": 52, "7413": 51, "7417": [48, 51], "742": 64, "7421": 35, "7422": [34, 69], "74263": 44, "74268": 44, "7430": 51, "7434": 48, "7443": 51, "7447662570799594": 39, "744766257080116": 24, "7447662570801983": 24, "7447662570806624": 39, "7447662570808116": 24, "7447662570833065": 24, "74476987": 51, "745": [46, 51], "74509804": 49, "7453": 51, "7457": 51, "7458604": 32, "7459": 65, "746": 64, "7461": 69, "7472": 34, "7473285": 53, "7476e": 62, "7477": 69, "7479": 65, "7482": 65, "7486": [35, 68], "748797": 52, "7491": 63, "7496": 65, "74965775": 32, "74u": 35, "75": [20, 33, 34, 35, 55, 63, 65, 66, 69], "750": 48, "7500": [63, 69], "7502": 48, "75026011": 43, "751": [42, 48, 49, 51], "7510": 51, "7512": 34, "7517": 34, "75189483": 40, "7523": [48, 51], "7523302435874939": 48, "7524": 48, "75294118": 49, "7530": 48, "7534032": 40, "7535": 35, "7538": 48, "7539": 69, "7540": 48, "754209": 33, "7543545": 53, "754375": 52, "7545": 34, "7545385": 53, "7548": 65, "755": 44, "7552": 66, "7556874": 32, "7563": 51, "7564": 35, "7565": 34, "7566": 35, "7567": 51, "757019": 24, "7570201016172378": 24, "7577": 51, "7578": 69, "7579": 51, "7579541": 38, "75881691": 24, "75883713364987": 24, "758875": 33, "7590": 48, "7591": [48, 65], "75918376": 38, "7593": 65, "7594": 35, "75u": 35, "76": [33, 34, 35, 49, 54, 55, 65, 66, 67, 68, 69], "7602": 35, "760346": 52, "76078431": 49, "7610": 51, "7616": 48, "7617": 69, "7618": 65, "761875": 52, "762271": 52, "7626": 35, "7634138": 38, "7635": 65, "7638": 35, "764": [50, 53], "7640": 53, "76405235": 41, "76466936e": 33, "76468868e": 33, "765": [42, 44], "7656": 51, "767": [48, 49], "7671": 34, "7673": 34, "7675": 65, "7677": 48, "768": [58, 68], "7686": 34, "768_a": 58, "7695": [35, 69], "76987448": 51, "76u": 35, "77": [33, 34, 35, 65, 67, 68, 69], "7700": 51, "7709": 51, "7722": 34, "773": 51, "77307692": 51, "7731": 65, "7734": 69, "7735": 65, "7736": 48, "7739": [34, 51], "7745": 35, "775": 44, "77500826": 45, "7754": 49, "776": 48, "77637131": 48, "7763866": 38, "7768": 65, "7770021": 50, "7771": 65, "7773": 69, "7777777777777778": 27, "778": 40, "7782898545265198": 48, "7783": 48, "7784": 35, "7791": 35, "7796": 48, "77u": 35, "78": [27, 33, 34, 35, 61, 62, 65, 66, 67, 69], "780": 67, "7800": 34, "780073": 53, "7803": [35, 51], "781": 50, "781037": 33, "7811": 51, "7812": 69, "7817": 35, "7819588": 33, "782": 68, "7820": 34, "7823": 35, "782500": 52, "7826": 35, "7827": 35, "7828": 34, "7830": 51, "783466": 33, "784": [25, 27, 28, 30, 33, 34, 35, 36, 67], "7841": 35, "7842": 35, "7842876315116882": 51, "7843": [35, 51], "7844": 65, "7846": 35, "7847": 35, "7848": 35, "785": [26, 27, 28, 33, 34, 35, 36], "7851": 35, "7854": 35, "7855": 35, "7856": 35, "7857": 35, "7858": 35, "7861": 35, "7862": 35, "7866": 35, "7869": 35, "786911": 33, "7870": 66, "7872": 35, "7874": 35, "787456": 66, "7877": 51, "787974": 53, "788": 48, "78823529": 49, "7884": 35, "7888": 34, "7891": 51, "7891946": 32, "7892": 35, "7893": 35, "7894": [35, 65], "7898495": 33, "78u": 35, "79": [33, 34, 35, 50, 54, 56, 62, 65, 67, 69], "7901": 34, "7903": [34, 65], "7906": 35, "7908": 48, "7915": 51, "7919": 35, "792": [50, 54], "7920": 51, "7930": 69, "7931": 48, "7936": 35, "7938": 35, "7941": 35, "7942": 34, "7944": [48, 51], "7946": 35, "796": 34, "7962": 35, "7963": 35, "7963983": 38, "7970": 35, "7974": 35, "7975": 35, "7977": 34, "7978": 35, "7979": 65, "7980": 69, "7981": 35, "7983502fcad1": 53, "7984": 35, "7985": 35, "7986": 35, "7990": [25, 35], "7992": 35, "799375": 52, "79u": 35, "7m": [33, 36, 48], "7mb": 48, "7min": 16, "7x4": 43, "8": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 24, 27, 28, 29, 30, 32, 33, 34, 35, 39, 41, 42, 43, 46, 47, 48, 49, 51, 52, 53, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 69], "80": [33, 34, 35, 44, 48, 51, 52, 53, 62, 65, 66, 67, 69], "800": [24, 39, 44, 46, 48, 61, 64, 65, 66, 68], "80019156": 32, "80025815963745": 66, "8003": 65, "8004": 35, "8005": 34, "8015": 35, "8017": 65, "8021": 51, "8027775": 41, "8028": 35, "8030": 48, "8031": 35, "8033": 35, "8036885": 33, "8039": 65, "8040": 51, "8040316": 33, "8047": 35, "8048": 34, "8057": 65, "8058": 35, "8061": 35, "8062": 35, "8064": 65, "8068": [35, 51], "808": 50, "8088": 51, "8091405": 38, "8094": 35, "80952381": 51, "80966": 44, "80975": 44, "80u": 35, "81": [33, 34, 35, 65, 67, 69], "8103": 34, "8105": 35, "8106": 35, "8107": 35, "8111": 51, "8112e": 63, "811357": 52, "8116": 65, "8121": 65, "8122": 51, "8123": 35, "8125": 51, "8126": 35, "8130": 34, "8136": 65, "8141": 34, "8147": 30, "8150": 65, "81590414": 38, "8161": 48, "816250": 52, "8163": 35, "8170": 30, "8170469": 41, "81746032": 51, "8175": 35, "81757448": 43, "818": 34, "8182": 34, "8187": 35, "8189": 34, "8190326": 44, "8191": 35, "8192": 65, "8193": 48, "8194": 48, "819545": 32, "81960784": 49, "81960785": 49, "8197": [51, 65], "8199": [35, 65], "81m": 34, "81u": 35, "82": [33, 34, 35, 45, 62, 65, 67, 68], "820": 69, "8205e": 62, "8206": 35, "8208": 51, "8210": 35, "8217": 35, "8218": 35, "8219": 35, "8220": 35, "8221": 35, "8222": 35, "8223": 35, "8224": [35, 46], "8226": 35, "8227": [35, 51], "8230": 35, "8231506": 33, "8232": 35, "82327024e": 33, "82328672e": 33, "8234": 34, "8237": 35, "82375824": 41, "8239": 35, "824": 64, "8240": [35, 65], "8240411": 38, "8241": 35, "8242": 35, "8246": 35, "8247": 51, "8251": 65, "8254": 35, "825412": 33, "8254186": 41, "8255": 48, "8256": 25, "8259": 65, "8268": 35, "827": 67, "8270": 65, "8272": [34, 35], "8274": 65, "82745098": 49, "827451": 49, "8275": 34, "8277": 35, "8281": 66, "8286": 35, "8287": 35, "8299": [34, 35], "82u": 35, "83": [33, 34, 35, 60, 61, 65], "830000": 52, "8302": 35, "8304": 48, "8306": 35, "8308": 35, "8311": 35, "8313": 35, "8314": 35, "8316052": 32, "83168319": 45, "8319": 35, "832": 54, "8322": [35, 51], "8326857": 38, "8328": 51, "8333333333333334": 27, "83341053": 32, "83376545": 38, "8338981916716676": 62, "834": 67, "8342": 34, "8343": 48, "8346": 48, "835": 52, "8351": 35, "8355": [35, 65], "8357": 65, "8358": 35, "8364": 35, "8367": 34, "8375": 34, "8376": 34, "8377": 35, "838": 68, "8380": 65, "8383": 69, "8384": 35, "8387": 35, "839557": 33, "8396": 35, "8397": 35, "8398": [34, 35], "83u": 35, "84": [33, 34, 35, 48, 49, 62, 65, 67], "8400924": 41, "8404596": 41, "8407": 35, "8410": 35, "8411": 51, "8412": 35, "8420": [35, 48], "8427817": 41, "8427e": 62, "8428": 34, "8430": 35, "8432": 35, "84329534": 38, "8435824": 33, "8438": 35, "8440": 35, "8442": 35, "8444": [35, 65], "8444602": 41, "8447": 51, "8448": 35, "8457": 35, "8457896": 41, "8459": 35, "8460": 35, "846095": 33, "8461177": 38, "8470": 51, "8471": 35, "8472": 35, "8478": 48, "8479": 35, "8482": [35, 65], "8483": 65, "8486": 35, "84875023": 38, "8488": 35, "8489": [51, 66], "8490": 34, "8493": [35, 65], "8495": 35, "84u": 35, "85": [24, 33, 34, 35, 41, 61, 65, 69], "8503": 35, "8507542": 49, "8514": 35, "8517": 30, "8518": 51, "8519": 35, "8520": 30, "8521": 35, "8522": 51, "8523": 34, "8526": 48, "8543": 35, "8545": 35, "854732": 41, "8549": 51, "8553": 35, "85536695": 33, "8554": 51, "8555": 35, "856": [50, 54], "8561": 35, "8562": 34, "85661894": 38, "8567": 35, "8571": 34, "8571428571428571": 27, "8575": 35, "8577": [35, 51], "8578": 35, "8579": [34, 35], "8580": 35, "858655": 33, "85882353": 49, "85882354": 49, "8595": 35, "85u": 35, "86": [30, 33, 34, 35, 65, 66, 67], "8601": 66, "8604": 35, "8605": 35, "8607": 35, "86148352e": 33, "86149518e": 33, "8615": 34, "8617": 35, "8620": [30, 35], "8621": [48, 65], "8624": 63, "8625": 30, "86286545": 38, "8632": 67, "8633": 35, "8635": 65, "8639": 68, "8645": 30, "8650": 51, "8657": 35, "8663": 30, "8668": [30, 65], "86755799": 41, "8678": 69, "8680": 34, "8681": 35, "86824085": 45, "8685": 34, "86872587": 48, "8689": 65, "8694": 35, "86m": 48, "86u": 35, "87": [30, 33, 34, 35, 41, 64, 65, 67, 68], "870": 52, "8701": 35, "87063193": 38, "8712": 34, "8715": 30, "87191101": 32, "8727690577507019": 63, "8728": 30, "8730": 30, "8733": [34, 68], "8733646": 38, "8740": 65, "8746": 34, "8750": 30, "8751": 35, "8753": 30, "875452": 44, "8755": 30, "8760": 35, "8762": [30, 35], "8763": 30, "8766": 65, "8769": 35, "8770": 30, "8772": 30, "8774254": 38, "8777575": 38, "8778": 30, "878175": 23, "8783": 30, "87887999e": 33, "8789": 65, "8790": 65, "8791": 35, "8796": 34, "87u": 35, "88": [33, 34, 35, 61, 65, 66, 67, 68, 69], "880": 52, "8800": 35, "8805": [30, 35], "8808": 35, "8809": 35, "881138": 33, "8813": 65, "8814": 48, "8817": 30, "8820": [35, 68], "8826": 35, "8832942": 38, "8834": 35, "883u": 62, "8849": 51, "8849406838417053": 51, "8850": 51, "8852": 35, "8856": 35, "8857": 30, "8861": 30, "8873": 34, "8874": 48, "8879": 35, "8883195": 38, "8891": 34, "8898": 69, "88u": 35, "89": [33, 34, 35, 45, 61, 65], "8905": 34, "8917": 35, "8918": [34, 35], "8919": 30, "8921": 30, "892479": 50, "8924969": 38, "8926": 65, "8928": 35, "8938076496124": 66, "8940": 35, "8941": 35, "8951": 35, "8952345": 38, "89561131": 45, "8959839": 38, "8961": 34, "8968": 65, "8974": 34, "8975": 36, "8976": 35, "8977": 69, "8981": 30, "8987": 34, "8991": 30, "8992": 34, "89u": 35, "8j8nvncv3clnguh0na14l": 45, "8jmqoprnlvqxtv0wjxkb0a7j5ohbbp": 45, "8m": [33, 36, 37, 53], "8min": [16, 18], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 25, 27, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 45, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "90": [33, 34, 35, 36, 43, 48, 55, 65, 66, 67], "900": 66, "900038": 33, "9001": 35, "9008e": 62, "9018": 34, "9028": 30, "9032545": 38, "9033": 35, "9034": [30, 51], "9040": 51, "9041": [35, 48], "9043": 35, "9048": 51, "9050": 35, "9051679": 33, "9058": 34, "9061": 65, "9063075": 41, "9064": 35, "9068": 34, "9071": 30, "9072": 30, "9073": 49, "9075": 69, "9077": 35, "9082": 35, "90878613e": 33, "90881596e": 33, "9097": 51, "9099": 35, "90u": 35, "91": [33, 34, 35, 63, 65], "9102": [34, 69], "9110": [30, 36], "9112": 35, "9115": [30, 35], "9118": 48, "9120": 35, "91274303": 38, "9134": 35, "9140": 34, "9143": 30, "91462179e": 33, "9148": 30, "9150": 34, "9157": 51, "9159": 49, "9166": 34, "9170": 34, "91722184": 38, "9175": 35, "91794653204": 12, "918131": 40, "9182": 65, "9185": 35, "9191": 65, "9193": 35, "9195": 69, "91984620e": 33, "91987569e": 33, "91u": 35, "92": [20, 33, 34, 35, 45, 61, 65, 68], "92050209": 51, "9209": 65, "9210": 35, "9216": [34, 51], "9226": 35, "9233": 65, "9234": 69, "924": 69, "9243": 36, "9245": 34, "9246": 35, "9248": [34, 35, 46], "9258": 69, "9261": 65, "9264": 35, "9267": 35, "9269997": 38, "9273": [48, 65], "928": [50, 54], "9281": 34, "9287": 35, "9288": 66, "928m": 67, "9293": 36, "9294204": 33, "92u": 35, "93": [33, 34, 35, 36, 40, 65, 67, 69], "9301": 65, "9311633": 38, "9312": 69, "9320": [35, 68], "932034": 33, "932205": 33, "9326": 35, "93293601429": 1, "9331": 35, "9332": 67, "9335": 65, "9336": 69, "9337": 51, "9338": [34, 65], "9339323": 32, "9342": 34, "9346": 35, "9347": 34, "934946": 32, "9351": 35, "93553054": 45, "9365": 35, "9366": 35, "9369": 35, "9375": 69, "9376": 34, "9377": 35, "9378": 35, "9387": 35, "9390": 65, "9391": [34, 35], "93u": 35, "94": [33, 34, 35, 38, 55, 61, 65, 67], "940": 69, "941": 54, "9412": [34, 35], "9418": 35, "9423": [34, 35], "94241466e": 33, "94241650e": 33, "94266994891": [8, 9], "94331661": 24, "9434": 35, "9438": 69, "944": [48, 51], "9443": 34, "9444914": 53, "9445": 35, "9449": 35, "9452": 35, "9455": 65, "9457": 35, "9460": 35, "9461": 69, "9478": 35, "9479": 35, "9480": 34, "9481": 35, "9484": 35, "9485": 35, "9490": 34, "9494": 35, "9497": 35, "9498": 67, "94u": 35, "95": [33, 34, 35, 61, 65, 67], "950": 62, "9502": 35, "9504": 35, "9506": 35, "950751": 33, "951": 33, "9511": 35, "9512": 35, "9517": [34, 67], "95171": 66, "9519": 35, "9521": 35, "9522": 35, "9524": 35, "95260549230": [2, 3], "9528": 35, "9531": 35, "9532": 35, "9534": 67, "9536": 67, "95366177429": 14, "9539": 69, "9542": 36, "9543": 35, "9546": 34, "9547": 35, "9548": 34, "9553": 36, "9554": 35, "9555": 67, "9559": 35, "955u": 62, "9560": 35, "9561": 34, "9562": 67, "9563": 67, "9566": 35, "9569": 35, "95697427": 38, "956m": 69, "9577": 34, "9578": 69, "9581": 35, "9584": 65, "9586": [35, 69], "95893052e": 33, "95893807e": 33, "9591": 35, "9593": 35, "95947": 44, "9595": 36, "9596": 34, "9597": 36, "95978": 44, "95mb": 42, "95u": 35, "96": [33, 34, 35, 48, 49, 51, 52, 61, 65], "9600": [34, 35], "9601": [34, 35], "9602": 35, "9604": 35, "96046448e": 24, "9606": [35, 51], "9607": [35, 67], "9608": 35, "9609": 69, "961": 48, "9611": 35, "96112376": 52, "9612": 35, "9613": 35, "9614": 35, "9615": [35, 65], "9617": [34, 69], "9618": 35, "9619": 65, "9623": 65, "9628": 35, "9631": 35, "9632": 35, "9635": 68, "9636": 51, "9638": 35, "9639": 67, "9643": 35, "9644": 35, "9645": 35, "9646": 35, "9651": 35, "9652": 34, "96524782": 24, "9653506": 33, "9655": 35, "9656": 69, "9659": 35, "9660": 35, "9667": 35, "9667946100234985": 63, "9669": 35, "9673": 35, "9674": 34, "9675": 35, "9676": 35, "9677": 35, "9678": 35, "9681": [35, 36], "9682": 35, "9684": 35, "9689": 35, "9693": 35, "9695": 69, "9697": 35, "9699": 65, "96u": 35, "97": [20, 30, 33, 34, 35, 61, 65, 67], "9702": 35, "9703": 35, "9708": 35, "9709": 65, "9711": 35, "9714": 35, "9717": 35, "9718": 35, "9719": [35, 69], "9720": 35, "9721": 35, "9723": 35, "9724": 35, "9725": 35, "9727": 35, "9728": 35, "97280777": 38, "9729": 35, "9731": 35, "9738": 35, "9739": 35, "9740": 35, "9741": 67, "9742": 35, "9748": 35, "9749": 35, "9751": 35, "9753": 67, "9754": 35, "9757": 35, "9758": [35, 69], "9759": 35, "976": [48, 49, 51], "9761": 35, "9762": 35, "9763": 35, "9765": 35, "9766": 35, "9767": 35, "9769": 35, "97727788": 41, "9773": [65, 69], "9775": 51, "9779": 35, "977907121181488": 63, "978": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "9780": 35, "9780695": 33, "9783": 36, "97873798": 41, "978u": 62, "9790": [35, 36], "9791": 67, "97913008966": [10, 11], "9793": 35, "9797": 35, "97981918705": [6, 7], "97b794c97e5c": 35, "97m": 48, "97u": 35, "98": [33, 34, 35, 41, 55, 64, 65, 67, 68], "9800": 35, "98023224e": 24, "9803": [34, 35], "9804": 35, "9806": 67, "9807": 35, "9809": 67, "9810": 35, "9811": [35, 65], "9815": 35, "9818": 67, "981u": 62, "9820": 69, "9821": [35, 67], "9824": 67, "982u": 62, "9833": 35, "9836": 69, "9838": 35, "983u": 62, "984": 33, "9841359853744507": 63, "9843": 35, "9848": 35, "984u": 62, "9850567": 40, "9851": 35, "9854": 66, "9859": 35, "985u": 62, "9861": 35, "9862": 35, "9863": 35, "9866705": 53, "9867": 65, "986u": 62, "9872968792915344": 63, "9874": 35, "98798": 44, "987u": 62, "9881": 35, "98825": 44, "9884": 35, "9886": 48, "988807": 33, "9889": 35, "988u": 62, "9890": 35, "9892": 65, "9895753264427185": 63, "9896": 36, "9898": 69, "989u": 62, "98m": 48, "98u": 35, "99": [33, 34, 35, 51, 61, 65], "9902": 35, "99029623974": 13, "9906": 35, "9907": 35, "990u": 62, "991": [48, 51], "9910579919815063": 63, "9916": 65, "9917": 35, "991u": 62, "9922": [35, 65], "9922366142272949": 63, "9923": 35, "9927": 36, "9928": 35, "992u": 62, "9930955767631531": 63, "9933": [35, 48], "9933968": 33, "9937": 69, "9938153028488159": 63, "993u": 62, "9944646": 44, "9945": [34, 35], "99460286": 44, "99471575": 44, "9949": 35, "99497414": 44, "995": 41, "9950656": 44, "9952": [34, 35], "99527633": 44, "9964": 36, "9968": [35, 69], "9975": 35, "99862457e": 33, "9987": 51, "9988": 35, "9989": 65, "9989305": 32, "999": [51, 57, 58], "999375": 52, "99977154": 38, "99m": 48, "99u": 35, "9a": 59, "9i7wpblq": 50, "9m": 65, "9mb": 51, "9min": [15, 16, 18, 19], "A": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 29, 31, 37, 38, 44, 46, 47, 50, 52, 53, 54, 56, 58, 60, 62, 64, 65, 66, 67, 68], "AND": [29, 44, 52], "And": [26, 38, 65], "As": [20, 22, 29, 31, 56, 65, 67], "At": 35, "BE": 44, "But": [29, 40, 62], "By": [29, 68], "FOR": 44, "For": [0, 25, 26, 27, 29, 31, 37, 38, 43, 44, 45, 52, 58, 61, 66, 67, 68], "IF": 41, "IN": [44, 68], "IT": 41, "If": [21, 28, 30, 31, 32, 36, 38, 42, 44, 46, 54, 57, 61, 62, 64], "In": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 26, 27, 28, 29, 30, 31, 33, 34, 37, 38, 40, 42, 56, 64, 65, 66, 68, 69], "It": [0, 25, 30, 31, 36, 47, 53, 58, 62, 64, 68], "NO": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24], "NOT": [25, 38, 53, 56], "No": [12, 13, 14, 23, 54, 56, 63, 64], "Nos": 15, "ON": 68, "ONE": [27, 38], "OR": 29, "Of": [47, 61], "On": [29, 62, 64], "One": [18, 58, 64, 66, 68], "Or": 38, "Such": 64, "THE": [27, 41], "THEN": [40, 41, 55], "TO": 44, "That": 64, "The": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 21, 25, 26, 27, 28, 32, 33, 36, 37, 38, 40, 42, 43, 45, 46, 47, 48, 50, 54, 55, 56, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69], "Then": 62, "There": [20, 29, 31, 54, 61, 67, 68], "These": [20, 29, 64, 65, 68], "To": [26, 27, 37, 42, 52, 54, 57, 65], "WITH": [41, 46], "With": [28, 35, 38], "_": [24, 25, 27, 29, 30, 31, 37, 48, 49, 51, 53, 64, 66, 67, 68], "_0": [37, 39], "_1": 37, "_2": 37, "___________________________________": 63, "_________________________________________________________________": [25, 46, 61, 66], "__________________________________________________________________________________________________": 46, "__future__": 31, "__init__": [28, 30, 32, 35, 36, 37, 40, 49, 58, 63, 65, 66, 67, 68], "__keras_tensor__": [36, 51], "__version__": [25, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 64], "_c": 52, "_config": 20, "_i": [30, 31, 37, 61], "_j": 29, "_multivari": 23, "_t": [62, 64], "_toc": 20, "_tokenandpositionembed": 58, "_w": 64, "a1": [42, 43], "a2": [42, 43], "a_": 29, "a_m": 53, "aa": 41, "aaaa": 41, "ab": [23, 25, 29, 32, 36, 40, 47, 50, 51, 66], "abajo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "abcdefghijklmnopqrstuvwxyz": 67, "abierta": 70, "abierto": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "abl": [31, 38, 54, 57, 61, 66], "abordar": [18, 23], "about": [30, 33, 34, 54, 58, 64, 65, 67, 68], "abov": [20, 27, 33, 37, 38, 39, 43, 44, 45, 48, 59, 65], "abr": [1, 2, 3, 4, 6, 7, 10, 11, 13], "abrieron": 18, "abril": 3, "absl": 54, "absolut": [31, 68], "abstracci\u00f3n": 18, "abstract": 46, "academic_gown": 52, "acc": [36, 63], "acced": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "acceler": 42, "accent": [29, 66], "acceso": 23, "access": [0, 20, 32, 38], "acci\u00f3n": 19, "accord": [29, 44, 45, 58, 61, 64, 65, 67], "accordingli": [27, 37, 38, 43, 48, 54, 56, 57, 58, 59], "account": [29, 52, 54, 57, 62, 64, 66, 67], "accumul": [22, 29], "accur": [25, 66], "accuraci": [23, 25, 28, 30, 35, 36, 37, 42, 44, 48, 49, 51, 57, 58, 59, 63, 64, 67, 68, 69], "accuracy_scor": [23, 57, 58], "acelerar": 16, "acercamo": 15, "acercars": 23, "achiev": [30, 67], "acierto": 23, "acordingli": 31, "acount": 29, "acquaint": 28, "across": [33, 35, 64], "act": [30, 42, 48], "action": [59, 69], "activ": [25, 26, 30, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 61, 62, 63, 65, 66, 67, 68, 69], "activacion": 17, "activaci\u00f3n": [16, 18], "activation_2": 30, "activation_3": 30, "activation_map": 37, "activations_layer_0": 28, "activations_layer_1": 28, "activemil": 52, "activity_regul": 32, "activity_regular": [26, 35, 36, 40, 51], "actual": [21, 30, 34, 37, 42, 55, 66, 68], "actualizacion": 19, "acuerdo": 19, "acumul": 29, "acycl": 30, "ad": [21, 26, 30, 31, 54, 57, 59, 62, 66], "adam": [26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 46, 48, 49, 51, 53, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "adapt": [54, 61], "add": [26, 28, 30, 32, 34, 35, 37, 40, 43, 46, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "add_loss": 32, "add_nois": 33, "add_patch": [45, 52], "add_subplot": [33, 34, 66], "add_weight": [37, 40, 42], "addit": [29, 32, 34, 56, 66, 68], "addition": 20, "address": [31, 56, 64, 67], "adelant": 19, "adem\u00e1": 23, "adjust": [31, 33, 62], "admin": 20, "admitir\u00e1n": [12, 13, 14], "adquirir": 17, "adquirir\u00e1n": 16, "adquisici\u00f3n": 18, "advanc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 22, 29, 32], "advantag": [29, 64, 67], "adventuresinmachinelearn": [35, 36], "ae_activations_distribut": 26, "ae_sparse_activ": 26, "affect": 34, "after": [20, 33, 36, 38, 41, 42, 43, 45, 48, 57, 66, 67], "ag__": 41, "again": [31, 41, 42], "against": [38, 62, 66], "agent": 64, "agg_func": 67, "aggarw": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "aggreg": 68, "ago": [4, 8, 9, 14], "agrupamiento": 23, "ahora": [15, 18, 23, 24], "ai": [20, 54, 64, 65], "ai4eng": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ai_ml_dl": 22, "ailrh": 65, "aim": [31, 56, 67, 68], "air": 60, "airlin": [57, 58, 60, 61], "airline_senti": [57, 58], "aistats05": 64, "akernel": 53, "akward": 40, "al": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 24, 70], "alcanc": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "aleatoriament": 24, "alex": [12, 13, 14], "alex_c12": 51, "alex_w1": 51, "alexnet": [18, 50], "alexnet_conv1_conv2": 51, "alexnet_finetuned_minicifar": 51, "alexnet_fintun": 51, "algebra": [57, 58, 59], "algorithm": [20, 22, 31, 35, 66, 68], "algoritmo": [16, 19], "alguien": 24, "algun": 64, "alguna": [16, 18, 23], "alguno": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 64, 70], "alg\u00fan": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "alias_id": 41, "align": [24, 30, 52, 66], "alinear": 17, "all": [12, 13, 14, 20, 21, 25, 26, 28, 29, 33, 35, 37, 38, 45, 47, 48, 54, 56, 57, 58, 59, 61, 62, 64, 65, 67, 68, 69], "all_emb": 58, "all_sent": [57, 58, 64], "all_word": [57, 58, 64], "allow": [28, 30, 35, 42, 68], "almost": 39, "along": [44, 47, 64, 66], "alpha": [23, 24, 29, 30, 31, 32, 34, 36, 39, 42, 56, 62, 64], "alreadi": [37, 42, 56, 57, 58, 59, 64, 66, 67], "also": [21, 26, 28, 31, 32, 33, 40, 41, 42, 43, 44, 47, 48, 50, 53, 54, 56, 57, 61, 62, 63, 66, 67, 68], "alt": [63, 64, 66], "altern": [29, 54, 61, 63], "although": [32, 40, 54], "alto": 16, "alwai": [20, 31, 32, 35, 40], "am": 53, "amazon": 48, "amazonaw": [42, 44, 48, 49, 51, 53, 54], "amba": 23, "ambul": 50, "among": [34, 61, 66], "amount": [29, 64, 67], "amsgrad": [51, 57, 58], "an": [20, 25, 26, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 47, 49, 50, 53, 54, 55, 56, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69], "an_oper": 21, "anaconda": 23, "analitic_scor": 23, "analizamo": [18, 19], "analys": 67, "analysi": [19, 50, 58, 61, 64], "analyt": [31, 39], "analytic_scor": 23, "anal\u00edtica": [5, 18, 19], "anal\u00edticament": 23, "anc": 65, "anchor": [18, 52], "anchor_box": [45, 52], "anchor_index": 45, "andrej": 61, "andu": 65, "ani": [20, 21, 25, 27, 28, 32, 33, 37, 38, 39, 40, 42, 43, 44, 47, 53, 55, 57, 62, 66, 69], "anim": 69, "ankl": [25, 30], "ann": [29, 31], "ann1": 34, "ann2": 34, "annot": [45, 64], "anotado": [18, 24], "anoth": [28, 38, 39, 47, 63, 66], "anr": 65, "answer": [25, 38], "ant": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24, 65], "anterior": [12, 13, 14, 15, 16, 19, 23, 24], "anteriorment": 16, "anti_alias": 44, "antioquia": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "anywai": 54, "anywher": 49, "an\u00e1lisi": 19, "an\u00e1logo": 16, "aod": 65, "aparec": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "api": [16, 25, 30, 38, 42, 48, 54], "api_doc": 37, "aplazada": [12, 13, 14], "aplazamiento": [12, 13, 14], "aplicacion": [5, 16, 19], "aplicaci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "aplicar": 24, "apliqu": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "apoorv": 68, "appear": [20, 52, 64], "append": [23, 24, 28, 36, 40, 42, 53, 54, 56, 57, 58, 59, 62, 63, 64, 65, 67], "applewebkit": 64, "appli": [21, 25, 31, 38, 43, 47, 48, 49, 55, 57, 58, 64, 66, 67, 68], "applic": [18, 29, 48, 50, 52, 54, 61, 64, 69], "apply_autoencod": 26, "apply_gradi": [32, 40, 42, 66], "apply_model": 38, "approach": [31, 60, 61, 64, 65, 67], "appropri": [63, 68], "approx": [21, 53], "approxim": [39, 64, 67, 68], "apreciar": 18, "aprend": 18, "aprendido": 16, "aprendizaj": [15, 16, 18, 23, 24, 29], "aprovechen": 16, "aproximacion": 16, "aqui": 66, "aqu\u00ed": [6, 7, 8, 9, 10, 11, 24], "ar": [20, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68], "arang": [25, 29, 30, 39, 49, 56, 57, 60], "arcgi": 53, "architectur": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 27, 29, 32, 43, 46, 51, 52, 54, 56, 57, 58, 59, 62, 64, 66, 67, 68], "architectura": 18, "architecur": 56, "archiv": [66, 67], "arg": [36, 51, 69], "argmax": [25, 30, 34, 42, 48, 49, 51, 65, 66, 67, 69], "argmin": 23, "argsort": [33, 45, 50, 64], "argument": [21, 25, 26, 35, 36, 38, 40, 43, 44, 45, 47, 49, 55], "argwher": [27, 64], "ariasl": [1, 2, 3, 13, 14], "ariel": 67, "arithmet": 53, "aro": 65, "around": [25, 30, 36, 53, 54, 62, 67], "arounz": 36, "arquictectur": 30, "arquitectur": [29, 34, 59], "arquitectura": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 46], "arrai": [21, 23, 24, 25, 26, 27, 29, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 53, 55, 56, 59, 62, 63, 64, 65, 67, 68, 69], "arrang": 53, "arriv": 62, "arrow": 24, "art": 67, "articici": 15, "articl": 64, "article_text": 64, "artifact": 53, "artifici": 64, "artificial": 19, "artificial_intellig": 64, "artist": 66, "arxiv": [12, 13, 14, 64, 66], "asarrai": 65, "ascend": [52, 69], "ascii": [65, 66], "aseg\u00far": 70, "asimovinstitut": 22, "asociada": 18, "aspect": [32, 40], "aspecto": [16, 70], "assert": [37, 43], "assign": [30, 40, 41, 44, 57, 64, 67], "assign_sub": 40, "associ": [34, 43, 54, 64], "assum": [25, 29, 34, 37, 39, 43, 45, 47], "astyp": [25, 26, 27, 28, 32, 33, 37, 38, 40, 41, 42, 47, 49, 50, 52, 53, 54, 55, 61, 65], "asumimo": 24, "asumir": 15, "as\u00ed": [18, 19], "atenci\u00f3n": 19, "atrou": 18, "atr\u00e1": 19, "att": 68, "attach": [38, 40], "attack": 67, "attend": 68, "attent": [12, 13, 14, 19, 56, 58], "attention_lay": 66, "attention_plot": 66, "attention_result": 66, "attention_weight": 66, "attn_mechan": 66, "attn_model": 66, "attn_output": 68, "attribut": [32, 62], "aug": 12, "aumenta": 23, "aumentar": 18, "aunqu": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "author": 68, "auto": [19, 31], "autocar": 50, "autocorrecci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 70], "autocorrel": 60, "autoencod": [32, 53], "autograph": 41, "autom": 66, "automat": [20, 21, 40, 54], "autom\u00e1tica": 17, "autoregress": 60, "avail": [20, 30, 33, 40, 44, 45, 54, 64, 66], "aver": 42, "averag": [33, 62, 66], "averaged_perceptron_tagg": 67, "averaged_perceptron_tagger_eng": 67, "avg": 67, "avoid": [25, 29, 31, 37, 65], "awai": [36, 62], "await": [42, 48, 49, 51, 52, 54], "ax": [25, 29, 30, 33, 34, 45, 48, 51, 52, 57, 64, 66], "axesimag": [44, 47, 50, 52], "axhlin": [23, 24, 35, 52], "axi": [23, 25, 26, 27, 29, 30, 32, 33, 34, 42, 43, 44, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 62, 64, 66, 67, 69], "axvlin": [23, 24, 35, 52], "ayudan": 23, "ayudar": 18, "ayuh": 45, "a\u00f1adiendo": 24, "b": [21, 27, 29, 30, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 57, 60, 61, 62, 64, 65, 66, 67, 68, 69], "b1": 42, "b2": 42, "b7": 44, "b_2": 37, "b_d": 26, "b_e": 26, "b_h": 45, "b_l": 62, "b_w": 45, "b_x": 45, "b_y": 45, "back": [35, 56, 61, 65, 66, 67], "backbon": 18, "backend": [25, 33, 34, 35, 36, 48, 54, 61, 64], "background": 46, "backpack": 50, "backpropag": [16, 19, 35], "backward": [29, 35, 66], "bad": [29, 31], "bag": [25, 30], "bahdanau": 66, "bahdanauattent": 66, "balanc": [27, 58], "balance_beam": 52, "banjo": 66, "bar": [52, 57], "barh": 30, "barn": 50, "barrel": 67, "basada": [18, 19], "basado": 18, "base": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 23, 25, 29, 42, 48, 54, 56, 59, 61, 62, 66, 67, 68], "baselin": 31, "baseline_model": [1, 2], "bash": 54, "basic": [29, 30, 46, 57, 61, 62, 64], "batch": [16, 54, 63, 65, 66, 67], "batch_input_shap": 65, "batch_loss": 66, "batch_shap": [36, 51], "batch_siz": [25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 40, 42, 44, 48, 49, 51, 53, 54, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68], "batch_sz": 66, "batchnorm": 38, "batchsiz": 63, "bay": 23, "bayesiana": 23, "bbox": 45, "bbox_to_anchor": [23, 24, 28, 57, 62], "bd": [19, 26], "bd_model": 66, "beach_wagon": 50, "beautifulsoup": 64, "becaus": [29, 36, 38, 54, 57, 63, 66, 67], "becom": [29, 31, 35, 47], "been": [30, 40, 42, 63, 66, 67], "beerensahu": 54, "befor": [22, 25, 28, 29, 30, 31, 32, 33, 36, 42, 48, 57, 62, 66, 67, 69], "beforhand": 66, "begin": [20, 24, 29, 36, 39, 65, 67], "behavior": [26, 29, 31], "behind": [31, 66], "being": [25, 27, 28, 30, 31, 37, 41, 42, 52, 65, 67, 69], "believ": 54, "bell_cot": 50, "bellair": 50, "belong": [27, 30], "below": [20, 25, 34, 37, 38, 43, 45, 52, 54, 64, 65, 68], "benchmark": 50, "bengio": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 66], "bergmeir": 60, "bert": [19, 67], "bert_en_uncased_l": 58, "bert_en_uncased_preprocess": 58, "bert_lay": 58, "bert_preprocess_model": 58, "besid": 52, "best": [54, 57, 63, 67], "best_model": [1, 2], "beta": [26, 38, 42, 62, 70], "beta1": 62, "beta2": 62, "beta_1": [51, 57, 58], "beta_2": [51, 57, 58], "better": [30, 31, 33, 52, 54, 62, 64, 65, 66], "between": [25, 29, 44, 45, 50, 54, 57, 60, 62, 64, 66, 67, 68], "bevsedn": 65, "bewar": [39, 40], "beyond": 62, "bf": [25, 29, 30, 31, 61, 62, 64, 68], "bfg": [21, 24, 39], "bh": 45, "bi": 48, "bia": [26, 34, 37, 40, 42, 47, 61, 62], "bias": 37, "bias_constraint": [36, 51], "bias_initi": [36, 51], "bias_regular": [36, 51], "bibl": 65, "bibp0mkbnk82jauk1jfww6": [6, 7, 8, 9, 10, 11, 12, 13, 14], "bidi_model": 66, "bidireccional": 19, "bidirect": [19, 67, 68], "bidirection": 68, "bidirectional_1": 66, "bienvenido": 70, "big": [21, 26, 33, 66], "bigg": [21, 37], "biggest": 67, "bilingu": 66, "bilm": 67, "bilm1": 67, "bilm2": 67, "bilou": 67, "bilsn": 65, "bilstm": 67, "bin": [25, 33, 36, 52, 67], "binari": [25, 27, 30, 42, 48, 49, 51, 64, 69], "binary_accuraci": 37, "binary_crossentropi": [30, 46, 54, 57, 58, 59, 63], "binder": 20, "bio": 67, "bioinspir": 29, "biolog": 29, "biol\u00f3gico": 16, "biomed": 54, "bit": [26, 30, 54, 62, 63], "bivs": 65, "bjlkeng": 40, "black": [23, 24, 35, 45, 46, 52], "blanco": 24, "bleu": 66, "blit": 69, "block": [46, 58], "block1_conv1": 50, "block1_conv2": 50, "block1_pool": 50, "block2_conv1": 50, "block2_conv2": 50, "block2_pool": 50, "block3_conv1": 50, "block3_conv2": 50, "block3_conv3": 50, "block3_pool": 50, "block4_conv1": 50, "block4_conv2": 50, "block4_conv3": 50, "block4_pool": 50, "block5_conv1": 50, "block5_conv2": 50, "block5_conv3": 50, "block5_pool": 50, "blog": [48, 52, 54, 68], "blood": 67, "blue": [23, 24, 25, 28, 30, 37, 47, 62], "blur": 47, "bmatrix": [24, 39], "bn": [38, 42], "bnn": 29, "bo": 31, "boathous": 50, "boe": 65, "boi": 66, "boit": 65, "bome": 65, "book": [20, 66], "bool": 54, "boot": [25, 30], "border": 47, "borderaxespad": 62, "borrow": 66, "bot": 48, "both": [20, 25, 27, 28, 29, 31, 32, 34, 37, 40, 42, 47, 52, 54, 67], "bottom": 69, "boud": 45, "bound": [31, 52], "boundari": [23, 31], "bowl": [46, 54], "box": [18, 52, 67], "boxabl": 52, "bptt": 19, "break": [59, 64], "breaststrok": 59, "brevement": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 70], "british": 67, "broadcast": [21, 66], "browser": 48, "bs2dfrhh3odevm1dycvwugrc1hpe6jdgh": 45, "bs4": 64, "bu": 54, "buen": 18, "buena": 23, "buffer_s": 66, "build": [12, 13, 14, 27, 34, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 55, 56, 63], "build_config": [36, 51], "build_image_pair": 27, "build_logisitic_regression_cost_express": 39, "built": [29, 34, 38, 40, 49, 54], "builtin": 51, "busca": 24, "butth": 65, "bvc": 23, "bw": 45, "bx": 45, "byte": 51, "bz2": 51, "bz2file": 51, "b\u00e1sica": 18, "b\u00e1sico": 19, "c": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 25, 26, 27, 29, 30, 43, 47, 51, 52, 54, 55, 60, 61, 62, 64, 65, 66, 67], "c1": [39, 46, 47, 53, 54, 55], "c1_conv1": 46, "c1_conv2": 46, "c1_dropout": 46, "c1_maxpool": 46, "c2": [46, 47, 54], "c2_conv1": 46, "c2_conv2": 46, "c2_dropout": 46, "c2_maxpool": 46, "c3": 54, "c4": 54, "c5": 54, "c6": 54, "c7": 54, "c8": 54, "c9": 54, "c_": [62, 66], "c_j": [25, 30], "c_l": 62, "c_m": 53, "c_x": 45, "c_y": 45, "ca": [64, 65], "cab": 50, "cach": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "cache_s": 23, "cada": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 23], "cafe": 66, "cai": 65, "calcul": [20, 29, 35, 61, 62, 64, 66, 68], "calcula": 23, "calculado": 23, "calculamo": 18, "calculan": 23, "calcular": [23, 24], "calibrar": [15, 23], "calificaci\u00f3n": [6, 7, 8, 9, 10, 11, 12, 13, 14], "calin": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "call": [26, 27, 29, 30, 31, 32, 34, 38, 40, 41, 42, 54, 58, 62, 63, 64, 65, 66, 67, 68], "callabl": 30, "callback": [16, 24, 30, 31, 33, 34, 35, 36, 37, 40, 48, 51, 53, 54, 62, 63, 65, 66, 67, 69], "cambia": 23, "cambio": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "cambridg": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "came": 22, "camino": [15, 18, 24], "camp": 65, "campa\u00f1a": 18, "campelitt": 65, "campo": [15, 18], "camt": 65, "can": [20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68], "canal": 18, "candid": [62, 66], "cannot": [26, 31, 38, 43, 46], "canva": 29, "canwereallyk": 44, "cap": [54, 59], "capa": [16, 17, 18, 19], "capabl": [29, 31, 64], "capac": [56, 62], "capacidad": [17, 23], "capaz": 23, "caption": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 48, 61], "captuarar": 23, "captur": [31, 41, 55, 62, 64, 65], "capturar": 23, "car": [47, 50], "caract": 19, "care": [40, 47, 57], "carefulli": [28, 36], "cargar": 19, "carpeta": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "carri": [29, 40], "carton": 52, "case": [21, 25, 26, 28, 29, 30, 31, 33, 34, 42, 45, 47, 53, 56, 57, 58, 59, 62, 64, 67, 68], "caso": [1, 2, 16, 23, 24], "cast": [32, 66], "cat": 44, "categor": [25, 30], "categori": [30, 54, 66], "categorical_crossentropi": [25, 28, 30, 34, 35, 36, 42, 64, 65, 69], "cativ": 52, "cattht": 65, "caught": 64, "caus": [25, 31], "cb": 28, "cbow": 64, "cbs_test": 28, "cbs_train": 28, "cbset": 28, "cc1": 34, "cdbk6t8wcifvhycw": 45, "cdf": 23, "cdn": 44, "cdot": [24, 29, 31, 35, 37, 39, 61, 67], "celda": 23, "cell": [20, 25, 28, 37, 38, 43, 45, 48, 52, 54, 56, 57, 58, 59, 62, 67, 69], "cells_numb": 57, "center": [23, 24, 25, 28, 30, 45, 48, 51, 52, 64], "central": [17, 66], "centro": 23, "cerca": 23, "cercano": 23, "certain": [28, 35], "certainli": 54, "certif": 59, "certificado": 5, "ch": 67, "chain": [29, 54], "chained_assign": [57, 58], "challeng": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 21, 38, 50, 51], "chang": [29, 31, 32, 41, 42, 54, 67], "channel": [43, 46, 47, 49, 52, 67, 69], "channels_last": 51, "char": [65, 67], "char2idx": 67, "char_emb": 67, "char_emb_dim": 67, "char_embed": 67, "char_encod": 67, "char_len": 67, "char_to_int": 65, "charact": [64, 65, 67], "charcnnembedd": 67, "chars_idx": 67, "chart": 35, "charu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "chat": [6, 7, 8, 9, 10, 11, 12, 13, 14], "check": [25, 26, 28, 32, 36, 37, 38, 43, 44, 45, 51, 52, 54, 59, 62], "checkerboard": 53, "checkpoint": [54, 66], "checkpoint_dir": 66, "checkpoint_prefix": 66, "checkpointloadstatu": 66, "children": 65, "chmod": 54, "cho": 66, "choic": [27, 28, 32, 34, 63], "choos": [20, 28, 68], "chosen": [33, 57, 62], "chrome": 64, "chunk": 67, "church": 50, "ci": 54, "ciecnia": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ciego": 23, "ciencia": [5, 23], "cierr": [2, 6, 7, 8, 9, 10, 11, 12, 13, 14], "cifar": [18, 42, 44, 48, 53], "cil": 65, "cimg": [47, 55], "circunstancia": 17, "cire": 65, "cite": 67, "citycar": 50, "ckpt": 66, "cl": [39, 58], "claim": [66, 68], "claridad": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "clarifai": 48, "clase": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 23, 26, 27, 28, 33, 34, 35, 36], "clasificaci\u00f3n": [15, 16, 18, 19], "clasificac\u00f3n": 23, "clasificar": 19, "class": [25, 26, 28, 29, 30, 31, 32, 33, 34, 37, 38, 42, 44, 48, 49, 51, 52, 57, 58, 59, 60, 63, 65, 66, 67, 68, 69], "class_nam": [36, 51], "class_video": 59, "class_weight": [23, 57, 58], "class_weight_vect": 58, "classic": [44, 52, 61], "classif": [16, 19, 29, 30, 33, 37, 50, 51, 64, 68], "classifc": 59, "classifi": [52, 59, 63], "classification_report": [59, 67], "classnam": 52, "clea": 64, "clean": 66, "clear_sess": [34, 35, 36, 48, 61], "clf": 31, "clf1": 29, "clf2": 29, "clf3": 29, "clinic": 34, "clip": 25, "clip_by_valu": 25, "clipnorm": 51, "clipvalu": 51, "close": [25, 26, 42, 44, 48, 62, 67], "closer": 66, "cloth": 30, "cloud": 48, "clsm": 65, "cluster": [18, 29, 45], "cl\u00e1sica": 24, "cm": [24, 25, 26, 27, 28, 30, 33, 34, 42, 43, 47, 48, 53, 54, 55], "cmap": [24, 25, 26, 27, 29, 30, 33, 34, 43, 47, 48, 53, 54, 55, 66], "cnn": [18, 48, 52, 53, 57, 67, 68], "cnn_featur": 48, "cnn_feature_hierarchi": 22, "cnn_features2": 48, "cnn_swan": 48, "cntnre": 65, "co": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 38, 39, 50, 58, 64, 70], "coat": [25, 30, 52], "coddd": 65, "code": [12, 13, 14, 20, 21, 25, 26, 27, 28, 32, 34, 37, 38, 40, 43, 44, 45, 46, 52, 56, 63, 64], "code_s": [26, 33], "codifi": 64, "codificador": 19, "coef0": 23, "coef_": [24, 31, 32, 40], "coffe": 66, "coincid": 27, "colab": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 20, 37, 38, 43, 44, 48, 54, 56, 57, 58, 59, 60, 70], "colah": 62, "cold": 66, "colecci\u00f3n": 23, "collaps": 67, "collect": [37, 52], "color": [23, 24, 25, 28, 30, 35, 37, 42, 45, 46, 47, 52, 57, 62], "colorado": 64, "colorbar": [24, 25, 30, 33, 53], "column": [24, 26, 27, 39, 40, 45, 52, 56, 57, 58, 63, 64, 67, 69], "columna": [23, 24], "com": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "combin": [29, 31, 38, 47, 62], "combinaci\u00f3n": 24, "comentario": 70, "comment": 20, "commit": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 31], "common": [29, 54, 64, 65], "commonli": 67, "como": [12, 13, 14, 16, 17, 18, 19, 23, 66], "compacta": 24, "compar": [25, 35, 43, 48, 50, 51, 58, 64, 66], "comparison": [64, 67], "compartida": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "compat": [64, 67], "competencia": 18, "competici\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "competit": 54, "compil": [25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 46, 48, 49, 51, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "compile_config": 51, "compile_metr": [48, 51, 54], "compleci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "complej": 64, "complejidad": [15, 24], "complejo": 64, "complementari": 53, "complementario": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "complet": [20, 21, 25, 26, 37, 38, 43, 44, 45, 57, 62], "completar": 5, "completo": 5, "complex": [29, 30, 31, 67, 68], "compli": 25, "complic": 35, "compon": [33, 59, 66, 68], "component": [17, 18], "compos": [56, 63, 69], "composit": 65, "comprehens": [12, 13, 14, 33], "compress": [26, 27, 28, 33, 34, 35, 36, 56, 68], "comprobamo": 16, "compuesta": 16, "comput": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 21, 25, 26, 27, 28, 31, 32, 35, 37, 42, 44, 49, 53, 54, 57, 60, 64, 66, 67], "computacion": 17, "computacional": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19], "computation": 65, "compute_class_weight": [57, 58], "compute_nb_weight": 43, "comun": [18, 19], "con": [5, 15, 16, 18, 19, 24, 46, 47, 48, 56], "con1d_model_tf": 57, "concat": [27, 34, 62, 66, 67], "concaten": [27, 29, 33, 34, 35, 36, 46, 54, 66, 68, 69], "concatenate_1": 54, "concatenate_2": 54, "concatenate_3": 54, "concatenate_imag": 54, "concentr": 36, "concept": 68, "concepto": [16, 18], "concret": [39, 40], "concretefunct": 41, "concreto": 23, "condit": 31, "conect": 68, "conext": 66, "confer": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 40], "confid": 52, "config": [36, 51, 69], "configur": [20, 36, 37, 46, 61, 63], "configuracion": [19, 23], "confind": 56, "confirm": 59, "conform": 53, "conformando": 18, "conformar": 18, "confus": [25, 27, 30, 48, 51], "confusion_matrix": [25, 30], "conjointli": 31, "conjunto": [18, 24], "connect": [27, 30, 34, 42, 48, 49, 51, 52, 54, 67], "conoc": 24, "conocemo": 23, "conocida": [19, 23], "conocido": 19, "conocimiento": 23, "consecut": 68, "consenso": [6, 7, 8, 9, 10, 11, 12, 13, 14], "consensuado": [6, 7, 8, 9, 10, 11, 12, 13, 14], "consid": [47, 54, 61, 66, 68], "consider": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "considerar\u00e1": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "consist": [19, 57], "consolid": 35, "consolidar": 18, "constant": [29, 32, 35, 41, 42, 54, 67, 69], "constar": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "constituyen": 18, "constrict": 31, "construcci\u00f3n": [16, 17, 18], "construct": [37, 46], "constructor": [30, 37], "construir": [16, 18, 19], "construy": 18, "construyen": 17, "consultado": 19, "contain": [0, 20, 27, 28, 32, 34, 37, 38, 40, 43, 44, 45, 52, 59, 61, 62], "contan": 64, "contar": 24, "contect": 61, "content": [0, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "context": [64, 67, 68], "context_vector": 66, "contexto": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19], "contextu": [64, 67], "contextualizamo": 15, "contigo": [1, 2], "continu": [26, 31, 64], "continua": 5, "contourf": 24, "contrari": 62, "contribut": [29, 66], "contribuy": 17, "control": [20, 34, 62], "controlamo": 17, "controlling_retrac": 37, "cont\u00f3": 24, "conv": [43, 47, 55, 67], "conv1": [48, 51], "conv1d": [57, 67], "conv2": [48, 51], "conv2d": [43, 46, 47, 48, 49, 50, 51, 53, 54, 55, 69], "conv2d_1": [46, 48, 49, 54], "conv2d_10": [46, 54], "conv2d_11": [46, 54], "conv2d_12": [46, 54], "conv2d_13": [46, 54], "conv2d_14": [46, 54], "conv2d_15": [46, 54], "conv2d_16": [46, 54], "conv2d_17": [46, 54], "conv2d_18": [46, 54], "conv2d_2": [46, 49, 51, 54], "conv2d_3": [46, 49, 51, 54], "conv2d_4": [46, 51, 53, 54], "conv2d_5": [46, 51, 54], "conv2d_6": [46, 53, 54], "conv2d_7": [46, 54], "conv2d_8": [46, 54], "conv2d_9": [46, 54], "conv2d_transpos": [46, 54], "conv2d_transpose_1": [46, 54], "conv2d_transpose_2": [46, 54], "conv2d_transpose_3": [46, 54], "conv2d_transpose_4": 53, "conv2d_transpose_5": 53, "conv2dtr": 46, "conv2dtran": 46, "conv2dtranspos": [46, 53, 54], "conv_1x1": 46, "conv_lstm2d": 69, "conv_lstm2d_1": 69, "conv_lstm2d_2": 69, "conv_out": 67, "conveni": 54, "convent": [20, 62, 67], "converg": [23, 29], "convergencia": [16, 23], "convers": 69, "conversionopt": 41, "convert": [25, 30, 34, 44, 47, 53, 65, 66, 69], "convert_to_tensor": 66, "converted_cal": 41, "convex": 29, "convlstm": [19, 69], "convlstm2d": 69, "convolucion": [5, 18], "convoluci\u00f3n": 18, "convolut": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 40, 42, 46, 50, 52, 54, 59, 67], "convolution_byhand": 43, "convolv": 47, "convolve2d": 47, "cooki": 59, "coordin": [45, 52], "copi": [20, 37, 48, 52, 53, 55, 62, 63, 65], "copia": [6, 7, 8, 9, 10, 11, 12, 13, 14], "copos": 56, "core": [30, 35, 36, 40, 61], "corn": 65, "corner": [43, 45, 52, 69], "corpora": [64, 65], "corpu": [57, 58, 64, 65, 66, 67, 68], "corrctli": 20, "correct": [27, 31, 45, 50, 54, 62, 66, 67], "correctament": 66, "correctli": [31, 56, 57, 63, 66], "correl": 66, "correo": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "correspond": [25, 26, 27, 29, 31, 38, 40, 43, 44, 45, 46, 55, 57, 58, 61, 64, 66], "cosa": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "cost": [24, 29, 35, 37, 39, 64], "costli": 52, "costo": [17, 18], "costoso": 24, "could": [29, 32, 34, 37, 42, 55, 62, 64, 65, 66], "count": [21, 38, 48, 51, 52], "count_matrix": 64, "count_vector": 64, "counter": 63, "countri": 67, "countterminosdeinter": 64, "countvector": 64, "cours": [0, 20, 26, 27, 33, 46, 47, 48, 50, 58], "course_id": [21, 25, 26, 27, 28, 34, 35, 37, 38, 40, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 56, 57, 58, 59], "coursera": 66, "courvil": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "cov": 23, "cov0": 23, "cov1": 23, "covari": [17, 23], "covarianza": 23, "cover": 68, "covert": 65, "cpacidad": 19, "cpu": [29, 64], "craft": 47, "crea": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "creaci\u00f3n": 19, "crear": [17, 18], "crear\u00e1": [16, 18], "creat": [25, 26, 27, 28, 29, 30, 37, 38, 41, 46, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 67, 68, 69], "create_dataset": [56, 61, 62, 66], "create_datasetmultipletimesbackahead": 61, "create_datasetmv": 56, "create_datasetmv_multipletim": 56, "create_datasetmv_timesahead": 56, "create_model": 44, "creedrgn": 65, "creemo": 24, "criterion": [29, 31], "crop_center_squar": 59, "cross": [16, 25, 30, 56, 60], "cross_val_scor": 44, "crossentropi": 29, "crowdflow": 57, "cruzada": 19, "cs231n": 42, "cshc": 4, "csimg": 55, "csv": [20, 24, 26, 27, 28, 32, 33, 34, 35, 36, 39, 40, 45, 52, 56, 57, 58, 59, 60, 61, 62, 67], "ct": 53, "cuadrado": 24, "cuadr\u00e1tica": [15, 23], "cuadr\u00e1tico": 24, "cual": [15, 16, 18, 19], "cualquier": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 23], "cualquiera": 24, "cuando": [15, 23, 24], "cuanto": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24], "cuda": 54, "cuenta": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23], "cumul": 62, "cuonh": 65, "curat": 52, "curios": 53, "current": [54, 64, 65, 66, 67], "current_idx": 65, "curso": 5, "curva": [15, 23], "curvatur": 68, "custom": [16, 17, 20, 26, 32, 42], "custom_callback": 28, "custom_layers_and_model": 40, "custom_loss": [32, 37], "custom_model_2": 40, "customizing_what_happens_in_fit": 40, "custommodel": [32, 40], "cu\u00e1l": 23, "cu\u00e1nto": 24, "cv2": 59, "cxo5qmn4nkuzhg3huwuewf": 45, "c\u00e1lculo": [17, 18], "c\u00f3digo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 23, 70], "c\u00f3mo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 70], "d": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24, 26, 27, 29, 31, 32, 33, 39, 40, 43, 45, 47, 49, 54, 56, 64, 65, 66], "d0": 39, "d1": [23, 39], "d2": 23, "d_e": 58, "dada": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "dai": [56, 65, 67], "dam": 53, "damo": 16, "dar": 64, "dark": 65, "darl": 16, "darrel": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "data": [1, 2, 20, 22, 24, 25, 26, 27, 29, 30, 31, 32, 34, 37, 38, 39, 40, 41, 42, 44, 46, 49, 50, 51, 52, 56, 57, 58, 61, 62, 63, 64, 65, 67, 68, 69], "data_format": 51, "data_gener": 65, "databas": 64, "datafram": [27, 45, 52], "datai": [56, 65], "datal": 18, "dataprepar": 56, "datapreparation_timesahead": 56, "datapreparationrnn": [56, 57, 58, 60, 61, 62], "datas": 66, "dataset": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 24, 25, 27, 28, 30, 31, 33, 37, 40, 41, 42, 44, 45, 49, 50, 52, 54, 56, 58, 59, 61, 62, 63, 64, 68, 69], "dataset1": [60, 61], "dataset_s": 23, "dataset_tot": 62, "dataseto": [60, 61], "datax": [56, 65], "date": [56, 60, 62, 64, 67], "date_pars": 56, "datetim": 56, "dato": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 56], "dc8dbc1fad39": 66, "ddkernel": 55, "de": [5, 17, 20, 26, 27, 28, 33, 34, 35, 36, 46, 48, 52, 64, 66, 70], "deal": [29, 32, 40, 66], "debe": [19, 66], "deben": 19, "deber\u00e0": [8, 9, 10, 11, 12, 13, 14], "deber\u00e1": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "deber\u00eda": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "debido": 24, "debuggercaf": 54, "dec_hidden": 66, "dec_input": 66, "dec_unit": 66, "decai": [25, 30, 35], "decent": 54, "decid": [52, 62], "decidimo": 24, "decim": [21, 25, 26, 27, 30], "decir": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23], "decis": [52, 62, 64], "decision_function_shap": 23, "decisiontreeclassifi": 23, "declar": [58, 67], "decod": [19, 26, 33, 50, 52, 53, 56, 68], "decode_predict": [50, 52], "decoder_weight": 26, "decodificador": 19, "decompos": 64, "deconvolut": 53, "decor": 40, "decreas": [31, 35], "deep": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 19, 22, 42, 48, 50, 51, 53, 54, 65, 66, 67, 68, 70], "deepdreamgener": 48, "deeper": 68, "deeplab": [53, 54], "deeplabv3": 53, "deeplap": 18, "deeplearn": [0, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "def": [21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69], "default": [26, 30, 37, 38, 40, 43, 48, 49, 54, 56, 57, 58, 59, 67], "defin": [20, 24, 25, 26, 27, 29, 32, 33, 37, 40, 45, 52, 56, 57, 58, 59, 62, 63, 64, 65, 66, 68], "definegrad": 20, "definiendo": 18, "definir": 24, "definit": [21, 30, 53, 54, 67], "degre": [23, 31], "del": [5, 15, 16, 17, 18, 19, 23, 30], "delimit": 31, "delta": [32, 68], "delta_": 29, "demand": 67, "demo": 48, "demonstr": 67, "demostramo": 18, "dem\u00e1": [6, 7, 8, 9, 10, 11, 12, 13, 14], "denois": 16, "denot": [37, 68], "dens": [25, 26, 27, 30, 32, 33, 34, 36, 38, 40, 41, 43, 44, 46, 48, 49, 50, 51, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69], "densa": [18, 19], "dense1": [30, 32, 34, 58], "dense1000": 46, "dense1000_dropout": 46, "dense2": [30, 34, 58], "dense3": [30, 34], "dense_1": [34, 44, 49, 51, 62, 69], "dense_10": 30, "dense_128x128": 46, "dense_128x128x3": 46, "dense_2": [30, 34, 49, 51, 61, 62, 69], "dense_3": [30, 34, 40, 49, 61], "dense_308": 25, "dense_309": 25, "dense_310": 25, "dense_311": 25, "dense_312": 25, "dense_3_1": 41, "dense_4": [30, 49, 64], "dense_4_1": 41, "dense_5": 49, "dense_6": [49, 61], "dense_7": [49, 61], "dense_8": [30, 49], "dense_9": [30, 61], "dense_s": 44, "dense_shap": 43, "denser1": 41, "denser2": 41, "densidad": [23, 24], "densidad_escama": [24, 32, 39, 40], "densiti": 36, "dentro": [1, 2, 12, 13, 14, 18, 19], "depend": [19, 24, 29, 31, 32, 38, 42, 46, 58, 61, 62, 67, 68], "depict": 27, "deprec": 69, "deprecationwarn": 69, "depth": 68, "deriv": [29, 31, 35, 38, 39, 40], "derivaci\u00f3n": 24, "derivada": 24, "desarrollamo": [16, 17, 23], "desarrollando": 16, "desarrollar": 19, "descarga": 70, "descartado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "descend": [61, 69], "descendient": 15, "descent": 29, "describ": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 26, 27, 37, 44, 59], "describimo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 70], "describir": 19, "descripci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "descript": [45, 52], "desd": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 23], "desean": 19, "desempe\u00f1o": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23], "design": [29, 61, 63, 64], "desir": [31, 37, 38, 66], "desmitificamo": 15, "despit": 30, "despu\u00e9": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23], "desvanecient": 16, "detail": [37, 46, 52, 54, 55, 67, 68], "detal": 15, "detallamo": 18, "detect": 47, "detectiond": 52, "detector": 18, "determin": [29, 62], "determinamo": 23, "determinar": 24, "detr\u00e1": [17, 23], "dev": [39, 41, 44, 52, 54, 58, 67], "develop": [0, 20, 22, 31, 53], "deviat": [28, 42], "devis": 52, "dew": 56, "df": 39, "df_t": 64, "di": 65, "diabet": 31, "diag": [61, 62], "diagn\u00f3stico": 15, "dic": [2, 4, 12, 14], "diciendo": 66, "dict": [44, 64, 65], "dict_kei": 40, "dictionari": [27, 43, 44, 57, 58, 64, 67], "did": [51, 54, 65], "diferencia": 23, "diferent": 19, "diff": 39, "differ": [20, 25, 26, 27, 28, 29, 30, 33, 35, 37, 41, 42, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 66, 67, 68, 69], "differenti": [29, 39, 40, 60, 67], "difficult": [31, 47, 63], "dificultad": 18, "digit": 33, "dilat": [53, 55], "dilation_r": [51, 55], "dilut": 55, "dim": [44, 67], "dimens": [26, 27, 28, 33, 34, 35, 36, 38, 43, 44, 52, 53, 56, 57, 58, 67], "dimension": [18, 23, 33, 40], "dimensionalidad": 18, "dinos3": 65, "dire": 59, "direccionesd": 3, "direcct": 47, "direct": [29, 47, 68], "directament": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "directli": [30, 32, 40, 62, 67, 69], "dirnam": 66, "dirti": 54, "discard": 57, "disco": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "discov": 67, "discret": 47, "discrimin": 64, "discriminativo": 24, "discutimo": [18, 19], "dise\u00f1ado": 23, "dise\u00f1ador": 23, "dise\u00f1ar": [15, 19], "dise\u00f1o": 15, "disitribuci\u00f3n": 23, "disk": 65, "disminuy": 23, "disp": 54, "displai": [20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 35, 36, 39, 40, 45, 46, 48, 52, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "display_img": [48, 51], "dispon": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19], "dispuesto": 66, "dist": [33, 35, 36, 40, 49, 50], "distanc": 64, "distance_matrix": 64, "distinta": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 23], "distinto": [12, 13, 14, 17, 18, 23], "distribucion": [15, 17, 23], "distribuci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "distribut": [26, 27, 35, 42, 48, 51, 65], "dive": 59, "diverg": 62, "divergencia": 23, "diversa": 19, "divid": [42, 44, 64, 65], "dividir": 23, "divis": 31, "dkernel": 53, "dl": [19, 56, 58, 59], "dl_timelin": 22, "do": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 22, 23, 25, 27, 28, 29, 33, 35, 36, 38, 39, 40, 43, 44, 47, 49, 50, 52, 54, 55, 56, 62, 63, 65, 66, 70], "do_return": 41, "do_someth": 20, "doc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "document": [57, 66, 67], "document_count": 67, "documento": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "doe": [20, 21, 32, 46, 57, 62, 63], "doesn": [33, 36, 50], "dog": 66, "domain": [65, 68], "donahu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "dond": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 23], "done": [38, 42, 54, 55, 60, 65], "dorrt": 65, "dot": [24, 28, 29, 37, 38, 39, 43, 52, 53, 66, 68], "dot_alpha": 23, "dota": 19, "dots_alpha": 23, "doubl": [28, 38], "down": [59, 61], "downgrad": [37, 38, 43, 48, 56, 57, 58, 59], "downgrade_tf_vers": [56, 57, 58, 59], "download": [44, 45, 50, 52, 57, 58, 59, 64, 65, 66, 68], "downsampl": [52, 54], "downsiz": 53, "downstream": 67, "dp1": 64, "dpi": 62, "dr": 65, "draft": 67, "draw": [29, 39, 54, 68], "drawback": [62, 67, 68], "drelu": 35, "dress": [25, 30], "drive": [47, 50, 59], "driver": 54, "drop": [30, 49, 56, 57, 58, 67], "drop1": 58, "drop_remaind": 66, "dropout": [18, 26, 30, 33, 34, 35, 36, 42, 46, 48, 51, 54, 57, 58, 59, 61, 62, 65, 66, 67, 68], "dropout1": 68, "dropout2": 68, "dropout_1": [46, 49, 54, 62], "dropout_2": [46, 49, 51, 54, 62], "dropout_3": [46, 49, 51, 54], "dropout_4": [46, 51, 54], "dropout_5": [46, 49, 51, 54], "dropout_6": [46, 49, 54], "dropout_7": [46, 54], "dropout_8": [46, 54], "droput": 58, "drown": 68, "dsbowl2018": 54, "dsigm": 35, "dsolv": 39, "dt": 39, "dtanh": 35, "dtrue": 27, "dtype": [32, 33, 36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 64, 65, 66, 67, 68], "dtypepolici": [36, 51], "due": [25, 31, 32, 37], "dump": 57, "durant": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 70], "dure": [29, 31, 32, 33, 36, 43, 49, 56, 57, 58, 62, 64, 65, 66, 67, 68], "dx": 53, "dy": 53, "dydt": 39, "dynam": 65, "dzmitri": 66, "d\u00eda": [6, 7, 8, 9, 10, 11, 12, 13, 14, 18], "e": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 24, 26, 31, 33, 35, 37, 44, 52, 53, 54, 56, 57, 58, 59, 64, 65, 66, 67, 68, 70], "each": [20, 21, 25, 27, 28, 29, 30, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 52, 53, 56, 58, 62, 63, 64, 66, 67, 68, 69], "eager": [33, 40, 41], "eagerli": 41, "eanah": 65, "earli": [16, 54], "earlier": 52, "earlystop": [31, 54], "earlystopp": 54, "earth": 65, "easi": 64, "easier": 68, "easili": [29, 30], "eat": 67, "eayt": 65, "ec": 24, "ecc": 54, "econom": 64, "eda": 66, "edg": 47, "edgecolor": [45, 52], "edici\u00f3n": 29, "edu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 51, 64, 70], "edyaa": 65, "eeaem": 65, "efecto": [16, 18], "effect": [25, 43, 47], "efficientnet": 44, "eficacia": 18, "eficiencia": 17, "eficient": 24, "efter": 65, "eg": 66, "egg": 67, "egyptian": 44, "ei": 27, "either": 41, "eitherwai": 31, "ej": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 23, 24], "ejecuci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 70], "ejecut": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ejecuta": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23], "ejecutado": 19, "ejecutars": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ejecutivo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ejec\u00fatalo": 24, "ejempl": 64, "ejemplo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 48, 64], "ejercicio": [15, 19, 20], "el": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 23, 66, 70], "elaps": [23, 40, 42, 54], "elegir": 24, "element": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 21, 26, 28, 37, 42, 43, 44, 47, 69], "elemento": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19], "eliminaci\u00f3n": 16, "ello": [19, 70], "elman": 61, "elmo": 19, "els": [27, 35, 47, 54, 67], "elu": [54, 68], "em": 66, "ema_momentum": 51, "ema_overwrite_frequ": 51, "emb": [44, 58, 67], "embeb_dim": 57, "embebimiento": 19, "embed": [19, 57, 58, 66, 68], "embed_dim": [57, 58, 68], "embed_model": 66, "embed_s": 64, "embedd": 67, "embedding_1": 66, "embedding_2": 66, "embedding_5": 64, "embedding_8": 64, "embedding_dim": 66, "embedding_lay": 68, "embeded_model": 66, "empezar": [15, 18], "empleado": 19, "empti": [54, 67], "empty_lik": 56, "emul": 29, "en": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 64, 66, 70], "en_sent": 66, "enc_hidden": 66, "enc_out": 66, "enc_output": 66, "enc_unit": 66, "encdec_model": 66, "encod": [19, 26, 34, 51, 53, 54, 57, 58, 64, 65, 67, 68], "encodeco_model": 66, "encoded_doc": 67, "encontrar": 23, "encount": 64, "end": [20, 24, 28, 29, 39, 42, 46, 56, 62, 66, 68], "endpoint": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "enfoca": 23, "enfocart": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "eng": 66, "eng_extract": 66, "engin": [60, 61], "english": [57, 58, 64, 66], "english_vocab_s": 66, "enlac": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19], "enlanc": 9, "ensamblamo": 16, "ensamblando": 18, "ensamblar": 18, "ensembl": 23, "ensur": [20, 25, 44, 64, 69], "entend": [15, 17, 23, 24], "entendimiento": 18, "enter": 36, "entiend": 23, "entir": [29, 65, 66, 67], "entiti": 61, "entonc": 24, "entorno": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "entr": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 23, 24], "entrada": [16, 17, 18, 19, 24], "entreg": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "entrega": 5, "entrega1": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "entregado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "entregar": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "entrenada": 19, "entrenado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19], "entrenamiento": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], "entrenar": [16, 18], "entropi": [16, 25, 30], "enumer": [26, 28, 33, 36, 42, 52, 54, 56, 57, 63, 64, 65, 66, 67], "environ": [20, 37, 54], "environment": 56, "env\u00edo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "epoch": [25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 40, 42, 44, 48, 49, 51, 53, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "epsilon": [23, 25, 38, 42, 51, 58, 68], "eq": 39, "equal": [25, 27, 29, 57, 58, 66], "equat": [31, 39, 64], "equival": [31, 33, 40, 43, 53], "erf": 68, "erhan": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "err": [24, 29], "errat": 54, "erro": 65, "error": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 26, 29, 31, 32, 41, 62, 64, 68, 69], "es": 19, "esa": 16, "escama": 24, "escap": [29, 34, 35, 40, 43, 48, 49, 50, 52, 53, 54], "escog": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "escoja": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "escribir": 24, "escr\u00edbeno": 70, "espacio": [16, 24], "espcializaci\u00f3n": 5, "especi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "especi_scor": [57, 58], "especializada": 16, "especif": [57, 58], "espec\u00edfico": 18, "esperada": 24, "esperado": 66, "esperamo": 18, "esquema": [16, 18], "est": [1, 3, 4, 5, 6, 7, 14, 16, 18, 19, 23, 66, 70], "esta": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 66], "estabilidad": 23, "establecer\u00eda": 23, "establecida": [12, 13, 14], "estado": 70, "estad\u00edstica": 23, "estad\u00edsticament": 23, "estamo": [16, 23, 24, 70], "estar": [12, 13, 14, 66], "estim": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 29, 31, 44, 56, 58, 66], "estimaci\u00f3n": 23, "estimador": 23, "estimarms": 61, "estimarmse_rnn": 61, "estimarmse_rnn_multistep": 61, "estimarmse_rnn_multistepencodeco": 61, "esto": [3, 19, 23, 24], "estrategia": [16, 19], "estricta": [12, 13, 14], "estrictament": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "estructura": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 18], "estruct\u00faralo": [3, 4, 6, 7, 8, 9, 10, 11], "estudiant": [6, 7, 8, 9, 10, 11, 12, 13, 14], "est\u00e1": [14, 70], "est\u00e1n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 23], "est\u00e1ndar": 17, "est\u00e1tico": 19, "est\u00e9n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "et": [12, 13, 14], "eta": [29, 31], "etapa": [18, 19], "etc": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 20, 23, 33, 35, 37, 40, 42, 44, 50, 60], "eter": 68, "euclidean_dist": 64, "ev": 67, "eva": 65, "eval": 36, "evalu": [25, 26, 38, 39, 40, 44, 48, 49, 51, 54, 60, 62, 63, 65, 66, 67], "evaluacion": 24, "evaluate1": 66, "evaluci\u00f3n": 17, "even": [31, 32, 34, 39, 41, 42, 54, 62, 63, 64, 65, 67], "eventhough": 67, "everi": [25, 28, 29, 42, 57, 61, 62, 63, 64, 66, 67], "everyth": [41, 54, 66], "everytim": [37, 41], "evidencia": 23, "evolucion\u00f3": 18, "evoluci\u00f3n": [16, 17], "evolut": 67, "ewma": 62, "ewma_correct": 62, "ex2data2": 31, "exact": [21, 67, 68], "exactli": [29, 46, 63], "examen": 4, "exampl": [18, 20, 27, 31, 35, 38, 43, 44, 52, 65, 66, 69], "example_bayes2dclassifi": 23, "example_input_batch": 66, "example_target_batch": 66, "excel": 68, "excelent": 18, "excepcionalment": 23, "except": [41, 63, 64, 66, 67], "excess": 37, "exclud": 67, "exclus": 63, "execut": [20, 29, 37, 38, 40, 41, 49, 54], "exercis": [20, 25, 26, 39, 56], "exhaustivo": 23, "exist": [24, 31, 64], "exit": 29, "exp": [26, 29, 35, 37, 38, 43, 52, 64, 65], "exp_pr": 65, "expand": 39, "expand_dim": [54, 66], "expandir\u00e1": 16, "expect": [33, 36, 39, 47, 50, 67], "expens": 37, "experi": [25, 56, 58, 66], "experiment": [36, 69], "experimenta": 23, "experimental_enable_numpy_behavior": 36, "experimentalment": 16, "experimento": [16, 17, 18, 23], "explain": [52, 54, 65, 67], "explan": [20, 49, 52, 68], "explicamo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 70], "explicitli": [28, 32], "expliqu": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "explod": 67, "explor": 52, "exploraci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "exploramo": 15, "explorando": 15, "explot": 68, "expl\u00edcita": [6, 7, 8, 9, 10, 11, 12, 13, 14], "expl\u00edcitament": 24, "exponenti": [22, 52, 62], "export": [54, 59], "expr": [38, 39], "expr_cost": 39, "expr_dt0": 39, "expr_dt1": 39, "expres": [38, 39], "expresion": [17, 24], "expresi\u00f3n": 24, "express": [29, 31, 37, 38, 39, 40, 61, 62], "expression_fn": 38, "extend": 29, "extendemo": 18, "extens": [37, 42], "extmath": 64, "extra": 34, "extra_info_dim": 34, "extract": [31, 38, 45, 55, 63, 66, 67, 68, 69], "extractor": 50, "extrem": [25, 42], "ex\u00e1men": 2, "ex\u00e1ment": [7, 11, 12, 13, 14], "ey": [25, 28, 34, 35, 36, 42], "ey0": 27, "ey1": 27, "eyt": 27, "eytr": 27, "f": [21, 31, 33, 35, 36, 38, 39, 40, 41, 43, 44, 47, 51, 54, 55, 56, 57, 58, 62, 64, 65, 67, 69], "f1": [39, 41, 47, 67], "f11": 41, "f1_score": 67, "f2": [39, 41, 47], "f3": 41, "f4": 41, "f47": 41, "f5": 41, "f_gradient": 36, "f_l": 62, "f_output": 36, "face": [30, 59, 65], "facecolor": [45, 52], "fact": [29, 62, 65, 66], "factor": 39, "factsfigur": 52, "facultad": [1, 2, 3, 4, 6, 8, 9, 10, 11], "fai": 65, "fairli": 66, "fall": [45, 52], "fals": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "famili": [61, 65], "familia": 18, "familiaric": 16, "familiarizars": 15, "familiarizart": 70, "familiarizar\u00e1": 18, "fan": 54, "far": 29, "fashion": 26, "fashion_mnist": [25, 30], "faster": [39, 52, 62, 64], "fatur": 64, "fc": [24, 66], "fc1": 50, "fc2": 50, "fe": 65, "feat": 50, "featur": [18, 29, 31, 50, 65, 67, 69], "feature_extract": 64, "feature_learning_ml_dl": 22, "feature_rang": [61, 62], "feature_vector_inceptionv1": 44, "feb": [1, 2, 3, 5, 6, 7, 10, 11], "fed": [33, 42, 66, 68], "fedbn": 65, "feed": [28, 38, 40, 44, 66, 68], "feedback": [61, 62], "ferd": 65, "few": [39, 64], "fewer": [62, 64], "ff": 41, "ff_dim": [58, 68], "ffill": 67, "ffn": 68, "ffn_output": 68, "fg1": 41, "fg2": 41, "fi": [41, 65], "fichero": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "field": [29, 55, 64], "fig": [25, 29, 30, 33, 34, 52, 57, 64, 66, 69], "figsiz": [21, 23, 24, 25, 26, 27, 28, 30, 33, 34, 36, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 60, 62, 64, 66], "figur": [21, 23, 24, 26, 27, 28, 33, 34, 36, 40, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 61, 66, 69], "fiid": 65, "file": [20, 42, 44, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 64, 66], "file_prefix": 66, "filenam": [22, 23, 24, 27, 29, 31, 34, 39, 48, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69], "fillna": 56, "filter": [43, 46, 47, 53, 55, 57, 62, 66, 67, 69], "filter_nb": 43, "filterwarn": [23, 54, 61], "filtro": [18, 48], "fin": [2, 18], "final": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 33, 46, 52, 55, 59, 62, 68, 69], "finali": 4, "finalizacion": 4, "finalizaci\u00f3n": [3, 6, 7, 8, 9, 10, 11, 12, 13, 14], "finalment": 18, "find": [31, 39, 53, 68], "find_al": 64, "fine": 54, "fiost": 65, "fir": 65, "firmament": 65, "first": [20, 25, 26, 27, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 52, 54, 56, 61, 62, 63, 64, 65, 66, 67, 68], "fit": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 40, 42, 44, 45, 48, 49, 51, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "fit_on_text": [64, 66, 67], "fit_transform": [25, 30, 57, 58, 61, 62, 64], "fivethirtyeight": 62, "fix": [38, 42, 52, 53, 68], "flat": [31, 67], "flatten": [26, 30, 33, 34, 35, 36, 42, 43, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 61, 67, 69], "flatten_1": [49, 51], "flatten_2": [51, 69], "fled": 65, "flexibl": [30, 32, 33, 65], "float": [21, 65], "float32": [25, 26, 27, 28, 32, 33, 36, 37, 38, 40, 41, 42, 44, 47, 49, 50, 51, 52, 53, 55, 61, 64, 65], "float64": [27, 32, 36, 40, 43, 49, 50, 55, 64, 65], "flow": [62, 68, 69], "flpane": 65, "flujo": [15, 23], "flush": 54, "flush_ev": 29, "fmt": 62, "fo": 65, "foco": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "focu": 68, "focus": 46, "folder": 69, "follow": [20, 21, 25, 26, 27, 28, 31, 32, 37, 38, 40, 43, 44, 45, 46, 48, 53, 54, 56, 57, 58, 59, 61, 63, 64, 66, 68, 69], "fontdict": 66, "fontsiz": [29, 52, 66], "footbal": 52, "forc": [25, 26, 33, 58, 66, 67], "force_download": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "forecast": 61, "forget": 62, "form": [29, 39, 40, 42, 65, 69], "forma": 23, "format": [48, 51, 52, 54, 56, 57, 58, 61, 62, 63, 64, 66, 67, 69], "formato": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "formen": [6, 7, 8, 9, 10, 11, 12, 13, 14], "former": [29, 31, 56, 57, 58, 61, 62, 67, 68], "formul": [29, 61, 64, 67], "formula": 29, "formulario": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "forthcom": 67, "forward": [28, 29, 30, 35, 40, 66, 67, 68], "forwardbackward": 29, "found": [54, 64, 67, 68], "four": [25, 67, 69], "frac": [24, 25, 26, 29, 30, 31, 33, 35, 37, 38, 39, 40, 42, 44, 58, 61, 64, 68], "fragment": 43, "frame": [19, 59, 69], "framework": [19, 29, 40], "frase": 66, "fraseo": 66, "frecuenc": 64, "frequenc": 64, "frequent": 64, "friedman": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "frio": 66, "from": [12, 13, 14, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69], "from_logit": 66, "from_tensor_slic": 66, "fronter": 23, "frontera": 15, "frontier": 37, "fscope": 41, "fuent": 16, "fuera": [6, 7, 8, 9, 10, 11, 12, 13, 14], "fueron": 18, "fuil": 20, "full": [0, 39, 66], "fun": [24, 39], "funcanim": 69, "funcion": [16, 17, 18, 24, 37], "funcionamiento": [18, 19], "funci\u00f3n": [16, 17, 18, 24], "function": [16, 17, 20, 26, 27, 28, 31, 33, 34, 35, 36, 38, 39, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56, 57, 58, 61, 62, 65, 66, 67, 68, 69], "functional_1": [49, 51, 53], "functional_11": 33, "functional_15": 64, "functional_18": 36, "functional_2": [49, 51], "functional_26": 33, "functional_3": 49, "functional_4": 49, "functional_7": 30, "functionscop": 41, "fund_deep_learn": 64, "fundament": 15, "fundamental": 16, "fundamento": 70, "further": 52, "futur": [56, 66, 69], "futura": 19, "fx": 43, "fy": 43, "f\u00edjate": [23, 24], "g": [24, 29, 31, 40, 47, 54, 57, 58, 59, 61, 64, 65, 67], "g0_after": 36, "g0_befor": 36, "g1": 41, "g2": 41, "gallery_slid": 50, "gamma": [23, 38, 42, 44], "gap": 60, "gassrr": 65, "gate": 67, "gather": [27, 28], "gaussian": 68, "gaussian_kd": 42, "gb": 40, "ge": 65, "gecko": 64, "gelu": 68, "gener": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 23, 30, 31, 41, 45, 46, 53, 57, 61, 62, 66, 67, 68, 69], "genera": [18, 23, 46], "generaci\u00f3n": [15, 19], "general": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18], "generalizada": 18, "generan": [15, 23], "generar": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19], "generate_context_word_pair": 64, "generativo": 24, "genesi": 65, "genfromtxt": 31, "gensim": [57, 64], "gen\u00e9rico": 24, "geo": 67, "geograph": 67, "geometri": 40, "get": [21, 25, 26, 27, 28, 29, 30, 33, 38, 39, 40, 43, 44, 46, 47, 50, 52, 53, 56, 57, 58, 62, 65, 66, 67], "get_a1": 42, "get_a2": 42, "get_anchor_box": 45, "get_basic_model": 25, "get_closest_anchor_box": 45, "get_concrete_funct": 41, "get_config": 36, "get_conv_model": 49, "get_conv_model_a": 48, "get_conv_model_b": 48, "get_conv_model_c": 48, "get_double_deriv": 38, "get_feature_names_out": 64, "get_fil": 66, "get_gradi": 40, "get_gradients_funct": 36, "get_img": 50, "get_l1l2_model": 25, "get_l2_model": 25, "get_lay": [28, 33, 48, 49, 50], "get_loss": 26, "get_model": [26, 27, 28, 33, 35, 36, 38, 49, 51, 53, 59], "get_model5": 40, "get_model8": 40, "get_model_a": [34, 46], "get_model_b": [34, 46], "get_model_functional_1": 32, "get_model_functional_2": 32, "get_model_sequenti": 32, "get_model_target_predict": 45, "get_model_u": 33, "get_model_unet": 54, "get_model_unet_no_skip": 46, "get_modela": 53, "get_modelb": 53, "get_modelt": 51, "get_next": 67, "get_percentil": 36, "get_preprocessed_seq": 57, "get_tensors_and_funct": 36, "get_top3_inceptionv1_label": 44, "get_transformer_model": 58, "get_weblink": [21, 25, 26, 27, 28, 56, 57, 58, 59], "get_weight": [26, 28, 32, 33, 36, 38, 40, 48, 51, 53, 63, 64, 65], "get_x_extra": 34, "get_z1": 42, "get_z2": 42, "getpid": [56, 57, 58, 59], "getter": 67, "gfx": 44, "ggplot": 67, "gi": 54, "gif": [67, 68], "github": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 20, 40, 48, 62, 63, 66, 67], "githubusercont": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "gitignor": 20, "give": [28, 30, 31, 58, 64], "given": [21, 26, 27, 28, 29, 31, 33, 37, 38, 44, 45, 58, 59, 61, 62, 64, 67], "glihm": 65, "global": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 53, 55, 56, 57, 58, 59, 64, 67, 68, 69], "global_clipnorm": 51, "globalaveragepooling1d": [58, 68], "globalmaxpooling1d": 57, "glorot_uniform": 66, "glorotuniform": [36, 51], "glove": [57, 64, 67], "glove_vector": [57, 64], "gn": 65, "go": [29, 31, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "goal": [28, 29, 40, 55], "god": 65, "golfcart": 50, "gond": 65, "gone": 33, "good": [33, 36, 54, 56, 65, 66], "goodfellow": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "googl": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 37, 38, 43, 44, 48, 52, 54, 56, 57, 58, 59, 60, 67, 70], "googleapi": [45, 50, 52, 66, 68], "gord": 65, "got": [26, 58], "gove": 64, "govern": 67, "gpe": 67, "gpt": [12, 13, 14], "gpu": [22, 33, 44, 65, 66, 69], "grabacion": [1, 6, 7, 8, 9, 10, 11, 12, 13, 14], "grad": [24, 35, 40, 42], "grade": [20, 45], "grader": [21, 44, 45, 57], "gradient": [15, 17, 29, 32, 36, 38, 41, 42, 52, 61, 62, 66], "gradient_accumulation_step": 51, "gradienttap": [32, 36, 38, 40, 41, 42, 66], "grafo": 17, "grai": [24, 30], "gram": 64, "grammat": 66, "graph": [25, 30, 38, 39, 40, 62], "graphic": 60, "grayscal": 53, "great": [67, 68], "green": [23, 24, 47, 67], "grei": 47, "greys_r": [26, 27, 33, 34, 43, 47, 48, 53, 54, 55], "greyscal": 30, "grid": [23, 24, 28, 34, 35, 36, 40, 42, 43, 45, 52], "grill": 50, "grm": 19, "ground": 23, "group": [33, 51, 56, 67], "group_kei": 67, "groupbi": 67, "grrst": 65, "gru": [56, 57, 66], "grupo": 1, "gsp": 67, "guerzhoi": 51, "guid": [28, 30, 37, 40, 50, 53], "gutenberg": 65, "gu\u00eda": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "gw": 40, "gz": [26, 27, 28, 33, 34, 35, 36, 59], "gzip": [25, 26, 27, 28, 30, 33, 34, 35, 36, 56], "h": [29, 40, 44, 45, 52, 56, 61, 62, 65, 67, 68], "h5": [42, 44, 48, 49, 50, 51, 52, 53, 54, 65], "h5f": [42, 44, 48, 49, 51, 53], "h5py": [42, 44, 48, 49, 51, 53], "h_": 62, "h_0": 45, "h_1": 45, "h_j": 62, "h_l": 62, "h_t": 62, "ha": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 25, 27, 30, 37, 38, 40, 42, 43, 47, 49, 53, 61, 62, 63, 64, 65, 66, 67], "ha1": 42, "ha2": 42, "habia": 66, "habilitaci\u00f3n": [2, 7, 11], "hablant": 66, "habr\u00e1": [6, 7, 8, 9, 10, 11, 12, 13, 14], "habr\u00e1n": [6, 7, 8, 9, 10, 11, 12, 13, 14], "hace": [5, 66], "hacemo": [23, 24], "hacer": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 23], "hacerl": 16, "hacia": 19, "haciendo": 23, "hack": 53, "had": [66, 67], "hadamard": 61, "hadhb": 65, "hai": 23, "half": 63, "hall": 29, "ham": 67, "han": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "hand": [33, 35, 39, 40, 47, 53, 64], "handicap": 29, "handl": [34, 54], "haneh": 65, "happen": [41, 42, 54], "hardwar": 22, "harinisuresh": 35, "hash": 41, "hasta": [18, 66], "hasti": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "hat": [23, 24, 25, 30, 37, 39, 61, 62], "have": [20, 21, 25, 26, 27, 29, 30, 32, 34, 35, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "haya": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "haykin": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 29], "haz": 23, "hazt": 23, "hd5": [1, 2], "hdf": 54, "hdf5": [54, 65], "he": [20, 65, 66, 67], "he_norm": 54, "head": [20, 27, 45, 51, 52, 56, 58, 62, 68], "head_length": 24, "head_width": 24, "headed_self": 68, "header": [26, 27, 28, 33, 34, 35, 36, 56, 64], "heart": 67, "heav": 65, "heaven": 65, "height": [29, 45, 65], "hello": 54, "help": [29, 68], "helper": 65, "henc": 33, "here": [21, 27, 32, 35, 37, 38, 40, 43, 44, 45, 46, 54, 55, 62, 63, 64, 65, 66, 67, 68, 69], "herramienta": [15, 17, 18, 23], "hess_inv": [24, 39], "hessian_matrix": 38, "hi": [65, 67], "hicist": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "hidden": [25, 28, 29, 33, 35, 37, 57, 61, 62, 66, 68], "hidden_layer_s": 29, "hidden_s": [28, 35, 66], "hierarch": 64, "hif": 65, "high": [42, 45, 52, 60, 61, 62, 64, 66], "higher": [31, 35, 55, 62], "highest": [52, 64], "highest_protocol": 57, "highwai": 67, "hint": [21, 25, 38, 56], "hist": [25, 33, 36, 52, 67], "histogram": [25, 35, 36, 67], "histogram_freq": [35, 36], "histograma": [16, 17], "histori": [30, 33, 34, 35, 36, 37, 40, 53, 58, 62, 63, 65, 66, 67, 68, 69], "hl": 65, "hloss": 42, "hn": 65, "hnrde": 65, "ho": 65, "hoc": 30, "hochreit": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "hoi": 18, "hole": 67, "home": 64, "hoopskirt": 50, "hope": 55, "horizon": 56, "horizont": 47, "hot": [24, 64, 65], "hour": [56, 66], "hous": 50, "how": [20, 26, 27, 28, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 53, 54, 55, 62, 65, 68], "howev": [29, 31, 32, 33, 41, 55, 64, 66, 67], "hsize": 36, "hsn": 65, "hsoftmax": 64, "hstack": [27, 62], "html": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 48, 52, 61, 64, 69], "http": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "httperror": 64, "hub": [18, 58, 59, 67], "human": [64, 66], "hundr": 66, "hyndman": 60, "hyperparamet": 31, "hz1": 42, "hz2": 42, "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 58, 59, 61, 62, 64, 66, 67, 68, 69], "i_l": 62, "ia": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ibcab": 65, "id": [54, 58, 59, 66], "id2word": 64, "id_": 54, "idea": [31, 66], "ideal": 23, "idealizado": 15, "identifi": 31, "idf_": 64, "idj": 4, "idx": [27, 33, 40, 42, 48, 57, 58, 64], "idx2tag": 67, "idxs0": 27, "idxs1": 27, "idxs_p1": 27, "idxs_p2": 27, "ie": 65, "ieee": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "igh6ykbnittwvlxt2ro7x4xqgui7x7t34ryoqnukncfvuvkldso0c2gjmn4pgnxnou65iql65ji49cfzmyd0tdwcok7v7pn0j1okvg33bbeashjmxq": 45, "ignor": [23, 25, 30, 54, 61], "ih": 65, "ij": [29, 31], "ill": 31, "illustr": [32, 35, 50], "iloc": [24, 45, 52, 62], "ilsvrc": 50, "ilustramo": [15, 16, 17], "ilustrando": 15, "im": [25, 30, 69], "imag": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 39, 40, 44, 45, 46, 50, 51, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "imageid": 52, "imagen": [26, 27, 28, 33, 34, 35, 36], "imagenet": [18, 44, 50, 51, 52], "imagenet_class_index": 52, "imagenet_util": 50, "imagenetlabel": [44, 52], "imaginario": 24, "imdb": 68, "img": [20, 22, 23, 24, 25, 26, 27, 29, 31, 33, 34, 39, 40, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "img_channel": [46, 54], "img_fnam": 50, "img_height": [46, 54], "img_siz": [48, 49, 51, 53], "img_url": 50, "img_width": [46, 54], "imga": 44, "imgb": 44, "imgs_task": 48, "impact": 67, "impiden": 16, "implement": [17, 20, 25, 26, 28, 31, 32, 33, 53, 55, 59, 63, 64, 66, 67, 68], "implementa": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "implementacion": 17, "implementaci\u00f3n": 19, "implementado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "implementamo": 18, "implementar": [16, 19], "implementar\u00e1": 18, "implementen": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "impli": 66, "implic": 67, "implicacion": 19, "import": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "important": [17, 24], "importlib": 23, "improv": [22, 25, 31, 54, 67], "imread": [43, 44, 47, 50, 52, 54, 55], "imread_collect": 54, "imshow": [25, 26, 27, 30, 33, 34, 43, 44, 47, 48, 50, 52, 53, 54, 55, 69], "im\u00e1gen": [16, 18], "in_group": 67, "inabl": 62, "inbound_nod": [36, 51], "incept": [18, 44, 50], "inception_resnet_v2": 52, "inception_v3": 52, "inception_v3_weights_tf_dim_ordering_tf_kernel": 52, "inceptionv1": 44, "includ": [20, 25, 29, 30, 33, 38, 56, 57, 60, 62, 64, 66, 67, 68], "include_top": 52, "incluir": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16], "inclusi\u00f3n": [12, 13, 14], "incluso": 23, "incluy": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "incl\u00fayelo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "inconveni": 32, "inconvenient": 70, "incorpor": 66, "increas": [40, 43, 54, 63, 64, 68], "increment": [31, 63], "incremental": 18, "ind": 30, "independ": [31, 66, 68], "independient": 23, "index": [26, 27, 45, 56, 57, 64, 65, 66], "index_col": [52, 56, 62], "index_word": 66, "indian": 67, "indic": [26, 30, 67], "indica": [3, 4, 6, 7, 8, 9, 10, 11], "indicar\u00e1": 3, "indirectament": 24, "individu": [21, 66], "inexpens": 66, "inf": [25, 54], "infer": [32, 44, 49], "infin": 47, "inflex": 29, "info": [34, 64, 67], "inform": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 31, 33, 34, 46, 52, 62, 64, 66, 67, 68], "informaci\u00f3n": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19], "informact": 66, "informe_proyecto": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "infti": 47, "ingenia": [6, 7, 8, 9, 10, 11, 12, 13, 14], "ingenier\u00eda": [1, 5, 23], "inherint": 30, "inici": 23, "inicio": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "init": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "init1b": 36, "init1k": 36, "init_print": 39, "init_t": [24, 39], "initi": [28, 37, 38, 40, 42, 43, 46, 48, 51, 55, 58], "initial_st": 66, "initial_valu": 40, "initial_w0": 48, "initialize_hidden_st": 66, "inject": 34, "inlin": [20, 21, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 61, 62, 64, 67], "inmat": 67, "inner": [29, 32], "innov": 68, "inp": [49, 66], "inp1": 34, "inp2": 34, "inp_lang": 66, "inp_lang_token": 66, "inplac": 56, "input": [21, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69], "input_1": [46, 48, 49, 51, 53], "input_2": 46, "input_7": 46, "input_dim": [25, 26, 27, 28, 30, 33, 34, 35, 36, 38, 40, 49, 61, 64, 66, 67, 68], "input_extra": 34, "input_img": 34, "input_img0": 27, "input_img1": 27, "input_lay": [36, 50, 51, 54, 66], "input_layer_3": 30, "input_layer_4": 40, "input_layer_7": 64, "input_mask": 58, "input_segments_t": 58, "input_segments_tr": 58, "input_sent": 67, "input_seq": 66, "input_shap": [30, 35, 36, 37, 40, 42, 43, 44, 47, 49, 51, 53, 55, 56, 61, 66, 67], "input_tensor": 66, "input_tensor_train": 66, "input_tensor_v": 66, "input_text": [58, 67], "input_type_id": 58, "input_word_id": 58, "inputlay": [27, 30, 33, 34, 36, 40, 46, 48, 49, 50, 51, 53, 54, 64, 66], "inputs1": 27, "inputs2": 27, "insecticida": 24, "insecto": 24, "insert": [31, 53, 55], "insid": [38, 67, 68], "inspeccionamo": 15, "inspeccionando": 15, "inspeccionar": [16, 17], "inspect": [21, 25, 26, 27, 28, 36, 37, 38, 46, 52, 56, 57, 58, 59], "inspir": 67, "inspiraron": 19, "instal": [29, 44, 48, 54, 56, 57, 58, 59, 67], "instalada": 19, "instanc": [25, 27, 29, 30, 31, 33, 34, 37, 38, 43, 44, 48, 52, 53, 56, 61, 66, 67, 69], "instanti": [25, 30], "instead": [29, 33, 35, 36, 37, 40, 49, 54, 57, 58, 62, 69], "insteat": 30, "instruccion": [1, 2], "instrumentaci\u00f3n": 16, "int": [25, 26, 27, 28, 33, 34, 37, 42, 47, 50, 54, 56, 61, 63, 66, 69], "int32": [41, 67, 68], "int64": [34, 42, 48, 51, 52], "int_": 47, "int_to_char": 65, "intact": 68, "integ": [37, 43, 45, 65, 67], "integr": [32, 40, 42, 47, 52], "integrar": 17, "intellig": [64, 66], "intend": 59, "interaccionar": 70, "interact": [0, 68], "intercept_": [24, 32, 40], "interchang": 64, "interesant": 23, "interest": [45, 52, 62, 68], "interfac": 64, "intermedi": [29, 42], "intern": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 36, 42, 60, 61, 67, 69], "internal_convert_user_cod": 41, "internet": 44, "interpol": [25, 30, 33, 34], "interpret": 28, "interpretabilidad": 16, "interv": [56, 69], "inter\u00e9": [6, 7, 8, 9, 10, 11, 12, 13, 14], "intratal": 29, "intro": 5, "intro_ml_2025": 14, "introduc": [42, 62, 66], "introducci\u00f3n": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17], "introducimo": [16, 17, 18], "introduct": [22, 54], "intuici\u00f3n": [15, 16, 17, 18], "intuit": [47, 49, 50, 52, 53, 62, 68], "intuitivo": 16, "invalid": [34, 35, 40, 43, 48, 49, 50, 52, 53, 54, 64], "invers": [31, 53, 64], "inverse_transform": [56, 61, 62], "invert": 47, "investigaci\u00f3n": [6, 7, 8, 9, 10, 11, 12, 13, 14], "invok": [25, 28, 37, 56], "involv": 40, "io": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 30, 40, 43, 44, 45, 46, 47, 48, 50, 52, 54, 55, 62, 63, 65, 66], "ioteph": 65, "iou": 52, "ipykernel_19352": 69, "ipynb": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20], "ipython": [20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 39, 40, 45, 46, 48, 52, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "ir": 65, "iraq": 67, "iri": 29, "iro": 64, "irrelev": 68, "isdepict": 52, "isdigit": [57, 58], "isinsid": 52, "isnan": [60, 61, 62], "isocclud": 52, "isra": 67, "israel": 65, "issu": [25, 42, 66, 67], "istrunc": 52, "item": [20, 26, 51, 67], "iter": [24, 29, 31, 61, 66], "iteracion": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "iteraci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "iterrow": [57, 58], "itertool": [24, 50, 54], "itok": 50, "itr": 27, "its": [26, 27, 29, 31, 37, 42, 45, 52, 57, 61, 62, 64, 68, 69], "itself": [62, 65, 67], "ival": 54, "j": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24, 25, 27, 29, 30, 37, 39, 44, 49, 50, 56, 57, 60, 62, 63, 64, 65, 69], "jac": [24, 39], "jaca": 65, "jacob": 65, "jacobgil": 48, "jacobian": 38, "jbcob": 65, "jdariasl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 64, 66, 67], "jeep": 50, "jerarqu\u00eda": 18, "ji": 29, "jit_compil": 51, "jk": 29, "jl": 29, "jno": 65, "join": [24, 33, 64, 65, 66, 67], "jointli": 66, "jpeg": [22, 48, 61, 62], "jpg": [24, 29, 39, 44, 47, 48, 50, 52, 61], "json": [51, 52, 54, 65], "json_fil": 65, "judgement": 66, "juguet": 18, "jul": 13, "julian": [1, 2, 3, 13, 14], "jun": [1, 3, 6, 7, 10, 11, 13], "junto": 18, "jupyt": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 70], "just": [21, 27, 28, 30, 32, 33, 40, 42, 43, 46, 49, 53, 54, 55, 58, 63, 64, 67, 69], "justificaci\u00f3n": 16, "k": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 25, 26, 29, 33, 35, 36, 37, 43, 48, 51, 52, 53, 54, 55, 56, 62, 64, 65, 67, 68], "k0": [24, 29, 34], "k1": [24, 34], "k2": 34, "kaggl": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 54, 57], "kaggle_config_dir": 54, "karim": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "karpathi": [12, 13, 14, 61], "kb": [27, 30, 33, 34, 36, 44, 48, 49, 52, 53, 62, 64, 69], "kc": 45, "kde": 42, "kdnugget": [12, 13, 14], "keegil": 54, "keep": [20, 28, 48, 51, 54, 55, 57, 58, 59, 62, 66, 68], "keepoutput": 20, "kei": [27, 37, 40, 44, 58, 64, 68], "kept": [20, 42, 53], "kera": [16, 18, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 61, 62, 63, 65, 66, 67, 68, 69], "keras_histori": [36, 51], "keras_tensor": 50, "keras_tensor_117": 36, "keras_tensor_123": 36, "keras_tensor_129": 36, "keras_tensor_135": 36, "keras_tensor_147": 36, "kerasbatchgener": 65, "keraslay": [44, 52, 58, 67], "kernel": [23, 28, 40, 47, 54, 55, 57, 68], "kernel_0": 35, "kernel_constraint": [36, 51], "kernel_filt": 67, "kernel_initi": [36, 51, 54], "kernel_regular": [25, 36, 51, 61], "kernel_s": [43, 47, 51, 53, 55, 67, 69], "key_dim": 68, "khtml": 64, "kill": [56, 57, 58, 59], "kimono": 52, "kind": [29, 34, 46], "king": 44, "kjv": 65, "kl": 29, "km": 45, "kmean": [18, 45, 52], "know": [29, 32, 48, 66], "known": [31, 37, 40], "ko": [60, 61, 62], "ko_2006": [60, 61, 62], "koo": 60, "kwarg": [32, 35, 36, 40, 49, 51, 67], "kyunghyun": 66, "kz": 35, "l": [24, 25, 29, 30, 35, 42, 51, 61, 62, 65, 66, 68], "l0": [28, 29], "l01": 21, "l02": [25, 26, 27, 28], "l03": [37, 38], "l04": [43, 44, 45, 46], "l05": [56, 57, 58, 59], "l1": [16, 28, 49], "l11": 34, "l12": 34, "l13": 34, "l1l2": [25, 31], "l2": [16, 25, 28, 61], "l21w1": 25, "l21w2": 25, "l21w3": 25, "l3": 28, "l_1": 31, "l_2": 31, "l_i": 44, "l_j": 44, "la": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 26, 27, 28, 33, 34, 35, 36, 38, 46, 56, 66, 70], "lab": [5, 15, 16, 17, 18, 19], "lab_coat": 52, "lab_id": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "laban": 65, "label": [20, 23, 24, 25, 27, 28, 29, 30, 34, 35, 36, 37, 40, 44, 45, 46, 47, 48, 51, 52, 54, 56, 57, 61, 62, 67, 69], "labelencod": [57, 58, 59], "labelnam": 52, "labels_list": 44, "laboratorio": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "labotorio": 5, "lack": 60, "lag": 60, "lam": 31, "lambda": [21, 24, 26, 31, 35, 37, 38, 39, 40, 43, 44, 46, 47, 49, 54, 57, 58, 64, 67], "lambda_1": 46, "lambda_5": 64, "lambda_6": 46, "lambdifi": 39, "lan": 65, "land": [29, 52, 65], "lang": 66, "lang_token": 66, "languag": [12, 13, 14, 19, 61, 64, 65, 66, 68], "larg": [12, 13, 14, 26, 29, 31, 44, 50, 51, 52, 62, 64, 65, 67, 68], "larger": [31, 33, 52, 55, 65], "largest_sen": 67, "largo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "lash": 51, "lasso": 31, "last": [30, 37, 48, 52, 56, 59, 61, 66, 67], "late": [22, 52], "latent": [16, 26, 64], "later": [32, 33, 38, 48, 51, 54, 66], "latest": 66, "latest_checkpoint": 66, "latin1": 67, "latitud": 24, "layer": [19, 25, 26, 27, 30, 32, 34, 36, 37, 40, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 68, 69], "layer0_proj": 67, "layer1": 67, "layer1_img0": 27, "layer1_img1": 27, "layer1_out": 67, "layer2": 67, "layer2_common": 27, "layer_": [28, 35, 36], "layer_00_input": [35, 36], "layer_01_hidden": [35, 36], "layer_02_hidden": [28, 36], "layer_03_output": 36, "layer_a": 38, "layer_b": 38, "layer_c": 38, "layer_decod": 33, "layer_encod": 33, "layer_input": 33, "layer_nam": [28, 38, 48], "layer_output": 67, "layer_output_fn": 50, "layer_outputs2": 67, "layer_s": 36, "layer_typ": [56, 57], "layernorm": 68, "layernorm1": 68, "layernorm2": 68, "layerweightscallback": 28, "layerweightscallback_class": 28, "lb": [38, 54], "lc": 38, "lcurv": 23, "ld": 41, "le": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 59], "lead": [31, 62], "leaki": 62, "leaky_relu": 35, "leakyrelu": 62, "learn": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 27, 31, 32, 48, 53, 54, 61, 62, 65, 66, 67, 68, 70], "learnabl": 42, "learning_r": [25, 29, 30, 32, 37, 40, 51, 57, 58, 66], "learning_rate_init": 29, "learnt": [33, 65], "least": [29, 31, 54], "leav": 54, "leaverag": 64, "lectur": [20, 67], "lef": 69, "left": [23, 24, 25, 28, 29, 31, 43, 45, 48, 52, 58, 61, 62, 64, 68, 69], "leftarrow": 62, "legaci": [50, 54], "legend": [23, 24, 28, 29, 34, 35, 36, 40, 45, 47, 56, 57, 60, 61, 62], "lemmat": 64, "len": [23, 24, 26, 27, 28, 29, 33, 34, 36, 37, 39, 40, 42, 44, 45, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68], "len_seq": 63, "lend": 64, "length": [20, 42, 48, 49, 51, 52, 54, 57, 58, 61, 63, 64, 66, 67], "lenguaj": 19, "leq": [64, 68], "lerarn": 33, "less": [41, 62, 63, 64], "let": [12, 13, 14, 30, 31, 33, 54, 62, 65, 69], "level": [17, 20, 24, 35, 42, 51, 52, 62, 67], "lexic": 64, "li": [29, 33], "lib": [20, 21, 23, 25, 26, 27, 28, 29, 31, 33, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67], "librari": [20, 57, 62, 64], "librer\u00eda": [16, 19], "libressl": [66, 67], "libro": 66, "life": 66, "light": [54, 65, 66], "lightest": 64, "like": [25, 32, 33, 34, 38, 40, 45, 46, 53, 54, 57, 58, 62, 63, 64, 66, 67, 68, 69], "limit": [4, 60, 68], "limitacion": 19, "linalg": 44, "line": [20, 21, 23, 29, 31, 38, 50, 66], "line1": 29, "line2d": [23, 31, 50], "line_alpha": 23, "line_color": 23, "line_width": 23, "linea": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46], "lineal": [15, 17, 24], "linear": [28, 36, 37, 38, 42, 43, 47, 53, 55, 57, 58, 59, 67, 68], "linear_loss": 32, "linear_model": [23, 24, 31, 32, 40], "linear_predict": 24, "linear_regression_model4": 40, "linearregress": [23, 24, 32, 40], "linearregressionmodel4": 40, "linearregressionmodel6": 40, "linearregressionmodel7": 40, "linewidth": [45, 52], "link": [60, 64, 66], "linspac": [21, 23, 24, 29, 35, 42, 47, 62, 69], "lisa": 64, "list": [12, 13, 14, 25, 28, 30, 32, 33, 34, 37, 38, 43, 44, 54, 57, 58, 59, 64, 65, 67, 69], "list_physical_devic": 69, "listdir": 59, "listedcolormap": 29, "liter": 41, "littl": [47, 54, 62], "ll": [29, 54], "llamada": [1, 2], "llamar": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "llegar": 24, "llegu": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "lo": [5, 15, 16, 17, 18, 19, 56, 66], "load": [29, 37, 42, 44, 51, 54, 56, 57, 59, 64, 65, 67], "load_data": [25, 30, 68], "load_dataset": 66, "load_diabet": 31, "load_ext": [35, 37, 39, 40, 41, 42, 49, 50, 51, 52, 53, 54, 56], "load_iri": 29, "load_model": 54, "load_video": 59, "loafer": 52, "loc": [23, 24, 28, 52, 56, 62], "local": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "locat": 43, "log": [24, 25, 28, 29, 30, 35, 36, 37, 40, 48, 51, 61, 63, 64, 65], "log_dir": [35, 36, 37, 48, 51], "logarithm": 64, "logdir": [35, 37, 40, 48], "logical_not": 66, "loginsequ": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "logist": [16, 31], "logisticregress": 23, "logit": [44, 66], "logsig": 29, "london": 67, "long": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 63], "longer": 58, "longitud": [24, 32, 39, 40], "longrun": 35, "look": [25, 30, 35, 40, 54, 57, 58, 62, 64, 68], "look_back": [56, 61, 62], "lookback": 56, "loop": [28, 32, 37, 39, 41, 43, 61, 62, 65, 69], "loos": 54, "lord": 65, "loss": [16, 24, 26, 27, 28, 30, 31, 35, 36, 38, 39, 42, 44, 46, 48, 49, 51, 53, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "loss_": 66, "loss_curve_": 29, "loss_fn": 40, "loss_funct": [25, 66], "loss_histori": 24, "loss_object": 66, "loss_scale_factor": 51, "loss_track": 32, "loss_valu": [40, 42], "loss_weight": 51, "lost": [52, 63], "lot": [54, 64], "love": 67, "low": [17, 35, 42, 62, 64], "lower": [33, 37, 38, 43, 48, 55, 56, 57, 58, 59, 64, 66, 67], "lowercas": 65, "lowest": 64, "lr": [24, 32, 40], "lsa": 64, "lsaintro": 64, "lsize": 49, "lstm": [56, 57, 58, 59, 61, 65, 66, 67], "lstm2": 62, "lstm_1": 69, "lstm_4": 66, "lstm_hidden": 67, "lstmandgru": 62, "luck": 46, "luego": 23, "lugar": 66, "lw": [23, 24, 34, 35], "lxml": 64, "l\u00edmite": [5, 15], "l\u00ednea": 16, "m": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 21, 24, 25, 26, 28, 33, 37, 39, 40, 41, 43, 44, 46, 52, 53, 54, 56, 64, 65, 69], "m1": 23, "m2": 23, "m_": 38, "m_1": 29, "ma": 64, "machin": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 22, 27, 29, 31, 44, 64], "macro": 67, "made": [35, 53, 55, 62, 63, 65], "mae": [37, 40], "magnitud": [31, 56], "magpi": 52, "mai": [1, 3, 4, 6, 7, 10, 11, 13, 20, 28, 29, 35, 44, 49, 62, 66, 68], "main": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "mainli": 31, "major": 67, "make": [29, 32, 35, 40, 44, 45, 50, 52, 57, 62, 66, 67, 68], "make_graph": 40, "make_moon": [29, 37, 49], "mamanieh": 65, "manag": 54, "manera": [15, 18, 19, 24, 66], "mani": [29, 43, 44, 52, 61, 64, 66, 67, 68], "manifold": 64, "maniplando": 18, "manipula": 17, "manipulaci\u00f3n": 17, "manner": [28, 32], "mano": 18, "manual": [25, 26, 28, 37, 38, 43, 47, 56, 63], "manuali": 61, "map": [41, 43, 49, 52, 53, 65, 66], "mapa": [18, 24], "mape": 61, "mar": [1, 2, 3, 4, 5, 6, 7, 10, 11, 13], "march": 67, "marh": 65, "mark": 56, "markdown": 20, "marker": 24, "mask": [18, 53, 54, 58, 65, 66, 68], "mask_": 54, "mask_fil": 54, "mask_zero": 67, "master": [12, 13, 14, 51], "mat": 25, "match": [33, 36, 50], "matem\u00e1tica": 24, "materi": [0, 20, 40, 48, 58, 66], "material": 5, "materialesclas": 64, "math": [58, 59, 62, 66, 67, 69], "mathbb": [21, 24, 26, 33, 37, 39, 53], "mathbf": [24, 33, 37, 39, 52], "mathcal": [25, 29, 30, 31], "mathemat": [31, 47, 61, 64], "matlab": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "matmul": [40, 42, 64], "matplotlib": [21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69], "matric": [19, 23, 25, 33, 64, 68], "matriculada": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "matrix": [25, 28, 29, 30, 33, 37, 38, 39, 40, 48, 51, 56, 57, 58, 61, 62, 63, 68, 69], "matshow": 66, "matter": 31, "max": [21, 23, 24, 26, 29, 42, 43, 47, 48, 49, 50, 52, 54, 55, 57, 60, 61, 62, 66, 67], "max_char": 67, "max_characters_per_token": 67, "max_depth": 23, "max_df": 64, "max_fatur": 64, "max_featur": 64, "max_fram": 59, "max_it": [23, 29], "max_len": [63, 66, 67], "max_length": 66, "max_length_inp": 66, "max_length_targ": 66, "max_pooling2d": [46, 48, 54], "max_pooling2d_1": [46, 51, 54], "max_pooling2d_2": [46, 51, 54], "max_pooling2d_3": [46, 54], "max_pooling2d_8": 69, "max_train_s": 60, "max_valu": 54, "maxent_ne_chunk": 67, "maxent_ne_chunker_tab": 67, "maxim": 21, "maximum": [44, 54, 58, 64, 65, 67], "maxit": 29, "maxlen": [58, 66, 67, 68], "maxpool2d": [48, 49, 51, 53], "maxpooling2": 46, "maxpooling2d": [46, 48, 49, 50, 51, 54, 69], "maxthon": 48, "mayor\u00eda": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "mb": [42, 48, 49, 50, 51, 52, 54, 64, 66, 67], "mbox": 64, "mc": [23, 26], "md": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 64], "me": 33, "mean": [20, 21, 23, 24, 25, 26, 27, 28, 30, 32, 33, 34, 36, 37, 39, 40, 41, 42, 47, 50, 51, 53, 58, 62, 63, 64, 67], "mean0": 23, "mean1": 23, "mean_absolute_error": 40, "mean_per_epoch": 28, "mean_squared_error": [40, 56, 62, 63], "mean_te_acc": 63, "mean_te_loss": 63, "mean_tr_acc": 63, "mean_tr_loss": 63, "meansquarederror": 40, "measur": [31, 33, 45], "mecanismo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 70], "mechan": [28, 32, 39, 68], "mec\u00e1nica": 15, "medic": [34, 67], "medio": [6, 7, 8, 9, 10, 11, 12, 13, 14, 18], "medir": 23, "medium": [35, 66], "meet": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "mejorando": 70, "memor": [31, 66], "memori": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 29, 43, 54, 63, 65], "memor\u00faa": 19, "mencionamo": 18, "meno": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23], "menor": 70, "meshgrid": 29, "messag": [20, 24, 39, 45], "method": [21, 24, 26, 30, 31, 32, 33, 37, 39, 40, 44, 62, 63, 64], "metodolog\u00eda": 19, "metric": [23, 25, 28, 30, 32, 35, 36, 37, 40, 44, 48, 49, 51, 53, 54, 56, 57, 58, 59, 62, 63, 64, 67, 68, 69], "metrics_nam": [48, 51], "mezclada": 23, "mh": 65, "mha": 65, "mhe": 65, "mi": [65, 66], "micro": 67, "microsoft": 1, "mida": 24, "middl": 48, "midst": 65, "miembro": [6, 7, 8, 9, 10, 11, 12, 13, 14], "mig": 54, "might": [25, 35, 39, 40, 42, 46, 51, 52], "mikolov": 64, "mild": 42, "min": [18, 23, 24, 29, 42, 43, 47, 48, 50, 52, 54, 55, 59], "min_delta": 31, "min_df": 64, "min_dim": 59, "mine": 64, "mini": [16, 29, 44, 63], "mini_cifar": [42, 44, 48, 49, 51, 53], "minibu": 50, "minim": [21, 24, 39], "minima": 29, "minimizaci\u00f3n": 24, "minimum": 44, "minist": 67, "minivan": 50, "minmaxscal": [61, 62], "minor": 67, "minu": 30, "minut": 54, "minx": 23, "mira": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "misma": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 23, 66], "mismo": [5, 16, 24, 66, 70], "miss": [22, 57, 62], "mistak": 29, "mit": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "mitigarlo": 16, "miv": 65, "mix": 67, "miyeet": 65, "ml": [15, 19, 29, 31, 40, 66], "ml_2020": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "ml_workflows_tool": 23, "mlcd": 65, "mldesign": [24, 39], "mlm": [58, 68], "mlp": [25, 37], "mlp2": 37, "mlp3": 37, "mlp_": 29, "mlp_class": 37, "mlpclassifi": 29, "mlutil": [23, 37, 40, 41, 42, 48, 49, 50, 51, 52, 54, 64], "mn": [26, 66], "mnist": [26, 27, 33, 34, 36], "mnist1": [26, 27, 28, 33, 34, 35, 36], "mo": 65, "moattdnt": 65, "mode": [31, 41, 47, 54, 57, 58, 63], "model": [1, 2, 12, 13, 14, 29, 31, 32, 38, 39, 41, 43, 46, 48, 49, 50, 51, 53, 54, 61, 62, 66, 68, 69], "model1": [61, 69], "model2": [30, 58, 67, 69], "model3": 61, "model3b": 61, "model4": 61, "model4b": 61, "model5": 61, "model5b": 61, "model6": 61, "model6c": 61, "model7": 61, "model8": 61, "model8b": 61, "model_1": [41, 46], "model_2": 41, "model_6": 46, "model_a": 48, "model_b": 48, "model_c": 48, "model_json": 65, "model_nam": [48, 51], "model_select": [23, 26, 27, 28, 33, 34, 35, 36, 40, 42, 44, 48, 49, 51, 57, 58, 59, 60, 66, 67], "modela": [46, 53], "modelar": 23, "modelb": [46, 53], "modelcheckpoint": [54, 65], "modelgendnnlstm": 65, "modelo": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 46], "modif": 66, "modifi": [64, 68], "modul": [36, 51, 54, 56, 57, 58, 59, 60, 66, 67, 68], "mof": 65, "mohit": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "moment": 51, "momento": 66, "momentum": [25, 30], "monei": 65, "monitor": 31, "monoton": 68, "montar\u00e1": 16, "month": [56, 67], "moonei": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "mope": 50, "more": [21, 26, 27, 29, 30, 32, 37, 39, 43, 54, 62, 63, 64, 66, 67, 68], "morn": 65, "morphologi": 54, "mortarboard": 52, "mose": 65, "most": [26, 29, 33, 45, 64, 66, 67], "mostli": [20, 22, 40], "mostramo": [15, 16, 17, 18], "motor": 17, "motor_scoot": 50, "motorbik": 50, "move": [35, 36, 62, 65, 69], "movi": 68, "moview": 68, "moving_mean": 38, "moving_var": 38, "mozilla": 64, "mse": [26, 27, 32, 38, 40, 46, 53, 56, 61, 64], "mse_loss": 32, "mseloss": 33, "msg": [33, 36, 50], "mte5xbvw1hedpxc7t3_": [66, 67], "mu": [38, 42, 62, 65], "much": [26, 42, 51, 62], "mucha": [18, 19, 23], "mucho": [18, 23, 24, 66], "muestr": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "muestra": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "muestrea": 23, "muestreado": 23, "muestrear": 23, "muestreo": 23, "mui": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 24], "mulpli": 62, "mult": 28, "multi": [30, 56, 67, 68], "multicapa": 16, "multidimension": 40, "multiheadattent": [58, 68], "multilay": 37, "multinomi": 65, "multipl": [28, 29, 30, 31, 32, 40, 58, 69], "multipleloc": 66, "multipli": [43, 47, 62, 68], "multivari": 19, "multivariado": 19, "multivariate_norm": 23, "music": 65, "musico": 66, "must": [21, 25, 26, 27, 28, 29, 30, 31, 32, 37, 38, 40, 41, 43, 44, 45, 52, 56, 57, 58, 59, 61, 63, 64, 66, 67, 69], "mvseri": 56, "my": [57, 66], "my_loss": 32, "my_model": 54, "myf": 40, "mylib": 20, "mymodel": [30, 32, 42], "mymodel2": 30, "m\u00e1": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24, 64], "m\u00e1ximo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "m\u00e9todo": 23, "m\u00e9trica": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "m\u00ednimo": 24, "m\u00f3dulo": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "m\u00faltipl": 16, "n": [21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 37, 38, 39, 40, 41, 43, 45, 52, 53, 54, 55, 57, 58, 59, 64, 65, 66, 68], "n02669723": 52, "n02701002": 50, "n02769748": 50, "n02777292": 52, "n02793495": 50, "n02814533": 50, "n02825657": 50, "n02859443": 50, "n02930766": 50, "n02971356": 52, "n03028079": 50, "n03445924": 50, "n03459775": 50, "n03534580": 50, "n03594945": 50, "n03617480": 52, "n03630383": 52, "n03769881": 50, "n03770679": 50, "n03785016": 50, "n03787032": 52, "n03791053": 50, "n03930313": 50, "n03977966": 50, "n04252077": 50, "n04336792": 52, "n04456115": 52, "n04479046": 52, "n04482393": 50, "n04507155": 52, "n1": [38, 65], "n2": 38, "n3": 38, "n_": [29, 64], "n_a": 52, "n_batch": [63, 65], "n_channel": [44, 47, 69], "n_char": [65, 67], "n_class": 27, "n_cluster": 45, "n_column": 69, "n_compon": 64, "n_cost": [24, 39], "n_dataset": 23, "n_epoch": 63, "n_featur": [56, 61, 63], "n_filter": [43, 53, 67], "n_grad": [24, 39], "n_h": 45, "n_imag": 44, "n_img": 47, "n_iter_no_chang": 29, "n_l": 42, "n_layer": 67, "n_model": 33, "n_neuron": 63, "n_pairs_per_class": 27, "n_partit": 63, "n_pattern": 65, "n_rep": 23, "n_row": 69, "n_sampl": [23, 29, 56, 61, 63, 69], "n_sent": 67, "n_step": [56, 61], "n_steps_ahead": 56, "n_steps_in": 61, "n_steps_out": 61, "n_tag": 67, "n_test": 63, "n_time": [56, 61, 63, 69], "n_train": 63, "n_vocab": 65, "n_w": 45, "n_word": 67, "n_x": 45, "n_y": 45, "na": 56, "nabla": [24, 29, 39], "nabla_": [61, 62], "naccuraci": 23, "nactiv": 28, "name": [20, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 40, 41, 48, 49, 51, 52, 53, 54, 56, 57, 58, 61, 62, 64], "namespac": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "nan": [25, 56], "nand": 65, "nandan": 68, "nanonet": 54, "nat": 67, "nativ": [54, 66], "nativo": 66, "natur": [19, 22, 40, 64, 66], "naturaleza": 16, "navegador": 18, "navig": 20, "nb": 42, "nb_class": [25, 30, 69], "nbcrllh": 65, "nc": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "nd": 65, "ndim": 69, "ndistribut": [42, 48, 51], "ndone": 65, "nearest": [25, 30, 33, 34], "neccessari": [57, 58], "necesaria": 19, "necesariament": 23, "necesario": 24, "necesidad": 17, "necesit": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16], "necesita": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "necesitamo": 23, "necessari": [31, 57, 66, 67], "necessarili": 47, "nee": 52, "need": [12, 13, 14, 20, 26, 32, 38, 43, 50, 54, 61, 62, 64, 66, 67, 68], "neg": [45, 57, 58, 64], "negativo": 19, "neglig": 35, "negocio": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "negro": 23, "neither": 31, "neptun": 54, "neq": [29, 64], "ner_dataset": 67, "nerv": 54, "nesterov": [25, 30], "net": [29, 44, 46, 54], "network": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 25, 26, 27, 33, 35, 37, 42, 50, 56, 62, 64, 65, 67, 68], "neural": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 26, 30, 42, 50, 51, 63, 64, 65, 68], "neural_network": 29, "neurolab": 29, "neuron": [16, 17, 23, 25, 26, 27, 29, 33, 34, 37, 42, 43, 44, 46, 56, 57, 58, 59], "neurona": 66, "neuronal": [5, 16, 18], "neutral": [57, 58], "never": [31, 66], "new": [25, 27, 29, 32, 34, 42, 44, 54, 62, 63, 64, 65, 67, 68, 69], "new_model": [63, 65], "new_seq": 67, "new_x": 67, "newaxi": [29, 61], "newff": 29, "newx": [57, 67], "next": [30, 54, 56, 62, 65, 66, 68], "nfd": 66, "nfev": [24, 39], "nfilter": 53, "nfrom": 65, "ngram_rang": 64, "nh": 45, "ni": 65, "nice": [58, 64], "nicn": 65, "night": 65, "nit": [24, 39], "nivel": [16, 18, 19, 48], "nj": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "njev": [24, 39], "nl": 29, "nlayer": 49, "nloss": 25, "nlp": [19, 64, 67], "nltk": [57, 58, 64, 65, 66, 67], "nltk_data": [64, 65, 67], "nmorn": 65, "nn": [30, 35, 48, 49, 51, 57, 58, 66], "nnlm": 64, "nntype": 22, "nnum": 42, "no_regular": 37, "nocion": 16, "noci\u00f3n": [15, 16, 17, 18], "node": 64, "nois": [29, 37, 42, 49, 62], "noise_level": 33, "noise_shap": 51, "noisi": [29, 31], "nombr": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "nombrado": [12, 13, 14], "non": [19, 25, 27, 29, 30, 33, 34, 36, 40, 44, 46, 48, 49, 50, 51, 53, 54, 57, 58, 59, 61, 62, 64, 66, 68, 69], "none": [23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 37, 38, 40, 41, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 62, 64, 66, 67, 69], "norm": [23, 31, 37, 44], "normal": [23, 25, 30, 33, 40, 44, 47, 48, 49, 51, 57, 58, 61, 62, 64, 65, 66], "normalizado": 56, "normalment": 23, "normil": 68, "nos": [18, 23], "noskip": 46, "nota": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "notaci\u00f3n": 24, "notat": [25, 61], "note": [20, 25, 26, 29, 30, 32, 37, 38, 56, 57, 58, 59, 60, 62, 65, 67, 68], "notebook": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 29, 36, 44, 46, 54, 69, 70], "notic": 40, "notion": 40, "notopensslwarn": [66, 67], "nov": [2, 8, 9, 12, 14], "now": [26, 27, 28, 32, 33, 37, 39, 40, 41, 44, 45, 53, 54, 55, 56, 57, 62, 68], "nowadai": 22, "np": [21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69], "np_util": [65, 69], "npz": 68, "nred": 42, "nshape": 54, "nsp": [58, 68], "nt": 64, "ntarget": 27, "nthe": 65, "nube": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 70], "nuclei": 54, "nuestra": 17, "nuestro": [16, 18, 23, 24], "nuevo": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18], "null": [51, 54], "num": [42, 69], "num_class": [42, 44, 48, 49, 51, 65], "num_exampl": 66, "num_head": [58, 68], "num_hidden_lay": [28, 35], "num_step": 65, "num_word": [58, 64, 67, 68], "number": [20, 21, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 37, 40, 42, 45, 48, 52, 56, 57, 58, 59, 60, 62, 64, 68, 69], "numer": [25, 34, 39, 40, 42], "numerado": [12, 13, 14], "numpi": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69], "num\u00e9rico": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "nunca": 23, "nunder": 65, "nvidia": 54, "nw": 45, "nwater": 65, "nwe": 30, "nweight": 28, "nwjikfefqxp7jdmavkch9gxxdvnpsajakrnfzi0eadeug5qo0u5o2ddmsac8c0s4u6o9ne6ryjpmlwz": 45, "nx": 45, "ny": 45, "n\u00famero": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24], "o": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], "o0_aft": 36, "o0_befor": 36, "o_i": 61, "o_l": 62, "object": [21, 25, 30, 31, 35, 36, 37, 40, 49, 57, 61, 64, 65, 67, 69], "objecto": 18, "objetivo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 23], "objeto": [16, 19], "observ": [20, 21, 25, 26, 27, 28, 30, 32, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 56], "observa": 24, "observacion": 19, "observando": 16, "observar": 16, "obtain": [25, 31, 32, 33, 40, 42, 43, 44, 45, 48, 52, 55], "obten": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19, 23], "obtenci\u00f3n": 17, "obtendr\u00e1": 5, "obtenida": 23, "obtenido": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "occur": 64, "occurr": 64, "oct": [8, 9, 12, 14], "octet": [42, 48, 49, 51], "oculta": 19, "ocurr": 64, "odd": 34, "odot": 61, "off": [23, 26, 29, 33, 43, 44, 47, 48, 50, 53, 54, 55], "offer": [28, 33, 64, 65, 66], "offic": 67, "offici": 67, "offset": 52, "ofici": [2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ofrecen": 18, "often": 38, "oh": 65, "oi": 65, "oidv6": 45, "oil": 67, "ok": [28, 29, 42, 46, 48, 49, 51, 52, 54, 67], "old_weight": [63, 65], "olvid": 23, "on_batch_begin": 63, "on_epoch_end": 28, "onc": [30, 56, 57, 59, 65, 66, 69], "one": [20, 21, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 44, 45, 46, 47, 48, 52, 53, 55, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68], "one_hot": 34, "one_index": 63, "ones": [25, 29, 39, 47, 52, 58, 64, 69], "oni": 27, "onl": 56, "onli": [0, 20, 31, 32, 40, 41, 43, 44, 48, 49, 51, 53, 54, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68], "op": [26, 32], "open": [18, 20, 44, 45, 48, 51, 52, 57, 59, 62, 65, 66, 67], "openimag": [45, 52], "openimages_boxes_0003bb040a62c86f": 52, "openssl": [66, 67], "oper": [26, 31, 32, 40, 43, 47, 53, 55, 68, 69], "operacion": 18, "operaci\u00f3n": 18, "oportuno": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "oposit": 31, "opt": [23, 57, 58], "optim": [21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 44, 46, 48, 49, 51, 53, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 69], "optimi_surfac": 29, "optimizaci\u00f3n": 16, "optimum": 29, "option": [20, 29, 37, 56, 57, 58, 67], "option1": 61, "option2": 61, "optional_featur": 41, "orandxor": 29, "ordenadament": [12, 13, 14], "ordenado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "order": [29, 31, 40, 56, 57, 59, 64, 65, 66, 68, 69], "org": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 22, 28, 37, 38, 40, 50, 52, 64, 66, 67], "organ": [20, 56], "organiza": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18], "organizaci\u00f3n": [17, 18], "origin": [27, 33, 43, 52, 54, 55, 56, 62, 66, 68], "orthodox": 32, "other": [20, 21, 26, 27, 29, 30, 31, 34, 42, 45, 47, 50, 53, 56, 58, 61, 67, 68], "otherwis": [27, 35], "otra": [19, 66], "otro": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 48, 64], "otros_notebook": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ouput": [58, 61], "our": [20, 28, 32, 33, 34, 40, 44, 52, 53, 62, 67, 69], "ourselv": 32, "out": [12, 13, 14, 20, 23, 26, 29, 31, 33, 36, 37, 41, 45, 53, 64, 66, 67, 68], "out1": 68, "out_group": 67, "out_i": 67, "out_put": 67, "outp": [48, 49], "output": [20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69], "output_1": [48, 49, 51], "output_at_lay": [38, 48], "output_dim": [28, 35, 36, 64, 66, 67, 68], "output_kei": 67, "output_lay": [36, 51], "output_sequence_length": 66, "output_shap": [50, 52, 64], "output_target": 67, "outsid": [37, 67], "over": [26, 28, 46, 47, 49, 64, 66, 67], "overal": 66, "overcom": [52, 62], "overfit": [16, 23], "overflow": 64, "overlap": [52, 61], "overlin": [24, 39], "overpass": 29, "overview": 17, "ovidiu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "ovr": 23, "owdjryupng": 29, "own": [26, 32, 64], "p": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 23, 24, 36, 49, 52, 59, 64, 65, 67], "p0": 27, "p1": [27, 46, 54], "p2": [46, 54], "p3": 54, "p4": 54, "p8": 54, "p_": [25, 30], "p_h": [45, 52], "p_i": [44, 67], "p_w": [45, 52], "pa": 47, "packag": [23, 33, 35, 36, 40, 49, 50, 64, 65, 66, 67], "pad": [43, 47, 48, 51, 53, 54, 55, 58, 64, 66, 67, 69], "pad_sequ": [66, 67, 68], "padword": 67, "page": 44, "pahs": 58, "pai": [56, 66, 68], "paint": 45, "pair": [16, 27, 30, 64, 65, 66], "pair_0": 27, "pair_1": 27, "pairup": 27, "pairwis": 64, "palabra": 19, "pamestard": 65, "panda": [20, 24, 26, 27, 28, 32, 33, 34, 35, 36, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67], "pantalla": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "paper": [48, 51, 52, 64, 68], "paquet": 19, "para": [5, 15, 16, 17, 18, 19, 23, 24, 70], "paradaanticipada": 31, "paradigm": 61, "paradigma": 15, "paradigmat": 64, "paragraph": 64, "parallel": [29, 61, 68], "param": [25, 27, 30, 33, 34, 36, 40, 44, 46, 48, 49, 50, 51, 53, 54, 61, 62, 64, 66, 68, 69], "paramet": [25, 30, 31, 37, 40, 41, 42, 43, 44, 48, 53, 54, 56, 57, 58, 59, 62, 63, 64, 65, 68], "parametr": [28, 31, 35], "paratem": 62, "parch": 18, "parcial": [19, 24], "pare": 16, "pargraph": 67, "pars": [56, 64], "parse_d": [56, 60, 62], "parsed_articl": 64, "part": [6, 7, 8, 9, 10, 11, 12, 13, 14, 25, 26, 48, 56, 57, 58, 59, 61, 62, 64, 67, 68], "parten": 23, "partial": [24, 29, 35, 38, 39, 60, 61], "particip": [27, 32, 37, 38], "participaci\u00f3n": 24, "particular": 19, "particularidad": 19, "particularli": 52, "partida": 18, "partiendo": 23, "partimo": 23, "partir": [19, 24], "partit": [52, 63], "par\u00e1metro": [19, 23], "pasado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "pass": [25, 30, 31, 35, 36, 37, 40, 44, 45, 49, 56, 57, 58, 59, 62, 65, 66, 68], "passeng": [57, 60, 61], "past": [56, 62, 67], "patch": 45, "path": [31, 40, 54, 59, 66], "path_to_fil": 66, "path_to_zip": 66, "pathcollect": [37, 52], "patienc": [31, 54], "patient": 44, "pattern": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 33, 65, 69], "pb": 47, "pbar": [40, 42, 54], "pcolormesh": 29, "pd": [20, 24, 26, 27, 28, 32, 33, 34, 35, 36, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 67], "pdf": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 64], "pe": 65, "pe_": 58, "pearson": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "peephol": 69, "penal": [26, 29, 31], "penalizaci\u00f3n": [12, 13, 14], "penalizada": [6, 7, 8, 9, 10, 11, 12, 13, 14], "penguin": 44, "peopl": 65, "peque\u00f1o": 23, "per": [28, 29, 33, 39, 40, 41, 43, 57, 64, 66, 67], "perc": 36, "percentag": [27, 64, 68], "percentil": 36, "perceptron": [16, 18, 37], "perceptron_": 29, "perceptronexampl": 29, "perceptr\u00f3n": 16, "perclass_bin_accuraci": 27, "perdict": 66, "peresentamo": 19, "perf": 54, "perform": [29, 30, 31, 35, 40, 43, 46, 57, 64, 67, 69], "performance_rtx": 63, "perm": [33, 34], "permit": 19, "permiten": 19, "permut": [26, 30, 33, 34, 40, 42, 45, 48, 54], "pero": [12, 13, 14, 24], "persist": [20, 36, 40, 54], "person": 52, "persona": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19], "perspectiva": [15, 16], "pertinencia": 18, "pertinent": [1, 2], "ph": 45, "phase": [31, 58, 62, 68], "phd": 48, "phenomena": 62, "phenomenon": [29, 31], "philipperemi": 63, "phone": 67, "phrase": [64, 66], "pi": [39, 69], "pia": 65, "pick": 65, "picket_f": 50, "pickl": [51, 57], "pictur": 65, "pid": 54, "pimg": [43, 52], "pink": 46, "pinta": 23, "pintaresultado": 61, "pip": [29, 44, 54, 56, 57, 58, 59, 67], "pixel": [43, 44, 47, 49, 50], "pixels_height": 47, "pixels_width": 47, "pkl": 57, "pklz": 51, "place": [20, 66, 68], "plai": 66, "planificaci\u00f3n": 18, "plano": 23, "plantea": 18, "planteamo": 15, "plantear": 23, "plataforma": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 70], "platform": [20, 64], "player": 66, "pleas": 37, "plot": [21, 23, 24, 25, 28, 29, 31, 33, 34, 35, 36, 40, 42, 47, 50, 56, 60, 61, 62, 66], "plot_2d_boundari": 23, "plot_2ddata": [23, 49], "plot_2ddata_with_boundari": [23, 37, 49], "plot_attent": 66, "plot_confusion_matrix": [48, 51], "plot_cost": 24, "plot_epoch": 28, "plot_estimator_bord": 23, "plot_hist": 42, "plot_img_with_histogram": 52, "plot_model": 24, "plot_pacf": 60, "plot_sentiment_perform": 57, "plot_sgd_trajectori": 29, "plot_task2": 56, "plot_z_histori": 42, "plotcrossvalidationt": 60, "plotcrossvalidationts_gap": 60, "plotvalidationtimeseri": 60, "plt": [21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69], "plu": 58, "pmahzewvq": 45, "png": [20, 22, 23, 25, 26, 27, 29, 31, 34, 40, 43, 45, 46, 48, 52, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69], "po": [58, 67], "poco": 23, "podemo": [15, 16, 17, 18, 23, 24], "poder": [16, 18, 24, 70], "podr\u00e1": 16, "podr\u00e1n": [6, 7, 8, 9, 10, 11, 12, 13, 14], "poiest": 65, "point": [24, 25, 29, 31, 42, 63, 66, 69], "pointeur": 64, "police_van": 50, "polinomi": 31, "polit": 67, "pollut": 56, "poltipd": 65, "polymorphic_funct": 40, "polynomi": 31, "ponemo": 16, "poner": 23, "ponerlo": 18, "pool": [18, 58, 67], "pool_emb": 58, "pool_siz": [51, 54, 69], "pooled_output": 58, "pop": 23, "popular": [66, 67], "por": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23], "porqu": 23, "pos_emb": 68, "pos_embed": 58, "pose": 31, "posgrado": [1, 12, 14], "posibilidad": [12, 13, 14], "posibilit\u00f3": 15, "posibl": [1, 2, 23, 24, 64], "posici\u00f3n": 19, "posit": [21, 23, 38, 45, 47, 49, 57, 58, 64, 68], "positional_embed": 58, "positional_or_keyword": 41, "positivo": 19, "possibl": [26, 31, 40, 53], "post": [40, 52, 62, 66, 67], "posterior": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "potenci": 17, "potenti": 31, "power": [60, 64, 66], "pp": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "pr": 52, "practic": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 65, 66, 67], "practica": 66, "practicar": 66, "pradeep": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "pre": [19, 27, 28, 46, 57, 58, 67, 68], "prebuilt": 33, "precis": [26, 67], "precision_scor": 67, "pred": [24, 25, 27, 30, 40, 42, 48, 50, 52, 65, 66, 67], "pred2label": 67, "pred_i": 67, "pred_label": 67, "predecir": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19], "predefin": 32, "prediccion": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 23], "predicci\u00f3n": [16, 19, 39], "predict": [19, 20, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 37, 40, 42, 48, 49, 50, 51, 53, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 69], "predicted_id": 66, "predicted_sent": 66, "predicted_stock_pric": 62, "prediga": 24, "preds_t": 27, "preds_test": [34, 54], "preds_test_t": 54, "preds_test_upsampl": 54, "preds_tr": 27, "preds_train": [34, 54], "preds_train_t": 54, "preds_val": 54, "preds_val_t": 54, "preentrenada": 18, "prefer": [35, 36, 40, 49], "pregrado": [1, 3, 4, 5, 6, 8, 10, 12, 13, 14], "pregreado": 12, "pregunta": 23, "preg\u00fantat": 23, "prejifo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "prentic": 29, "prepar": [30, 58, 62, 64, 65, 67, 68], "prepare_img": 43, "prepare_sequ": 63, "prepare_text_for_cbow": 64, "preprocesado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "preprocesamiento": 19, "preprocess": [25, 30, 57, 58, 59, 61, 62, 64, 66, 67, 68], "preprocess_sent": 66, "preprocessed_seq": 58, "preprocessed_text": 58, "present": [52, 64], "presentaci\u00f3n": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "presentamo": 19, "presentan": [18, 19], "preserve_rang": 54, "press": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 56], "prestado": 66, "pretend": 26, "pretrain": [51, 64], "pretty_printed_concrete_signatur": 41, "preven": 31, "prevent": [25, 31, 68], "previa": 18, "previament": 18, "previo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "previou": [25, 26, 35, 37, 42, 43, 46, 52, 55, 56, 57, 62, 63, 65, 66], "previous": [26, 37, 68], "price": [60, 61, 62], "prime": 67, "primer": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 48], "primera": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "primero": 23, "princip": [15, 16, 19], "principal": 19, "principio": [18, 19], "principl": 62, "print": [21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "printoverfittingclassifi": 31, "printoverfittingreg": 31, "prior": 18, "prison": 67, "privaci": 20, "prob": 44, "proba": 65, "probabl": [23, 25, 30, 35, 44, 52, 64, 65, 67], "problem": [30, 31, 35, 54, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68], "problema": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19], "proce": 64, "procedimiento": [15, 19], "procedur": 67, "proceed": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "procesado": 64, "procesar": 19, "proceso": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 23], "process": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 28, 29, 30, 31, 52, 54, 56, 57, 58, 59, 61, 63, 65, 67, 68], "processed_articl": 64, "prod": 45, "produc": [23, 31, 32, 37, 38, 47, 65], "produciendo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "product": [24, 43, 50, 53, 61, 67, 68], "producto": 23, "produzca": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "profession": 66, "profunda": 19, "program": 64, "progress": 28, "progressbar": [40, 42, 54], "proj": 67, "project": [57, 67], "promedio": 23, "pronounc": 64, "propag": [29, 35, 61], "propagacion": 19, "propagaci\u00f3n": 19, "properti": 32, "propia": [12, 13, 14, 17], "propio": [6, 7, 8, 9, 10, 11, 12, 13, 14], "proport": 35, "propos": [52, 62, 68], "propto": 35, "propuesta": 18, "protest": 67, "protocolo": [12, 13, 14], "provid": [27, 30, 32, 39, 52, 57, 58, 61, 64, 66, 67, 68], "proxi": 52, "prubea": 23, "prueba": 23, "pr\u00e1ctica": [16, 17], "pr\u00e1ctico": [15, 16, 18], "pub": 64, "public": 50, "publicado": 18, "publicli": 40, "publish": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 44], "pued": [1, 2, 6, 7, 8, 9, 10, 11, 18, 19, 23, 70], "pueda": 19, "puedan": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 66], "pueden": [12, 13, 14, 16, 18, 19], "puedo": 66, "puend": 64, "puenden": 64, "pujari": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "pullov": [25, 30], "punctuat": [64, 66], "punkt": [57, 67], "punkt_tab": [58, 64], "punto": [5, 17, 18], "puntualizamo": 16, "pure": 47, "purpos": [56, 57, 68], "push": 62, "pw": 45, "pwr": 54, "px": 27, "px0": 27, "px1": 27, "px_cifar": 53, "pxt": 27, "pxtr": 27, "py": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "py0": 27, "py1": 27, "pyplot": [21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69], "pyramid": 18, "pyt": 27, "python": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 21, 35, 37, 38, 40, 53, 60, 61, 64, 66, 70], "python3": [23, 33, 35, 36, 40, 49, 50, 64, 66, 67], "python_funct": 41, "pytohn": 40, "pytr": 27, "p\u00e1gina": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "p\u00e9rdida": [16, 17, 18, 24], "p\u00fablico": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "q": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "quad_predict": 24, "qualiti": [53, 66], "quantiti": 29, "que": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 64, 66, 70], "queda": 24, "queramo": 23, "queremo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 24], "queri": [66, 68], "query_with_time_axi": 66, "question": [33, 66], "quick": 54, "quien": 19, "quier": 66, "quiera": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "quieran": 19, "quiet": 59, "quit": [30, 32, 54], "qusi\u00e9ramo": 23, "qu\u00e9": [15, 19, 24], "qwjylrrvddcqi8uc": 45, "r": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 21, 24, 26, 27, 29, 31, 33, 36, 37, 38, 39, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 57, 60, 62, 64, 65, 66], "r1": 24, "r2": 24, "r_": [23, 24, 32, 39, 40, 42, 43, 45, 47, 48, 51, 53, 55, 69], "r_t": 62, "rag": [36, 51], "rain": 56, "rais": 41, "ram": [19, 29], "ramo": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "randint": [21, 24, 25, 27, 34, 37, 38, 44, 45, 48, 49, 52, 53, 65], "randn": [41, 63, 69], "random": [20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 41, 42, 44, 45, 48, 49, 50, 52, 53, 54, 57, 62, 63, 64, 65, 66, 68, 69], "random_img": [33, 34], "random_label": [33, 34], "random_norm": [37, 40, 42], "random_st": [23, 29, 45, 57, 58, 59, 67], "randomforestclassifi": 23, "randomli": [27, 33, 37, 45, 49], "randomnorm": 36, "rang": [23, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 36, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 67, 68, 69], "rank": 64, "rapidli": 35, "rare": 64, "rate": [29, 49, 51, 57, 58, 59, 65, 68], "rather": [20, 40, 54, 64], "ratio": 64, "raul": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "raw": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "raw_text": 65, "razon": 19, "rb": 67, "rbf": 23, "rdbu": 42, "re": [29, 53, 57, 58, 63, 64, 65, 66], "reach": [29, 35, 66], "read": [28, 59, 62, 64, 66, 67], "read_csv": [20, 24, 26, 27, 28, 32, 33, 34, 35, 36, 39, 40, 45, 52, 56, 57, 58, 59, 60, 61, 62, 67], "readi": 20, "readinsg": 68, "readlin": 44, "readm": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "real": [15, 23, 29, 30, 31, 61, 62], "realic": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "realidad": [23, 24], "realiza": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 23], "realizada": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "realizamo": [17, 18, 23], "realizando": 19, "realizar": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19], "realizarl": 16, "realizars": [6, 7, 8, 9, 10, 11, 12, 13, 14], "rearrang": 43, "reason": 64, "recabar": 23, "recal": [32, 33, 35, 36, 40, 42, 45, 67], "recall_scor": [57, 58, 67], "recap": 68, "receiv": [33, 36, 43, 47, 50, 56], "recent": [29, 40, 50, 67], "recept": 55, "recibir\u00e1": [6, 7, 8, 9, 10, 11, 12, 13, 14], "recogn": 37, "recognit": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 50, 51, 59, 61, 69], "recomendamo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "recommend": [20, 44, 54, 65, 68], "reconcil": 40, "reconstruct": [29, 33, 53], "record": 54, "recov": 53, "rectangl": [45, 52], "recuerda": 23, "recurr": [56, 58, 59, 65, 66, 67, 68], "recurrent_dropout": 67, "recurrent_initi": 66, "recurrent_model": [56, 57], "recurrent_model_": 56, "recurrent_model_mo": 56, "recurrent_model_tf": 57, "recurs": [41, 66], "red": [16, 17, 18, 19, 23, 24, 37, 47, 52, 62], "redacta": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "rede": 5, "reduc": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 31, 33, 42, 51, 53, 64, 67], "reducci\u00f3n": 18, "reduce_max": 67, "reduce_mean": [25, 26, 32, 33, 40, 41, 42, 66], "reduce_retrac": 37, "reduce_sum": [25, 66], "reducir": 18, "reduct": [31, 66], "reentrena": 23, "ref": 53, "refer": [20, 37, 52, 56, 64, 66], "referencia": 16, "reflect": 69, "reforzar": 18, "reg": [31, 37], "regardless": 32, "regin": 36, "region": 18, "regist": 20, "registered_nam": [36, 51], "registr": [12, 13, 14], "registra": [25, 26, 27, 28, 37, 38, 43, 44, 45, 46], "registrart": 70, "regla": [12, 13, 14], "regresi\u00f3n": [15, 17, 23, 24], "regress": [31, 52], "regressor": 62, "regressor2": 62, "regul": [26, 37, 47], "regular": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 26, 29, 33, 37, 39, 40, 42, 49, 53, 55, 61, 62], "regularis": 62, "regularizaci\u00f3n": [16, 18], "regularizador": 16, "regularli": 20, "regulir": 31, "reg\u00edstrat": 5, "reilli": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "reinforc": [23, 64], "rekognit": 48, "rel": [45, 68], "relacionado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relaci\u00f3n": 24, "relat": [48, 57, 63], "releas": 59, "relev": 64, "relevant": 19, "reliabl": 22, "rellena": [3, 12, 13, 14], "rellenado": [8, 9, 10, 11, 12, 13, 14], "rellenando": [4, 5, 6, 7, 70], "rellenar": [8, 9, 10, 11, 12, 13, 14], "reload": [23, 37, 42], "reload_ext": [37, 42], "relu": [21, 25, 26, 28, 33, 34, 36, 37, 41, 42, 43, 44, 46, 47, 48, 49, 51, 57, 58, 61, 62, 66, 67, 68, 69], "remain": 66, "remeb": 57, "rememb": [25, 30, 33, 38, 54, 58, 62, 63, 67], "remenb": 62, "remov": [20, 57, 58, 60, 64, 66, 67], "remuestrea": 23, "render": 20, "rendererd": 20, "rendimiento": 17, "reorder": 39, "repeat": [29, 43, 56, 58], "repeat_vector": [61, 66], "repeatedli": 37, "repeatvector": [61, 66], "repetit": 61, "repit": 68, "repitiendo": 23, "replac": [27, 29, 30, 57, 58, 63, 64, 66, 67, 69], "replic": [34, 35, 40, 43, 44, 48, 49, 50, 51, 52, 53, 54, 65, 67], "repo": [0, 54], "report": [3, 4, 28, 67], "repositori": 67, "repositorio": [3, 4, 6, 7, 8, 9, 10, 11, 18], "repres": [31, 34, 40, 50, 52, 62, 64, 67], "represent": [19, 26, 30, 33, 34, 65, 67, 68], "representa": [19, 23], "representaci\u00f3n": 16, "representet": 64, "reproduc": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 54], "reproducibilidad": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "req": 64, "requerimiento": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "request": [42, 48, 49, 51, 52, 54, 64], "requir": [19, 20, 26, 29, 30, 32, 37, 38, 41, 43, 48, 56, 57, 58, 59, 63, 64, 65, 66], "research": 64, "reserv": 57, "reset": [62, 63, 65], "reset_st": [32, 63], "resetstatescallback": 63, "reshap": [23, 24, 25, 26, 27, 29, 30, 33, 34, 36, 37, 40, 43, 44, 45, 46, 47, 49, 50, 52, 53, 55, 56, 61, 62, 63, 65, 66, 67], "reshape_128x128x1": 46, "reshape_128x128x3": 46, "residu": [67, 68], "residual": 18, "resiz": [44, 50, 52, 54, 55, 59], "resnet": [18, 50], "resolucion": 18, "resoluci\u00f3n": 15, "resolut": [52, 55], "resolv": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 42, 48, 49, 51, 52, 54], "resourc": [12, 13, 14, 20, 34, 35, 40, 43, 44, 48, 49, 50, 51, 52, 53, 54, 64, 65, 67], "respect": [25, 29, 30, 35, 38, 42, 61, 68], "respecto": [18, 23, 24, 64, 68], "respond": 67, "respons": [12, 13, 14, 42, 45, 48, 49, 51, 52, 54, 64], "respositorio": 19, "rest": [57, 61], "resto": [4, 6, 7, 8, 9, 10, 11], "restor": 66, "restore_best_weight": 31, "restrict": 31, "resuelven": 19, "result": [21, 26, 27, 29, 32, 33, 38, 41, 43, 47, 53, 54, 55, 56, 57, 58, 61, 62, 66, 68], "resultado": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18], "ret": [41, 59, 64], "retinanet": 52, "reto": 18, "retrac": 37, "retriev": 28, "return": [20, 21, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69], "return_all_lay": 67, "return_sequ": [61, 63, 65, 66, 67, 69], "return_st": 66, "returnseq": 61, "retval_": 41, "reus": 41, "reutilizar": 18, "review": [50, 57, 68], "revisamo": 18, "revisar": 70, "rezaul": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "rf": [35, 36, 37, 40, 59], "rgb": 43, "rid": 62, "ridg": 31, "right": [25, 29, 31, 43, 54, 56, 58, 61, 62, 64, 68, 69], "rightarrow": [21, 23, 24], "rigor": 53, "rimg": [44, 52], "ringneck": 44, "rise": 31, "river": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "rlx": [42, 44, 48, 49, 51, 53, 54], "rlxmoocapi": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "rm": [29, 35, 36, 37, 40, 59], "rmse": [40, 46, 56, 61, 62], "rmsprop": [64, 65], "rn": 59, "rnn": [19, 48, 56, 57, 63], "rnn2": 61, "rnn3": 61, "rnn_arc_3": 66, "rnn_tbptt_2": 63, "rohrbach": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "role": [15, 23], "room": 54, "root": [51, 60, 62, 65], "rotat": [25, 30, 52, 66], "round": [25, 29, 45, 57, 58, 59, 69], "routput": 53, "row": [27, 43, 48, 52, 56, 57, 58, 64, 69], "rp6ij5wln": 45, "rramosp": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "rrswbphev006": 50, "rstrip": 44, "rt": [57, 58], "ruido": 16, "rule": [29, 62], "run": [20, 25, 26, 29, 37, 38, 39, 41, 42, 43, 48, 51, 54, 56, 57, 58, 59, 62, 65], "run_eagerli": 51, "runtim": 44, "runtimewarn": [23, 64], "rv": 23, "rw": 51, "rw10h4p11w183sngnfybnwp40000gn": 69, "r\u00e1pida": [1, 2], "s1": 34, "s2": 34, "s3": [34, 42, 44, 48, 49, 51, 53, 54], "s3_activ": 34, "s_cost": 39, "s_grad": 39, "sabemo": 23, "saber": [23, 24], "sabernacl": 65, "saddl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 29], "saenko": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "safari": 64, "sai": [66, 67], "said": [22, 65, 67], "sake": [65, 67], "sald": 65, "salida": [16, 18, 19, 24], "same": [20, 26, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 41, 43, 46, 48, 52, 53, 54, 55, 56, 57, 58, 59, 62, 66, 67, 68, 69], "same_class": 27, "sampl": [23, 29, 30, 31, 33, 43, 45, 52, 53, 56, 57, 58, 61, 64, 66, 67], "sample_bord": 23, "sample_decoder_output": 66, "sample_hidden": 66, "sample_img": [43, 55], "sample_output": 66, "sandal": [25, 30], "sane": 65, "saniti": 54, "santa": 3, "saturdai": 67, "save": [29, 42, 48, 49, 51, 52, 54, 56, 59, 65, 66], "save_best_onli": 54, "save_model": 54, "save_weight": 65, "savefig": 62, "saw": 65, "sc": 62, "scalar": 69, "scale": [23, 40, 42, 50, 51, 62], "scale_x": 36, "scaler": [25, 30, 56, 61], "scatter": [23, 24, 29, 32, 37, 39, 40, 45, 52, 64], "schema": 45, "scheme": [64, 67], "schmidhub": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "scienc": [46, 54], "science_engin": 23, "scientif": 64, "scikit": 32, "scipi": [21, 23, 24, 39, 42, 47, 64], "score": [23, 42, 61, 63, 64, 66, 67, 68], "score_func": 23, "scratch": [12, 13, 14], "screenshot": 40, "scx2": 44, "se": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 56, 64], "sea": [19, 23, 44, 52, 64, 65], "search_term": 64, "season": 60, "sebsequ": 63, "sec": 66, "secci\u00f3n": 23, "second": [25, 26, 38, 41, 43, 47, 65, 67, 68], "section": [25, 54], "secuencia": 19, "secuencial": 19, "sed": 59, "see": [20, 26, 27, 30, 31, 33, 35, 38, 39, 40, 42, 43, 45, 47, 48, 49, 50, 52, 53, 54, 55, 62, 63, 65, 66], "seed": [36, 41, 51, 54, 65], "seek": 33, "seem": [33, 40, 54], "seen": [39, 42], "segment": [53, 58, 66, 67], "segmentaci\u00f3n": 46, "seguida": 18, "seguimiento": 16, "seguimo": 15, "seg\u00fan": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23], "seke": 65, "sekh": 65, "seleccionada": 24, "seleccionar": 19, "select": [27, 31, 56, 65], "self": [19, 26, 27, 28, 30, 32, 33, 34, 37, 40, 42, 58, 63, 65, 66, 67], "sem": 65, "semana": 3, "semant": [52, 53, 54, 55, 64], "semestr": [2, 3, 4, 5, 6, 7, 8, 9, 11], "semidefinit": 23, "sem\u00e1ntica": 46, "sen": 67, "sencillez": 18, "sencillo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24], "sens": [42, 45, 58, 68], "sensit": [40, 57, 58, 62], "sent": [42, 48, 49, 51, 52, 54, 57, 58, 64, 67], "sent_input": 67, "sent_token": 64, "sentec": 68, "sentenc": [57, 58, 64, 66, 67, 68], "sentence_bleu": 66, "sentencegett": 67, "sentences_to_char_id": 67, "sentiment": [19, 58, 61, 64], "senvart": 65, "sep": [8, 9, 12, 14, 51, 54], "separ": [25, 51], "separa": 23, "seq": [19, 61, 67], "seq_in": 65, "seq_len": 67, "seq_length": 65, "seq_out": 65, "seqev": 67, "sequenc": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 34, 35, 40, 43, 48, 49, 50, 52, 53, 54, 58, 66, 67, 68, 69], "sequence_length": 66, "sequence_output": 58, "sequenti": [25, 26, 28, 34, 35, 36, 38, 43, 44, 49, 56, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69], "sequential_1": [30, 61, 62, 66], "sequential_2": [61, 62, 66], "sequential_3": 69, "sequential_4": 61, "sequential_5": 69, "sequential_6": [61, 64], "sequential_64": 25, "sequential_7": 61, "sequential_8": 61, "ser": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 64], "seren": 65, "seri": [19, 31, 42, 48, 51, 52, 62], "serial": 65, "servant": 65, "servic": [44, 65], "servicio": 18, "ser\u00e1": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "session": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "session_id": [27, 28], "set": [20, 25, 29, 30, 31, 33, 38, 41, 43, 44, 45, 46, 47, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "set_arrai": 69, "set_floatx": 36, "set_major_loc": 66, "set_memory_growth": 69, "set_se": 49, "set_titl": [33, 34, 57], "set_weight": [28, 38, 43, 47, 51, 53, 55, 63, 65], "set_xlabel": [29, 57], "set_xtick": 57, "set_xticklabel": [33, 34, 57, 66], "set_ydata": 29, "set_ylabel": 29, "set_ylim": 29, "set_yticklabel": [33, 34, 66], "setgrad": 20, "seventh": [48, 65], "sever": [20, 22, 29, 32, 34, 64, 68], "sevt": 65, "sewak": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sfnha": 65, "sgd": [25, 29, 30, 32, 42], "sgn": 29, "shad": 65, "shall": 65, "shalt": 65, "shape": [23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "share": 30, "sharon": 67, "sharper": 55, "shat": 65, "she": 65, "sherg": 65, "shift": [17, 43], "shift_x": 36, "shirt": [25, 30], "short": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19], "shorter": 58, "should": [20, 21, 25, 26, 27, 28, 30, 35, 37, 38, 43, 44, 45, 46, 48, 56, 57, 58, 68], "show": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 29, 30, 32, 36, 39, 54, 56, 60, 61, 62, 66, 67, 68, 69], "show_1d_dataset_sampl": 23, "show_img": 54, "show_img_grid": [26, 33], "show_labeled_image_mosa": [42, 48, 51], "show_pr": 48, "shown": [20, 43], "shrink": 23, "shrinkag": 31, "shuffl": [49, 63, 66], "si": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 64, 66, 70], "side": 46, "siempr": [19, 23], "sigm": [26, 35, 37, 38], "sigma": [26, 29, 38, 42, 52, 62], "sigmoid": [26, 28, 29, 30, 33, 36, 37, 38, 41, 42, 43, 46, 47, 52, 53, 54, 55, 58, 62, 63, 64, 67], "sigmoid_longrun": 35, "sign": [29, 52], "signal": [42, 47, 52, 64], "signatur": 67, "significado": 16, "sigu": [12, 13, 14], "siguient": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 23, 24, 46, 70], "sim": 29, "simb\u00f3lica": 17, "simg": [50, 53, 55], "simg2": 50, "simg3": 50, "simg4": 50, "similar": [20, 26, 28, 29, 32, 44, 45, 46, 53, 54, 56, 57, 58, 63, 64, 65, 67, 68, 69], "similar_word": 64, "similarli": [28, 68], "simon": 29, "simpl": [22, 32, 35, 61], "simple_model": 66, "simple_rnn": 62, "simple_rnn_1": 61, "simple_rnn_14": 61, "simple_rnn_15": 61, "simple_rnn_2": 61, "simple_rnn_5": 61, "simple_rnn_6": 61, "simple_rnn_7": 61, "simple_rnn_model": 66, "simpleelmo": 67, "simplefilt": [25, 30], "simplernn": [56, 57, 61, 62], "simplest": 66, "simpli": [28, 33, 34, 43, 47, 53, 68], "simplic": 61, "simplif": 39, "simplifi": [26, 39, 40], "simplificaci\u00f3n": 16, "simul": [28, 34], "simulaci\u00f3n": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sin": [24, 38, 39, 58, 69], "sinc": [29, 33, 38, 41, 42, 47, 54, 64, 67], "singl": [21, 28, 30, 38, 42, 56, 61, 65, 67, 68, 69], "sino": 19, "sintacmat": 64, "sinusoid": 58, "sirv": 17, "site": [23, 50, 64, 66, 67], "situaci\u00f3n": 23, "situat": 34, "six": 43, "size": [21, 23, 24, 25, 26, 27, 28, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 54, 57, 58, 62, 63, 64, 65, 66, 67, 68], "sizes_test": 54, "skimag": [43, 44, 45, 46, 47, 50, 52, 54, 55], "skip": [52, 64], "skip_step": 65, "skipfoot": [60, 61], "skipgram": 64, "sklearn": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67], "sleep": 29, "slide": 52, "slightli": [27, 29, 64], "slow": [63, 68], "slower": 29, "small": [26, 28, 31, 42, 48, 52, 53, 54, 64], "small_bert": 58, "small_error": 32, "smaller": 55, "smi": 54, "snake": 44, "snake_img": 44, "snea": 65, "sneaker": [25, 30], "snow": 56, "snowballstemm": 64, "snowmobil": 50, "snuo": 65, "so": [21, 26, 27, 30, 31, 32, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 61, 63, 64, 65, 66, 67, 68], "sobr": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 23], "sobreajust": 16, "social": 67, "softmax": [16, 25, 28, 30, 34, 35, 36, 42, 44, 48, 49, 51, 64, 65, 66, 67, 68, 69], "softmax_v2": 51, "solicita": [1, 6, 7, 8, 9, 10, 11, 12, 13, 14], "solicitar": [12, 13, 14], "solicitud": [6, 7, 8, 9, 10, 11, 12, 13, 14], "solucion": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "solucionen": 16, "soluci\u00f2n": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "soluci\u00f3n": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46], "solut": [21, 29, 31, 56, 57, 58, 59], "solv": [21, 31, 38, 39, 56, 61, 63, 64, 68], "solventar": 16, "solver": 29, "some": [24, 25, 26, 29, 31, 33, 35, 38, 40, 42, 50, 51, 52, 55, 57, 66, 67, 68], "somehow": [53, 55], "someth": [26, 33, 45, 64], "somewhat": [33, 53], "somewher": 54, "son": [5, 12, 13, 14, 19, 23, 24, 65], "sonar": 66, "sone": 65, "sonsin": 65, "soon": 65, "sort": [33, 45, 49, 52, 65], "sort_valu": 52, "sound": 66, "sourc": [34, 46, 47, 51, 52, 62, 64, 67, 68], "sp": 66, "sp_sentenc": 66, "spa": 66, "space": [26, 31, 44, 66], "spanish": [64, 66], "spanish_vocab_s": 66, "spars": [16, 36, 51], "sparse_ae_loss": 26, "sparse_categorical_crossentropi": [44, 48, 49, 51, 66, 67, 68], "sparsecategoricalcrossentropi": 66, "spatial": [18, 52], "speak": 65, "speaker": 66, "special": [20, 26, 30, 43, 61, 66], "specif": [25, 26, 28, 33, 37, 38, 40, 46, 52, 68], "specifi": [20, 25, 26, 30, 37, 43, 45, 56], "specil": 66, "speech": [61, 64, 67], "spell": [12, 13, 14], "spirit": 65, "split": [28, 29, 31, 33, 54, 56, 61, 64, 66, 67], "split_sequ": 61, "spooe": 65, "spot": [22, 29], "spread": [36, 65], "springer": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sqrt": [38, 42, 56, 62, 68], "squar": [26, 29, 32, 37, 62], "squared_loss": 32, "squeez": 54, "src": [30, 33, 34, 35, 36, 37, 40, 49, 50, 51, 53, 62, 63, 65, 66, 67, 69], "ssl": [66, 67], "stabil": 42, "stabl": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "stack": [56, 64, 67], "stackoverflow": 66, "stage": [18, 28], "stage1_test": 54, "stage1_train": 54, "stand": [29, 31, 64, 67], "standard": [20, 26, 28, 32, 42, 66], "standardlogisticregress": 31, "standardscal": [25, 30], "stanford": 64, "start": [30, 31, 54, 63, 65, 66, 68], "start_i": 59, "start_x": 59, "starter": 54, "stat": [23, 42], "state": [61, 62, 66, 67, 69], "stateless": 63, "stationari": 60, "statist": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 31, 60, 61, 64], "statsmodel": 60, "statu": [24, 39], "std": [28, 39, 41, 42], "std_per_epoch": 28, "stddev": 36, "stdout": [54, 65], "steem": 64, "stemmer": 64, "step": [29, 30, 32, 33, 34, 35, 36, 37, 40, 42, 47, 48, 49, 50, 51, 52, 53, 56, 57, 62, 63, 64, 65, 66, 67, 68, 69], "steps_per_epoch": [65, 66], "steps_per_execut": 51, "still": [22, 35, 41], "stochast": 29, "stock": [60, 61, 62], "stop": [16, 54, 57, 58, 64, 66], "stop_word": [57, 58, 64], "stopword": [57, 58, 64], "storag": [45, 50, 52, 66, 68], "store": [37, 62, 66], "str": [33, 54], "straight": 28, "straightforwardli": 31, "strategi": [29, 31, 56], "stream": [42, 48, 49, 51], "stretcher": 52, "stride": [18, 43, 51, 53, 54], "string": [37, 41, 58, 67], "strip": [20, 66], "stroke": [59, 67], "stronger": 52, "strptime": 56, "structur": [20, 25, 27, 29, 31, 33, 36, 43, 46, 49, 50, 61], "stuck": 65, "student": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "studi": 65, "stuff": 50, "style": [50, 61, 62, 65, 67], "su": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 24], "sub": [39, 57, 58, 64, 66], "subclass": [17, 26, 30], "subconjunto": 18, "submiss": [20, 44, 45], "submit": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "submit_task": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "subplot": [21, 23, 24, 25, 26, 27, 28, 29, 30, 33, 36, 42, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 64], "subplots_adjust": 30, "subsequ": [41, 63], "subset": [59, 67], "substract": [42, 44, 45], "subsum": 42, "success": [24, 39], "successfulli": [24, 39], "suffer": [31, 67], "suffix": 20, "suficient": 19, "sugerencia": 70, "suggest": 20, "suit": [19, 52, 64], "suitabl": 61, "sum": [23, 25, 29, 30, 33, 37, 40, 42, 44, 47, 49, 52, 53, 55, 57, 58, 65, 66, 67, 68, 69], "sum_": [24, 25, 26, 29, 30, 31, 37, 39, 42, 47, 64], "sum_i": 61, "sum_j": [44, 62], "sum_k": 64, "sum_m": 33, "sum_t": [61, 62], "sumat": 47, "summar": [42, 56, 67], "summari": [25, 30, 33, 34, 36, 40, 43, 44, 46, 48, 49, 50, 51, 53, 54, 61, 62, 64, 66, 69], "summat": [25, 26, 39, 47], "super": [28, 30, 32, 35, 36, 37, 40, 49, 66, 67, 68], "superfici": 15, "supervis": [26, 32, 39, 64, 67], "supervisado": [16, 18, 23, 24], "supongamo": 23, "suposici\u00f3n": 23, "suppli": 20, "support": [20, 29, 66, 67], "sure": [35, 45, 54, 57], "surgen": 23, "surgimiento": 15, "surgir": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "surround": 64, "survei": 50, "sutskev": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "svar": 38, "svc": [23, 44], "svm": [23, 44], "sweep": 47, "swim": 59, "swoat": 65, "sy": [31, 39, 54, 56, 57, 58, 59, 60, 64, 65], "symbol": [29, 33, 41], "symmetr": 23, "sympi": [17, 38, 40], "synops": 64, "synopsesstem": 64, "syntaxwarn": [34, 35, 40, 43, 48, 49, 50, 52, 53, 54], "synteth": 69, "synthet": [37, 49], "system": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 31, 54, 56, 58, 59, 64], "s\u00ed": [18, 23], "s\u00f3lo": 19, "s\u00fabelo": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "t": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24, 25, 27, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41, 45, 47, 50, 53, 54, 55, 56, 57, 61, 62, 64, 65, 66, 67, 69], "t0": [24, 39], "t0_rang": 24, "t1": [21, 24, 25, 26, 27, 28, 37, 38, 39, 43, 44, 45, 46, 56, 57, 58, 59], "t1_rang": 24, "t2": [21, 24, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 69], "t3": [25, 37, 38, 43, 44, 45, 46, 56, 57], "t4": [25, 54, 56, 57], "t_": 29, "t_0": 52, "t_h": 45, "t_input": 36, "t_j": 29, "t_output": 36, "t_w": [45, 52], "t_weight": 36, "t_x": [45, 52], "t_y": [45, 52], "tabbi": 44, "tackl": 64, "tag": [61, 64, 67], "tags2index": 67, "tail": 67, "take": [25, 29, 30, 40, 44, 51, 52, 54, 56, 57, 58, 62, 64, 66, 67, 68], "taken": [38, 52, 61, 63, 64, 66, 67, 68, 69], "takl": 62, "tal": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "taller": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "tama\u00f1o": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "tambi\u00e9n": [19, 23], "tan": [23, 24], "tanh": [30, 34, 37, 38, 42, 53, 57, 58, 61, 62, 66], "tanta": 23, "tanto": [19, 23], "tape": [32, 40, 42, 66], "tar": 59, "tarea": [16, 18, 19], "targ": 66, "targ_lang": 66, "targ_lang_token": 66, "target": [26, 29, 31, 32, 56, 64, 66, 67], "target_nam": 59, "target_tensor": 66, "target_tensor_train": 66, "target_tensor_v": 66, "task": [20, 32, 67], "task_id": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "tat": 65, "tau": [29, 47, 61, 62], "tayt": 65, "tb_callback": [35, 36, 40], "tbptt": 63, "td": 27, "te": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 64], "te_acc": 63, "te_loss": 63, "teach": 18, "teacher": [20, 66], "team": 1, "technic": [0, 68], "techniqu": [31, 38, 52, 64], "teer": 65, "tell": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 33, 34], "tem": 29, "tem2": 29, "temp": [54, 56, 61], "temp_i": 65, "temperatur": 65, "templat": [20, 37], "tempo": 66, "tend": 35, "tendenc": 54, "tendr\u00e1": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "tenemo": [16, 18, 24], "tener": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 23], "tenga": [6, 7, 8, 9, 10, 11, 12, 13, 14], "tengan": [6, 7, 8, 9, 10, 11, 12, 13, 14], "teniendo": 23, "tensor": [17, 25, 26, 30, 32, 33, 36, 37, 38, 44, 47, 49, 50, 57, 61, 66, 69], "tensorboard": [16, 28, 36, 37, 39, 40, 41, 42, 48, 49, 50, 51, 52, 53, 54, 56], "tensorboard_callback": 37, "tensorflob": 44, "tensorflow": [5, 16, 18, 19, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 39, 41, 42, 43, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "tensorflow_hub": [44, 52, 58, 59, 67], "tensorflow_text": 58, "tensorflow_vers": [56, 57, 58, 59, 60], "tensorshap": [37, 47, 49, 52, 66], "tensorspec": 41, "tensroflow": 16, "term": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 26, 30, 31, 32, 37, 39, 40, 45, 63, 64, 68], "termin": [24, 39], "terminaci\u00f3n": [2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "terminosdeinter": 64, "tesi": [1, 2, 3, 4], "tesla": 54, "test": [20, 21, 23, 25, 27, 28, 29, 30, 31, 33, 34, 37, 42, 43, 48, 51, 56, 60, 61, 62, 63, 64, 69], "test2label": 67, "test_acc": 36, "test_id": 54, "test_imag": [1, 2], "test_index": 60, "test_label": 67, "test_on_batch": 63, "test_path": 54, "test_pct": 23, "test_pr": [48, 51, 67], "test_scor": 23, "test_set": 62, "test_siz": [23, 26, 27, 28, 33, 34, 35, 36, 40, 42, 44, 48, 49, 51, 57, 58, 59, 61, 66, 67], "test_step": 40, "testn": 61, "testpredict": 61, "testpredictplot": 56, "text": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 21, 23, 24, 25, 26, 29, 30, 33, 35, 37, 38, 42, 52, 55, 57, 58, 61, 62, 63, 65, 66, 67, 68], "text_list": 57, "text_preprocess": 58, "texto": 64, "texts_to_sequ": [64, 66, 67], "tf": [17, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 67, 68, 69], "tf2": 67, "tf__f47": 41, "tf_alexnet": 51, "tf_build_model": 43, "tf_cpp_min_log_level": 37, "tfapi": 40, "tfcycl": 40, "tfhub": [44, 52, 58, 67], "tfidf_matrix": 64, "tfidf_vector": 64, "tfidfvector": 64, "tftrainingworkflow": 40, "th": [29, 30, 45], "than": [20, 21, 29, 30, 37, 38, 43, 46, 48, 55, 56, 57, 58, 59, 62, 64, 67, 68], "the_transformer_encoder_decoder_stack": 68, "thed": 65, "thee": 65, "theee": 65, "thei": [20, 27, 28, 29, 32, 42, 45, 47, 48, 54, 57, 59, 61, 62, 66, 67, 68], "thel": 65, "them": [20, 28, 30, 32, 37, 38, 39, 40, 45, 48, 52, 54, 56, 57, 61, 64, 65, 66, 67, 68], "theoret": 22, "theori": [42, 52], "therefor": [29, 31, 52, 61, 62, 66, 67], "thes": 65, "thet": 65, "theta": [24, 39, 40], "theta_": 24, "theta_0": [24, 39], "theta_1": [24, 39], "theta_2": 24, "thi": [0, 20, 21, 22, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 38, 40, 42, 43, 44, 45, 46, 47, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "thie": 65, "thing": [39, 44, 45, 54], "think": [35, 55], "third": 65, "tho": 65, "thoe": 65, "those": [21, 28, 31, 57, 63, 64, 66, 68], "thou": 65, "though": [54, 63], "thousand": [63, 66, 67], "thr": 65, "three": [25, 26, 30, 31, 35, 44, 47, 58, 59, 62, 68], "threshold": [29, 54], "through": [19, 25, 26, 31, 55, 57, 62, 66, 67, 68, 69], "throught": 29, "throw": 62, "tht": 65, "thtd": 65, "thte": 65, "thto": 65, "thtu": 65, "thu": [29, 32, 52, 54, 55, 62, 64, 67], "thursdai": 67, "thv": 65, "thyung": 65, "ti": [15, 25], "tibshirani": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "tick_mark": [25, 30], "ticker": 66, "tiempo": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 66], "tien": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 70], "tienen": [12, 13, 14, 19, 23], "tight_layout": [33, 42, 47, 54], "tild": [42, 62], "tim": 67, "time": [19, 21, 23, 24, 26, 27, 29, 37, 38, 40, 41, 42, 48, 51, 53, 54, 62, 64, 65, 66, 67, 68], "time_ahead": 61, "time_distribut": 66, "time_distributed_10": 69, "time_distributed_11": 69, "time_distributed_12": 69, "time_distributed_13": 69, "time_distributed_14": 69, "time_distributed_15": 69, "time_distributed_16": 69, "time_distributed_2": 66, "time_distributed_3": 66, "time_distributed_8": 69, "time_distributed_9": 69, "timedist": 66, "timedistribut": [61, 66, 67, 69], "timeit": [39, 41], "timeseri": [20, 56, 60], "timeseriessplit": 60, "timestep": 69, "tini": [67, 68], "tipic": 67, "tipo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 23], "titl": [21, 23, 24, 25, 27, 28, 29, 30, 33, 36, 37, 40, 42, 43, 48, 51, 52, 54, 55, 56, 60, 62], "tloss": 64, "tmp": 59, "tnto": 65, "to_categor": [25, 30, 65, 69], "to_cod": 41, "to_csv": 56, "to_jshtml": 69, "to_json": [51, 65], "toarrai": 64, "tocar": 66, "toda": [17, 19], "todav\u00eda": [9, 70], "todo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24], "togeth": [27, 29, 33], "toi": 58, "tok": 67, "tokan": 67, "token": [54, 57, 58, 67, 68], "token_char": 67, "token_emb": [67, 68], "token_emb_dim": 67, "token_embed": 58, "token_pattern": 64, "token_proj": 67, "tokenandpositionembed": [58, 68], "tokenize_onli": 64, "tokenizer_pad": 57, "tol": 23, "told": 65, "tolerac": 47, "tolist": [27, 67], "tomado": 66, "tomando": 18, "tomar": 66, "too": [31, 65, 68], "tooeg": 65, "tool": 29, "toolkit": 64, "top": [20, 25, 30, 43, 44, 45, 52, 59, 64, 67, 68, 69], "topol": 61, "torch": 52, "toronto": 51, "tortois": 52, "toshev": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "total": [5, 12, 13, 14, 24, 25, 27, 30, 33, 34, 36, 40, 44, 45, 46, 48, 49, 50, 51, 53, 54, 61, 62, 64, 65, 66, 68, 69], "total_filt": 67, "total_loss": 66, "toto": 65, "touch": 20, "towardsdatasci": [53, 66], "tpe": 65, "tpu": [22, 33], "tr_acc": 63, "tr_loss": 63, "tr_pred": 23, "trabajamo": 15, "trabajo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23], "trace": [37, 41], "track": [28, 66], "trade": 29, "tradit": 60, "traffic": 52, "train": [22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 35, 37, 40, 44, 45, 46, 48, 49, 50, 52, 53, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68], "train_acc": 36, "train_and_evalu": 40, "train_data_gener": 65, "train_experi": 36, "train_id": 54, "train_imag": [1, 2], "train_index": 60, "train_on_batch": [30, 63, 64], "train_path": 54, "train_scor": 23, "train_siz": [56, 61], "train_step": [32, 42, 66], "train_test_split": [23, 26, 27, 28, 33, 34, 35, 36, 40, 42, 44, 48, 49, 51, 57, 58, 59, 66, 67], "trainabl": [25, 27, 30, 33, 34, 36, 37, 40, 41, 42, 44, 46, 48, 49, 50, 51, 53, 54, 57, 58, 59, 61, 62, 64, 66, 67, 69], "trainable_var": 32, "trainable_vari": [32, 36, 40, 42, 66], "trainable_weight": 36, "trainig": 29, "training_checkpoint": 66, "training_set": 62, "training_set_sc": 62, "trainmodel": 56, "trainn": 61, "trainpredict": 61, "trainpredictplot": 56, "trainvalactivationscallback": 28, "trainvalactivationscallback_class": 28, "trajectori": 29, "tran": 29, "trane": 68, "transfer": [18, 19, 29, 54, 63], "transform": [22, 25, 30, 37, 44, 50, 52, 54, 55, 57, 59, 60, 61, 62, 64, 67], "transformer_block": 68, "transformer_decoding_2": 68, "transformer_multi": 68, "transformer_resideual_layer_norm": 68, "transformer_resideual_layer_norm_2": 68, "transformer_resideual_layer_norm_3": 68, "transformer_self_attention_vector": 68, "transformerarch": 58, "transformerblock": 68, "translat": [61, 64], "transmit": 66, "transpos": 55, "transpuesta": 18, "trav\u00e9": [17, 18], "trazada": 15, "tre": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 24], "treat": 28, "treatment": 67, "tree": [23, 52, 64], "trench": 52, "trench_coat": 52, "trend": 62, "tri": [55, 64], "tricycl": 50, "trigger": 37, "trigram": 57, "trilobit": 24, "trilotropico": [20, 24, 32, 39, 40], "trilotr\u00f3pico": 24, "trivial": 30, "troop": 67, "tropical": 24, "trough": [68, 69], "trouser": [25, 30], "trsc": 23, "true": [23, 24, 25, 27, 30, 32, 35, 36, 37, 39, 40, 41, 42, 44, 48, 49, 51, 52, 53, 54, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69], "truncat": [19, 58, 67], "truth": 23, "try": [26, 29, 31, 33, 34, 37, 41, 45, 53, 59, 64, 66, 67], "ts_pred": 23, "tsaplot": 60, "tscv": 60, "tssc": 23, "tte": 65, "tu": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46], "tun": [4, 31], "tune": [40, 47], "tupl": 20, "turn": 53, "turtl": 52, "tutori": [28, 36, 64], "tw": 45, "tweet": [19, 58], "twitter": [57, 64], "two": [18, 20, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 43, 45, 46, 47, 52, 53, 56, 58, 59, 62, 63, 67, 68], "twoinput": 27, "tx": [41, 45], "txt": [31, 44, 52, 59, 64, 65, 66], "ty": 45, "type": [20, 21, 25, 27, 30, 33, 34, 36, 40, 44, 46, 48, 49, 50, 51, 54, 55, 56, 57, 58, 61, 62, 64, 66, 68, 69], "typic": [29, 52, 64], "typical": 29, "t\u00e9cnica": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19], "t\u00e9cnico": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "t\u00e9rmino": [18, 19, 24], "t\u00fa": [6, 7, 8, 9, 10, 11, 12, 13, 14], "u": [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 19, 24, 28, 29, 34, 35, 46, 54, 57, 61, 62, 64, 65, 66, 67], "u5": 58, "u6": 54, "u7": 54, "u8": 54, "u9": 54, "u_": 62, "u_i": 29, "u_j": 29, "u_k": 29, "u_l": 29, "uc": 59, "ucf50": 59, "ucf50_subset": 59, "udea": [27, 28, 70], "ueie": 65, "uint8": 54, "uk": 50, "ultrasound": 54, "umbrella": 52, "umontr": 64, "un": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 46, 66, 70], "una": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 66], "unabl": 31, "unchang": 57, "unconnected_gradi": 38, "unconnectedgradi": 38, "uncorr": 54, "undefinedreturnvalu": 41, "under": [20, 35, 54, 65, 67], "underfit": 31, "undergo": 67, "underli": [31, 33], "understand": [25, 27, 34, 36, 38, 39, 43, 45, 52, 53, 62], "understood": 64, "understudi": 66, "unet": [18, 53], "unfortun": [29, 67], "ungrad": [25, 56, 58], "unicod": 66, "unicode_to_ascii": 66, "unicodedata": 66, "unidad": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "uniform": 66, "uninstal": [56, 57, 58, 59], "uniqu": [27, 42, 48, 51, 58, 59, 64, 65], "unirt": 1, "unit": [29, 36, 51, 54, 60, 66, 67, 68, 69], "univari": 56, "universidad": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "unk": [57, 67], "unknown": 41, "unless": 63, "unlik": 67, "unnecessari": 37, "uno": [6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 23, 24], "unsampl": 52, "unstabl": 62, "unsupervis": [26, 32, 64], "until": [22, 37, 54, 66], "unto": 65, "unzip": [54, 65], "up": [15, 25, 26, 27, 37, 53, 56, 62, 63, 64, 67, 68], "updat": [29, 31, 40, 54, 62, 64], "update_freq": 40, "update_st": 32, "updatefig": 69, "updatefig2": 69, "upload": 54, "upon": [65, 67], "upper": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "upsampl": [46, 54], "upsilon": 62, "upsiz": 53, "url": 64, "url_chimp": 44, "urlerror": 64, "urllib": 64, "urllib3": [66, 67], "urlopen": 64, "us": [0, 20, 21, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 67, 69], "usa": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 23, 29], "usada": [18, 19], "usado": 19, "usag": 54, "usamo": [19, 24], "usan": 18, "usando": [17, 18, 19, 23, 24], "usar": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 24, 70], "usar\u00e1": 18, "use_bia": [36, 51], "use_ema": 51, "use_idf": 64, "use_latex": 39, "use_maxpool": 49, "usecol": [60, 61], "user": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 64, 66, 67], "user_model": 28, "user_request": 41, "userwarn": [33, 35, 36, 40, 49, 50, 54, 64], "uso": [16, 18, 19], "usr": [33, 35, 36, 40, 49, 50], "usual": [33, 35, 40, 41, 47, 64, 66], "usuario": 23, "utf": 66, "util": [25, 30, 54, 57, 58, 59, 64, 65, 66, 69], "utilizada": 18, "utilizando": 19, "utilizar": 16, "uv": [66, 67], "v": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 26, 36, 48, 51, 61, 62, 64, 65, 66, 68], "v0": [66, 67], "v1": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 44], "v2": [66, 67], "v3": 52, "v5": 52, "v6": [18, 45, 52], "v_": 62, "va": [25, 30], "val": [34, 40, 54], "val_acc": 36, "val_accuraci": [30, 35, 36, 48, 51, 63, 67, 68], "val_loss": [30, 31, 34, 35, 36, 40, 48, 51, 54, 63, 67, 68], "val_mean_absolute_error": 40, "vale": 5, "valid": [31, 35, 43, 44, 46, 47, 51, 53, 55, 56, 58, 61, 63, 65, 66, 67, 68, 69], "validaci\u00f3n": [2, 7, 11, 19], "validation_data": [28, 34, 35, 36, 40, 44, 48, 51, 63, 67, 68], "validation_split": [25, 30, 54, 57, 58, 61], "vall": 56, "vallu": 56, "valor": [5, 24], "valu": [20, 21, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 47, 50, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68], "value_count": [42, 48, 51, 52], "vamo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "vanilla": 62, "vanish": [29, 62], "vanishinggradi": 35, "var": 69, "varepsilon": 38, "varia": [16, 18, 24], "variabilidad": 23, "variabl": [29, 31, 38, 39, 40, 41, 47, 54, 56, 65, 66], "variable_1": 40, "variablespec": 41, "variac": 42, "variant": [19, 68], "vario": [17, 18, 19], "varnam": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "vaswani": [12, 13, 14], "vaue": 34, "ve": [23, 54, 66], "vece": [23, 24], "vecto": 64, "vector": [18, 19, 21, 29, 30, 31, 34, 35, 37, 39, 42, 43, 44, 47, 52, 57, 58, 61, 62, 64, 66, 67, 68, 69], "vectori": 24, "vectorial": 16, "vehicl": 52, "vemo": 18, "venugopalan": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "venv": 64, "verbos": [23, 25, 26, 30, 31, 32, 36, 37, 40, 49, 53, 54, 57, 58, 61, 63, 65, 66, 67], "verd": 23, "veri": [22, 26, 28, 29, 31, 32, 35, 36, 38, 40, 42, 47, 53, 54, 62, 63, 66], "verifi": 26, "verificaci\u00f3n": [1, 2], "verificar": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "verificarlo": 17, "verifiqu": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "verlag": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "version": [25, 31, 37, 38, 39, 43, 48, 54, 56, 57, 58, 59, 60, 62, 64], "versi\u00f3n": 70, "vertic": [47, 52], "vez": [23, 24, 66], "vgg": [18, 59], "vgg16": [50, 59], "vgg16_weights_tf_dim_ordering_tf_kernel": 50, "vggnet": 50, "vhath": 65, "via": [33, 54], "vida": 66, "video": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 48, 68, 69, 70], "videocaptur": 59, "videoclassifyarch": 59, "videos1": 69, "videos2": 69, "videos3": 69, "videos4": 69, "videostest": 69, "vie": 5, "vienen": 23, "view": [52, 53, 55, 61, 64, 67], "vinyal": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "viridi": 66, "virtual": 64, "virtualbox": 48, "vision": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 48, 53], "visit": 68, "visto": 18, "visual": [33, 45, 50, 51, 62], "visualizar": 23, "viven": 24, "vkfy8l4khbpawkiqkpwhtjd4o": 45, "vloss": 34, "vmax": 52, "vmin": 52, "vocab": [65, 66], "vocab_inp_s": 66, "vocab_s": [58, 64, 66, 68], "vocab_tar_s": 66, "vocabulari": 64, "void": 65, "vol": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "volatil": 54, "volum": 62, "volumetri": 52, "vstack": [27, 50], "vx": 24, "vy": 24, "v\u00e1lida": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11], "w": [21, 25, 26, 28, 29, 30, 31, 33, 36, 37, 38, 40, 42, 44, 45, 47, 51, 52, 57, 58, 61, 62, 64, 65, 66, 67, 68], "w0": [48, 51], "w0_after": 36, "w0_befor": 36, "w1": [42, 66], "w2": [42, 66], "w_": [25, 29, 35, 64], "w_0": [29, 45], "w_1": [29, 45], "w_1x_1": 29, "w_2": 29, "w_2x_2": 29, "w_d": [26, 29], "w_e": 26, "w_i": [29, 64], "w_ix_i": 29, "w_j": 31, "w_l": 35, "w_o": 64, "w_t": 64, "wa": [33, 63, 65, 66, 67], "waa": 65, "wai": [20, 22, 25, 27, 28, 30, 31, 32, 33, 35, 38, 40, 43, 47, 53, 54, 55, 63, 64, 66, 67], "walk": 54, "wall": 64, "want": [20, 27, 29, 32, 44, 45, 47, 63, 66, 68], "war": 67, "warm": 15, "warn": [23, 25, 30, 33, 36, 37, 38, 50, 54, 56, 57, 58, 59, 61, 64, 66, 67], "wasn": 67, "watch": 38, "wate": 65, "water": 65, "wb": 57, "wc": 45, "wcoro": 45, "wd": 26, "we": [20, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 58, 61, 62, 63, 66, 67, 68, 69], "weaker": 46, "web": 52, "websit": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "weight": [25, 26, 29, 31, 32, 35, 37, 38, 40, 42, 47, 48, 49, 52, 55, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68], "weight_decai": 51, "weighted_categorical_crossentropi": 25, "weighted_metr": 51, "weights0": 25, "weights1": 25, "weights2": 25, "weigth": [25, 29], "weird": 22, "weitgh": 29, "well": [30, 33, 35, 54, 64, 65], "went": 67, "were": [22, 62, 65], "wget": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "wh": [28, 65], "what": [21, 25, 27, 28, 29, 35, 36, 38, 40, 41, 48, 52, 53, 62, 67], "whatev": 20, "whe": 65, "whec": 65, "when": [20, 21, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 45, 49, 52, 54, 61, 63, 64, 66, 67, 68], "whenev": [20, 40], "where": [26, 27, 29, 30, 31, 32, 35, 42, 43, 44, 48, 53, 56, 58, 61, 63, 64, 67, 68, 69], "whether": 34, "which": [20, 21, 25, 29, 31, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 53, 54, 56, 58, 62, 64, 65, 66, 67, 68], "while": [28, 44, 51, 55, 57, 59, 62, 65, 67], "white": [24, 46, 66], "who": [35, 68], "whole": [29, 58, 64, 66], "whose": 52, "whrt": 65, "whru": 65, "whsu": 65, "why": [30, 33, 34, 41, 45], "wi": [26, 33], "wid": 64, "wide": [45, 67], "width": [20, 23, 24, 27, 29, 39, 45, 46, 48, 52, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69], "wiki": [38, 64], "wikipedia": [38, 47, 64, 66], "willing": 66, "win64": 64, "window": [31, 52, 63, 64], "window_end": 63, "window_length": 63, "window_s": 64, "window_start": 63, "windows_i": 63, "winit": 36, "wiol": 65, "wise": [16, 29], "with_regular": 37, "withdraw": 67, "within": [20, 28, 38, 40, 44, 52, 64], "without": [29, 33, 38, 42, 46, 48, 49, 59, 62, 65, 68], "wnd_dir": 56, "wnd_spd": 56, "woi": 65, "won": 54, "wondo": 65, "word": [19, 57, 58, 61, 66, 67, 68], "word2id": 64, "word2vec": 67, "word_count": [64, 67], "word_doc": 67, "word_index": [64, 66, 67], "word_pair": 66, "word_token": [57, 58, 64, 67], "wordnet": 64, "wordpress": 54, "words2index": 67, "wordvec": 64, "work": [32, 37, 41, 53, 54, 64], "workflow": 20, "world": [40, 48], "worth": 64, "would": [30, 34, 35, 38, 43, 52, 55, 66, 67], "wrap": 41, "wrapper": 33, "write": [40, 51, 57, 63, 65], "write_graph": [35, 36], "write_imag": [35, 36], "wrong": [29, 63], "wsig": 29, "wspace": 30, "wsro": 65, "www": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 22, 28, 37, 40, 48, 50, 51, 54, 57, 64], "x": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "x1": [29, 62], "x2": [29, 62], "x64": 64, "x_": [26, 29, 31, 67], "x_0": 29, "x_1": [29, 67], "x_2": [29, 67], "x_batch": [40, 42], "x_cifar": [42, 44, 48, 49, 51, 53], "x_d": 29, "x_embed": 64, "x_i": 29, "x_in": 28, "x_j": 62, "x_k": 67, "x_max": 29, "x_min": 29, "x_pair": 27, "x_pred": [26, 33], "x_pred_noisi": 33, "x_rnn": 67, "x_sampl": [26, 33], "x_sample_encod": 33, "x_sample_noisi": 33, "x_t": [62, 67], "x_te": [57, 58, 59, 67], "x_te_c": 67, "x_temp": 56, "x_test": [23, 25, 26, 28, 30, 33, 34, 35, 36, 42, 44, 48, 49, 51, 54, 56, 61, 62, 63], "x_test_extra": 34, "x_testf": 42, "x_testn": [25, 30], "x_tr": [57, 58, 59, 67], "x_train": [23, 25, 26, 28, 30, 33, 34, 35, 36, 40, 42, 44, 48, 49, 51, 54, 56, 61, 62, 63, 68], "x_train2": 61, "x_train_extra": 34, "x_train_noisi": 33, "x_trainf": 42, "x_trainn": [25, 30], "x_val": [40, 67, 68], "xai4eng": 20, "xaxi": 66, "xbf": 66, "xc2": 66, "xclick": 52, "xclick1i": 52, "xclick1x": 52, "xclick2i": 52, "xclick2x": 52, "xclick3i": 52, "xclick3x": 52, "xclick4i": 52, "xclick4x": 52, "xdata": 57, "xent": 29, "xf": 59, "xf_cifar": 44, "xin": 26, "xinput": 26, "xk": 24, "xlabel": [24, 28, 29, 30, 33, 36, 39, 40, 42, 48, 51, 62], "xlim": 45, "xmax": [45, 52], "xmin": [45, 52], "xor": 29, "xout": 26, "xp": 68, "xr": [23, 24], "xrang": 42, "xt": 27, "xtick": [25, 27, 30, 33, 52], "xtr": 27, "xtr_c": 67, "xval_c": 67, "xw": [36, 38], "xx": [12, 13, 14, 20, 29], "xy": 38, "y": [15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 53, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70], "y2": [29, 69], "y_": 29, "y_batch": [40, 42], "y_cifar": [42, 44, 48, 49, 51, 53], "y_est": [56, 59, 69], "y_est_t": 56, "y_i": [25, 30, 31], "y_k": 29, "y_label": 27, "y_max": 29, "y_min": 29, "y_pair": 27, "y_po": 30, "y_pred": [25, 32, 37, 40, 57, 58], "y_sampl": 33, "y_te": [57, 58, 59, 67], "y_temp": 56, "y_test": [23, 25, 26, 28, 30, 33, 34, 35, 36, 42, 44, 48, 49, 51, 56, 61, 63], "y_test_oh": [28, 34, 35, 36], "y_tr": [57, 58, 59, 67], "y_train": [23, 25, 26, 28, 30, 33, 34, 35, 36, 40, 42, 44, 48, 49, 51, 54, 56, 61, 62, 63, 68], "y_train2": 61, "y_train_oh": [28, 34, 35, 36], "y_trainoh": [25, 30, 69], "y_true": [25, 32, 37, 40], "y_val": [40, 67, 68], "ya": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 24, 66], "yaxi": 66, "yb1admmvvvkjtlz7wnvaqt5stuvigxvu4k0d0o": 45, "ye": [56, 57, 58, 59], "year": [56, 67, 68], "yet": [54, 56], "yhenh": 65, "yhll": 65, "yield": [32, 38, 43, 65], "yill": 65, "ylabel": [24, 27, 29, 33, 39, 40, 42, 48, 51, 60, 62], "ylim": [23, 40, 45], "ymax": [45, 52], "ymin": [45, 52], "yml": 20, "yoh": 34, "yolo": [45, 52], "yolo3": 52, "yolo9000": 52, "yolo_predict": [45, 52], "yolov3": 52, "york": 67, "yoshua": 66, "you": [12, 13, 14, 25, 26, 27, 28, 29, 30, 32, 33, 35, 37, 38, 39, 40, 43, 44, 45, 46, 48, 51, 52, 56, 57, 58, 59, 63, 66, 67, 68, 69], "youngest": 65, "your": [20, 21, 25, 26, 27, 28, 30, 32, 35, 37, 38, 43, 44, 45, 46, 54, 56, 57, 58, 59, 69], "youtub": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "youtubevideo": 29, "yr": 23, "yrtctmtv6uitpihosq3j9xdy1wslgunza0": 45, "yt": [27, 39], "ytick": [23, 25, 27, 30, 42], "ytr": 27, "yuaer": 65, "ywon": 65, "yy": 29, "z": [21, 25, 26, 29, 35, 37, 39, 42, 62, 64, 65, 66, 67, 68], "z0": [57, 58], "z1": 42, "z2": 42, "z4": 69, "z_": [29, 59], "z_l": 29, "z_t": 62, "za": [57, 58, 59, 64, 66], "zero": [24, 25, 26, 29, 35, 36, 38, 42, 43, 47, 50, 51, 53, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 69], "zero_divis": 67, "zip": [27, 32, 40, 42, 48, 51, 54, 64, 65, 66, 67, 70], "zoo": 22, "zoom": [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14], "\u00b5": [39, 41, 64], "\u00f3ptima": 23, "\u00f3ptimo": [23, 24], "\u00faltimo": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "\u00fanicament": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14]}, "titles": ["Fundamentos de Deep Learning", "Informaci\u00f3n 20211 - UdeA", "Info 20212 - UdeA - Pregrado", "Info 2022.1 - UdeA - Posgrado", "Info 2022.2 - UdeA - Posgrado", "Info 2023.1 - UdeA - Especializaci\u00f3n", "Info 2023.1 - UdeA - Posgrado", "Info 2023.1 - UdeA - Pregrado", "Info 2023.2 - UdeA - Posgrado", "Info 2023.2 - UdeA - Pregrado", "Info 2024.1 - UdeA - Posgrado", "Info 2024.1 - UdeA - Pregrado", "Info 2024.2 - UdeA", "Info 2025.1 - UdeA", "Info 2025.2 - UdeA", "01 - INTRODUCTION", "02 - NEURAL NETWORKS", "03 - TENSORFLOW CORE", "04 - CONVOLUTIONAL NETWORKS", "05 - SEQUENCE MODELS", "01 - General Instructions", "LAB 01.01 - WARM UP", "1.1 - DL Overview", "1.2 - Models derived from data", "1.3 - ML algorithm design", "LAB 2.1 - Customized loss function", "LAB 2.2 - Sparse Autoencoders", "LAB 2.3 - Pairwise classification", "LAB 2.4 - Model instrumentation", "2.1 - The Perceptron", "2.2 - The Multilayer Perceptron", "2.3 - Overfitting and regularization", "2.4 - Loss functions in Tensorflow", "2.5 - Autoencoders", "2.6 - Multimodal architectures", "2.7 - Vanishing gradients", "2.8 - Weights initialization", "LAB 3.1 - TF model subclassing", "LAB 3.2 - Low level <code class=\"docutils literal notranslate\"><span class=\"pre\">tensorflow</span></code>", "3.1 - Symbolic computing for ML", "3.2 - TF symbolic engine", "3.3 - Using <code class=\"docutils literal notranslate\"><span class=\"pre\">tf.function</span></code>", "3.4 - Batch normalization", "LAB 4.1 - Convolutions", "LAB 4.2 - Transfer learning", "LAB 4.3 - Object detection", "LAB 4.4 - Semantic segmentation", "4.1 - Convolutions", "4.2 - Convolutional Neural Networks", "4.3 - Dropout, pooling", "4.4 - CNN Architectures", "4.5 - Transfer learning", "4.6 - Object detection", "4.7 - Transposed convolutions", "<strong>4.8</strong> - UNet Image segmentation", "4.9 - Atrous convolutions", "LAB 5.1 - Time series prediction", "LAB 5.2 - Padding - Masking", "LAB 5.3 - Transformer - BERT", "LAB 5.4 - Video Classification", "5.0 Crossvalidation in time series", "5.1 Recurrent Neural Networks", "5.2 LSTM and GRU", "5.3 Truncated BPTT", "5.4 Text processing", "5.5 Sequences generation", "5.6 Bidirectional RNNs", "5.7 ELMo", "5.8 Transformer", "5.9  CNN-LSTM architectures", "Welcome"], "titleterms": {"": [29, 48, 56, 57, 58, 59, 61, 63, 64, 67], "0": [36, 60], "01": [15, 20, 21, 26], "02": [16, 26, 62], "03": 17, "04": 18, "05": 19, "1": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 33, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 56, 57, 58, 59, 61, 67, 69], "2": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 43, 44, 45, 46, 48, 56, 57, 58, 62, 69], "20211": 1, "20212": 2, "2022": [3, 4], "2023": [5, 6, 7, 8, 9], "2024": [10, 11, 12], "2025": [13, 14], "2d": 23, "3": [16, 18, 19, 20, 24, 25, 27, 31, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 56, 57, 58, 63, 69], "4": [16, 18, 20, 25, 28, 32, 33, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 64], "5": [20, 33, 40, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69], "6": [34, 40, 52, 66], "7": [35, 40, 53, 67], "8": [36, 40, 54, 68], "9": [55, 69], "A": [28, 32, 34, 35, 61], "And": [39, 54], "BUT": 63, "In": 47, "One": [29, 52], "The": [16, 20, 29, 30, 31, 57, 65], "There": [64, 69], "To": 20, "abl": 29, "about": [29, 63], "abriendo": 24, "access": 33, "accuraci": [27, 34], "activ": [28, 29, 33, 35, 48, 64], "actual": 41, "ad": 47, "ahead": [56, 61], "aim": 57, "alexnet": 51, "algebra": 39, "algorithm": [24, 29, 39], "algoritmo": [15, 23, 24], "also": 51, "altern": 64, "an": [21, 33, 52], "analysi": [57, 60, 68], "analyt": 48, "anal\u00edtico": 23, "anchor": 45, "annot": 52, "api": [32, 40], "approach": [29, 52], "aproxima": 23, "ar": [39, 41, 64, 69], "architectur": [30, 34, 50, 53, 61, 69], "argmax": 21, "arquitectur": 67, "arquitectura": [16, 18, 19], "artifici": [15, 29], "artificial": 16, "assembl": 33, "atrou": 55, "attent": [66, 68], "autoencod": [16, 26, 33], "autograd": 20, "automat": 41, "avoid": 51, "b": 20, "backpropag": [29, 61], "backward": 61, "bag": 64, "base": 64, "basic": [25, 28, 35], "batch": [17, 29, 38, 40, 42], "becaus": 65, "being": 51, "bert": [58, 68], "between": 63, "bidirecional": 19, "bidirect": 66, "black": 39, "block": 68, "blue": 29, "bound": 45, "box": [39, 45], "bptt": [61, 63], "build": [37, 54, 57, 64], "ca": 39, "caja": 24, "calendario": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "call": [33, 37], "callback": 28, "chang": 51, "clasificaci\u00f3n": 23, "clasificador": 23, "class": [27, 40], "classic": [29, 60], "classif": [27, 34, 44, 52, 59], "classifi": 30, "closest": 45, "cnn": [19, 46, 50, 69], "coco": 48, "code": 41, "color": 29, "como": [15, 24], "compar": 67, "complejidad": 23, "complet": 67, "complex": [48, 61, 65], "comput": [38, 39, 40, 41, 43, 45], "con": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 23, 70], "concret": 41, "connect": 46, "contacto": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "content": 20, "context": [56, 59, 66], "control": 40, "convent": 61, "convert": 41, "convolucional": 18, "convolut": [18, 43, 47, 48, 51, 53, 55, 69], "core": 17, "could": 51, "covari": 42, "creat": [20, 34, 45, 66], "crossvalid": 60, "curs": 31, "curso": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "custom": [25, 33, 40], "customari": [28, 35], "c\u00e1lculo": 23, "c\u00f3mo": [23, 24], "c\u00f3mputo": 17, "data": [23, 28, 33, 35, 36, 54, 59, 60, 66], "databas": 25, "dataset": [22, 23, 29, 32, 48, 57, 65, 66], "dato": 23, "de": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23, 24], "decod": [61, 66], "dedicaci\u00f3n": 1, "deep": [0, 15], "defin": [30, 61, 67, 69], "definimo": 24, "del": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 24, 70], "denois": 33, "dens": [28, 35, 61], "depend": [63, 64], "deriv": 23, "derivado": 23, "descent": 40, "design": [24, 39], "desir": 45, "detecci\u00f3n": 18, "detect": [45, 52], "detector": 52, "dev": 40, "diferent": 23, "differ": 36, "dimension": [22, 31], "directli": 54, "discuss": 63, "dise\u00f1a": 24, "dise\u00f1ador": 15, "displai": 34, "distribut": 33, "dl": 22, "do": [20, 61], "document": 64, "done": 37, "download": [54, 67], "downsampl": 53, "drawback": 29, "dropout": 49, "dure": 42, "e": [15, 17, 23], "earli": 31, "effect": 36, "ejemplo": 24, "el": [17, 19, 24], "elegimo": 24, "elimin": 64, "elmo": 67, "embed": [64, 67], "encod": [33, 56, 61, 66], "engin": 40, "entiti": 67, "entrega": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "epoch": 35, "error": [23, 24], "especializaci\u00f3n": 5, "estructura": [12, 13, 14], "evaluacion": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "evaluaci\u00f3n": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "exampl": [29, 58, 61, 63, 68], "excercis": 67, "expect": 65, "experi": 35, "explan": 36, "explor": 48, "extract": [33, 44], "factor": 64, "facultad": [7, 12, 13, 14], "facutlad": [2, 3, 4, 6, 8, 9, 10, 11], "fashion": [25, 30], "featur": [22, 44, 61], "fecha": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "feed": 33, "filter": [48, 51], "find": 63, "fine": 44, "first": [48, 51], "fit": [33, 34], "folder": 20, "follow": [29, 36], "forma": 24, "formali": 61, "forward": 61, "freez": 51, "from": [23, 51, 52, 67], "frontera": 23, "function": [21, 25, 29, 30, 32, 37, 40, 41, 47, 52, 64], "fundamento": 0, "gate": 62, "gener": [20, 39, 54, 65], "get": [45, 54, 59], "github": [12, 13, 14], "gpu": [54, 63], "grader": 20, "gradient": [16, 24, 35, 39, 40], "graph": 41, "gru": 62, "grupo": [6, 7, 8, 9, 10, 11, 12, 13, 14], "handcraft": 26, "happen": 63, "have": 33, "here": 36, "hessian": 38, "hierarchi": 48, "highli": 22, "how": [39, 52, 56, 60, 67], "hub": [44, 50, 52], "hyperbol": 29, "i": [22, 29, 40, 47, 52, 57, 63, 65], "idf": 64, "imag": [33, 43, 47, 48, 52, 54], "implement": [38, 40, 43], "inceptionv3": 52, "includ": 41, "info": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "informaci\u00f3n": 1, "ingenier\u00eda": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "inicializaci\u00f3n": 16, "initi": 36, "input": [22, 27, 36, 41], "inspect": 33, "instead": [61, 67], "instruct": 20, "instrument": 28, "inteligencia": 15, "intermedi": 33, "intro": 54, "introducci\u00f3n": [18, 19], "introduct": [15, 33], "intuit": 55, "iterativo": 24, "just": 47, "kera": [30, 40, 41, 42, 52, 64], "know": 20, "l_1": 25, "l_2": 25, "la": [23, 24], "lab": [20, 21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 56, 57, 58, 59], "laboratorio": [15, 16, 17, 18, 19], "languag": 67, "larg": [22, 36], "larger": 48, "latent": 33, "layer": [28, 29, 33, 35, 38, 41, 51, 61, 67], "layout": 20, "leaki": 35, "learn": [0, 15, 22, 23, 24, 29, 39, 40, 44, 51, 64], "lest": 67, "let": [29, 48, 56, 57, 58, 59, 61, 63, 64, 67], "level": [38, 40, 48], "librari": [39, 40], "like": 56, "lineal": 23, "linear": [32, 35, 39, 40], "lo": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 23, 24, 70], "load": [25, 28, 35, 36], "logist": 29, "long": 62, "longer": 35, "look": 56, "loop": 40, "loss": [25, 29, 32, 33, 34, 37, 40, 52], "low": [38, 40], "lstm": [19, 62, 63, 69], "l\u00edmite": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "machin": [15, 23, 24, 39, 40, 66], "mai": [54, 63, 64], "mainli": 65, "make": [33, 54, 61], "map": 48, "mask": 57, "material": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "matric": 21, "matrix": [53, 64], "maximum": 52, "measur": [27, 34], "medida": 24, "memori": 62, "metric": 66, "minibatch": 29, "minimizan": 24, "ml": [23, 24, 39], "mlp": [29, 61], "mnist": [25, 28, 30, 35], "model": [19, 23, 25, 26, 27, 28, 30, 33, 34, 35, 36, 37, 40, 42, 44, 45, 52, 56, 57, 58, 59, 63, 64, 65, 67], "modelo": [15, 19, 23, 24], "monitor": 28, "more": [33, 48, 61, 65], "mse": 33, "mu": 36, "muestra": 23, "multi": [27, 28, 29, 35], "multidimensionalidad": 23, "multilay": 30, "multimod": 34, "multimodal": 16, "multipl": [47, 61], "must": 20, "naiv": 46, "name": 67, "necessari": 64, "negra": 24, "ner": 67, "network": [16, 18, 22, 29, 30, 34, 48, 51, 54, 61, 63, 66, 69], "neural": [16, 22, 29, 34, 48, 54, 61, 66], "neurona": 16, "neuronal": 19, "noisi": 33, "non": 52, "normal": [17, 36, 38, 42], "notebook": 20, "now": [22, 29, 61], "number": 43, "numpi": 39, "object": [45, 52], "objeto": 18, "observ": [33, 35, 51, 52], "observa": 23, "obtain": [38, 39], "obtenemo": 24, "oficial": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "one": [43, 61], "onli": 33, "onlin": 29, "oper": 21, "optim": [39, 40], "optimizaci\u00f3n": 24, "option": 66, "origin": 63, "other": 64, "otra": 24, "our": [51, 54], "out": 39, "output": [38, 61], "overfit": 31, "overview": 22, "pack": 40, "pad": 57, "pairwis": 27, "para": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "par\u00e1metro": 24, "patch": 52, "per": 27, "perceptron": [29, 30], "perform": [41, 54, 56, 63], "peso": 16, "point": 51, "polymorph": 41, "pool": 49, "posgrado": [3, 4, 6, 8, 10], "possibl": 63, "predicci\u00f3n": 24, "predict": [33, 45, 52, 54, 56, 61], "pregrado": [2, 7, 9, 11], "prepar": 43, "preposit": 64, "pretrain": 54, "prior": 52, "problem": [29, 40], "problema": 23, "procesamiento": 19, "proceso": 24, "process": [39, 64], "proyecto": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "publish": [20, 52], "purpos": 60, "python": [39, 41], "que": 24, "qu\u00e9": [17, 23], "random": 40, "raw": 40, "real": [33, 56, 66], "recal": 39, "recognit": 67, "recommend": 48, "reconstruct": 26, "rectifi": 35, "recurr": [61, 62, 63], "recurrent": 19, "rede": [16, 18, 19], "refer": [54, 60], "referencia": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "region": 52, "registro": [12, 13, 14], "regres": 40, "regress": [32, 39], "regular": [25, 31, 34, 63], "relu": 35, "remark": 20, "repositori": 20, "repositorio": [12, 13, 14], "represent": 64, "resnet": 52, "reson": 65, "result": [65, 67], "rightarrow": [33, 40], "rnn": [61, 62, 66], "run": 35, "runtim": 54, "same": 47, "sampl": [28, 32, 35, 65], "scenario": 33, "scratch": [51, 67], "se": 24, "see": [56, 67], "segment": [46, 54], "segmentaci\u00f3n": 18, "select": 54, "self": 68, "semant": 46, "sem\u00e1ntica": 18, "sentiment": [57, 68], "sequenc": [19, 61, 63, 65], "sequenti": [30, 32, 40], "seri": [56, 60, 61], "sesion": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "set": 42, "sever": 61, "sgd": 40, "shift": 42, "short": 62, "shot": 43, "shuffl": 40, "sigma": 36, "sigmoid": 35, "simb\u00f3lico": 17, "simpl": [36, 66, 67], "simplifi": 67, "sincr\u00f3nica": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14], "singl": 29, "skip": [46, 54], "small": 36, "softmax": 29, "solo": 23, "solv": 29, "some": [22, 54, 61, 64], "sort": 39, "space": 33, "span": 29, "spars": 26, "specif": 41, "speed": 40, "split": [60, 63], "stage": 52, "standard": [36, 40], "start": 51, "state": 63, "stem": 64, "step": [54, 61], "still": 39, "stochast": 40, "stop": 31, "student": 20, "style": 29, "subclass": 37, "sugerida": 1, "suit": 22, "summari": [26, 27, 28], "summit": 40, "suppress": 52, "symbol": [39, 40], "sympi": 39, "system": [39, 57], "tama\u00f1o": 23, "tangent": 29, "tanh": 35, "tarea": 24, "task": [21, 25, 26, 27, 28, 37, 38, 43, 44, 45, 46, 48, 56, 57, 58, 59, 64], "taxonom\u00eda": 23, "tenemo": 23, "tensor": [40, 41], "tensorboard": 35, "tensorflow": [17, 32, 38, 40, 44, 47, 50, 52], "term": 62, "test": [26, 54, 57, 58, 59], "text": 64, "texto": 19, "tf": [37, 40, 41, 64, 66], "them": 51, "thi": [29, 54, 57], "thing": 29, "three": [61, 65, 69], "through": 61, "ti": 41, "tiempo": 1, "time": [56, 60, 61], "tipo": 24, "tipolog\u00eda": 24, "toi": 29, "token": [64, 66], "tool": 60, "trabajando": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 70], "train": [29, 33, 36, 42, 51, 54, 56, 63], "train_step": 40, "transfer": [44, 51, 64], "transform": [19, 58, 68], "translat": 66, "transpos": 53, "truncat": 63, "try": 48, "tt": 20, "tune": 44, "tweet": 57, "two": [51, 61, 64], "type": [22, 41, 53], "u5": 62, "udea": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "un": [23, 24], "una": 24, "underli": 41, "understand": 35, "unet": [46, 54], "unit": [35, 62], "unsupervis": 33, "up": [21, 40, 42], "upsampl": 53, "upstream": 41, "us": [29, 30, 39, 40, 41, 51, 54, 61, 63, 64, 65, 66, 68], "usuario": 15, "v": 23, "valid": [54, 60], "valu": 36, "vanish": [16, 35], "variabl": 22, "version": [20, 40, 67], "video": 59, "visual": 35, "wai": 69, "walk": 61, "warm": 21, "we": [33, 39, 51, 65], "weight": [28, 33, 36, 43, 51, 54], "welcom": 70, "what": [20, 63, 65], "whatsapp": [6, 7, 8, 9, 10, 11, 12, 13, 14], "whole": 65, "why": 22, "wide": 64, "word": 64, "word2vec": [64, 66], "x": 33, "y": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "you": [20, 54]}})