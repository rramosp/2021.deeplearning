
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>05 - SEQUENCE MODELS &#8212; Fundamentos de Deep Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-43235448-3"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-43235448-3');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'UA-43235448-3');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/M05';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.0 Crossvalidation in time series" href="U5.00%20-%20Intro%20time%20series.html" />
    <link rel="prev" title="LAB 4.4 - Semantic segmentation" href="U4%20LAB%2004%20-%20Semantic%20segmentation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/fudea.jpg" class="logo__image only-light" alt="Fundamentos de Deep Learning - Home"/>
    <script>document.write(`<img src="../_static/fudea.jpg" class="logo__image only-dark" alt="Fundamentos de Deep Learning - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="M00_20252_pre.html">Info 2025.2 - UdeA</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="M01.html">01 - INTRODUCTION</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="U1.01%20-%20DL%20Overview.html">1.1 - DL Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="U1.02%20-%20Modelos%20derivados%20de%20los%20datos.html">1.2 - Models derived from data</a></li>
<li class="toctree-l2"><a class="reference internal" href="U1.03%20-%20Como%20se%20disena%20un%20algoritmo%20de%20Machine%20Learning.html">1.3 - ML algorithm design</a></li>
<li class="toctree-l2"><a class="reference internal" href="U1%20LAB%2001%20-%20WARMUP.html">LAB 01.01 - WARM UP</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="M02.html">02 - NEURAL NETWORKS</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="U2.01%20-%20The%20Perceptron.html">2.1 - The Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2.02%20-%20The%20Multilayer%20Perceptron.html">2.2 - The Multilayer Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2.03%20-%20Overfitting%20and%20regularization.html">2.3 - Overfitting and regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2.04%20-%20Loss%20functions.html">2.4 - Loss functions in Tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2.05%20-%20Network%20Architectures%20-%20Autoencoders.html">2.5 - Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2.06%20-%20Network%20Architectures%20-%20Multimodal%20information.html">2.6 - Multimodal architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2.07%20-%20Vanishing%20gradients.html">2.7 - Vanishing gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2.08%20-%20Weights%20initialization.html">2.8 - Weights initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2%20LAB%2001%20-%20Customized%20loss%20functions%20and%20regularization.html">LAB 2.1 - Customized loss function</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2%20LAB%2002%20-%20Autoencoders.html">LAB 2.2 - Sparse Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2%20LAB%2003%20-%20Pairwise%20image%20classification.html">LAB 2.3 - Pairwise classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="U2%20LAB%2004%20-%20Model%20instrumentation%20and%20monitoring.html">LAB 2.4 - Model instrumentation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="M03.html">03 - TENSORFLOW CORE</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="U3.01%20-%20Simbolic%20computing%20for%20ML.html">3.1 - Symbolic computing for ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="U3.02%20-%20TF%20for%20symbolic%20computing.html">3.2 - TF symbolic engine</a></li>
<li class="toctree-l2"><a class="reference internal" href="U3.03%20-%20Using%20tf.function.html">3.3 - Using <code class="docutils literal notranslate"><span class="pre">tf.function</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="U3.04%20-%20Batch%20Normalization.html">3.4 - Batch normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="U3%20LAB%2001%20-%20Tensorflow%20model%20subclassing.html">LAB 3.1 - TF model subclassing</a></li>
<li class="toctree-l2"><a class="reference internal" href="U3%20LAB%2002%20-%20Low%20level%20Tensorflow.html">LAB 3.2 - Low level <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="M04.html">04 - CONVOLUTIONAL NETWORKS</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="U4.01%20-%20Convolutions.html">4.1 - Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.02%20-%20Convolutional%20Neural%20Networks.html">4.2 - Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.03%20-%20Dropout%2C%20pooling.html">4.3 - Dropout, pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.04%20-%20CNN%20Architectures.html">4.4 - CNN Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.05%20-%20Transfer%20learning.html">4.5 - Transfer learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.06%20-%20Object%20Detection.html">4.6 - Object detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.07%20-%20Transposed%20convolutions.html">4.7 - Transposed convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.08%20-%20UNet%20image%20segmentation.html"><strong>4.8</strong> - UNet Image segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4.09%20-%20Atrous%20convolutions.html">4.9 - Atrous convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4%20LAB%2001%20-%20Convolutions.html">LAB 4.1 - Convolutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4%20LAB%2002%20-%20Transfer%20Learning.html">LAB 4.2 - Transfer learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4%20LAB%2003%20-%20Object%20Detection.html">LAB 4.3 - Object detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="U4%20LAB%2004%20-%20Semantic%20segmentation.html">LAB 4.4 - Semantic segmentation</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">05 - SEQUENCE MODELS</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="U5.00%20-%20Intro%20time%20series.html">5.0 Crossvalidation in time series</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.01%20-%20Recurrent%20Neural%20Networks.html">5.1 Recurrent Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.02%20-%20Long%20Short%20Term%20Memory%20RNN.html">5.2 LSTM and GRU</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.03%20-%20Truncated%20BPTT.html">5.3 Truncated BPTT</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.04%20-%20Basic%20concepts%20of%20text%20processing.html">5.4 Text processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.05%20-%20Sequences%20generation%20using%20LSTM.html">5.5 Sequences generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.06%20-%20Bidirectional%20RNNs%20-%20Attention%20Model.html">5.6 Bidirectional RNNs</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.07%20-%20ELMo%20-%20NER.html">5.7 ELMo</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.08%20-%20Self-Attention%20-%20Transformer%20-%20BERT.html">5.8 Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5.09%20-%20CNN-LSTM%20architectures.html">5.9  CNN-LSTM architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5%20LAB%2001%20-%20Multivariate%20time%20series%20prediction.html">LAB 5.1 - Time series prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5%20LAB%2002%20-%20Padding%2C%20Masking%20-%20Sentiment%20Analysis.html">LAB 5.2 - Padding - Masking</a></li>
<li class="toctree-l2"><a class="reference internal" href="U5%20LAB%2003%20-%20Sentiment%20Analysis%20using%20BERT.html">LAB 5.3 - Transformer - BERT</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/content/M05.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>05 - SEQUENCE MODELS</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduccion">Introducción</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-recurrentes">Redes Neuronales Recurrentes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitecturas-recurrentes">Arquitecturas recurrentes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio-1">LABORATORIO 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-de-texto">Procesamiento de texto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio-2">LABORATORIO 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-recurrentes-bidirecionales">Redes Neuronales Recurrentes Bidirecionales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-modelo-transformer">El modelo Transformer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio-3">LABORATORIO 3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitecturas-cnn-lstm">Arquitecturas CNN-LSTM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio">LABORATORIO</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sequence-models">
<h1>05 - SEQUENCE MODELS<a class="headerlink" href="#sequence-models" title="Link to this heading">#</a></h1>
<section id="introduccion">
<h2>Introducción<a class="headerlink" href="#introduccion" title="Link to this heading">#</a></h2>
<p><strong>01 - Validación cruzada en problemas de series de tiempo</strong>: <a class="reference external" href="https://youtu.be/w8xfaSksicQ">Video 11mins</a><br/> Describimos las particularidades del proceso de validación en problemas de series de tiempo, una de las aplicaciones del procesamiento de datos secuenciales.</p>
<p><strong>02 - Tareas de analítica de secuencias</strong>: <a class="reference external" href="https://youtu.be/xTxLaCqUbBk">Video 13mins</a><br/>Presentamos de manera general el principio de funcionamiento de una red recurrente, los tipos de aplicaciones que se presentan en el análisis de de secuencias y las configuraciones de redes más comunes.</p>
</section>
<section id="redes-neuronales-recurrentes">
<h2>Redes Neuronales Recurrentes<a class="headerlink" href="#redes-neuronales-recurrentes" title="Link to this heading">#</a></h2>
<p><strong>03 - Introducción a las Redes Neuronales Recurrentes</strong>: <a class="reference external" href="https://youtu.be/n5ropbj3lno">Video 13mins</a><br/>  Describimos los principios de funcionamiento de las RNN y la analizamos como una red densa de muchas capas.</p>
<p><strong>04 - Algoritmo de Backpropagation Through Time</strong>: <a class="reference external" href="https://youtu.be/UiUSgNIvev8">Video 11mins</a><br/>  Analizamos los principios de funcionamiento del algoritmo de entrenamiento de las RNN y sus implicaciones en términos de computacionales.</p>
<p><strong>05 - Implementación de RNN en TensorFlow</strong>: <a class="reference external" href="https://youtu.be/YLeoRmmYmq4">Video 17mins</a><br/> Usamos un problema de series de tiempo para implementar RNNs de una y dos capas ocultas en TensorFlow. Describimos los elementos básicos de una arquitectura Codificador-Decodificador.</p>
</section>
<section id="arquitecturas-recurrentes">
<h2>Arquitecturas recurrentes<a class="headerlink" href="#arquitecturas-recurrentes" title="Link to this heading">#</a></h2>
<p><strong>06 - Implementación de Arquitecturas de RNN para problemas seq-to-seq</strong>: <a class="reference external" href="https://youtu.be/jitQc7YusUA">Video 19mins</a><br/>  Usamos un problema de series de tiempo en el que se desean predecir varios tiempos hacia adelante, para describir e implementar tres metodologías/arquitecturas para la solución de problemas donde tanto la entrada como la salida son secuencias.</p>
<p><strong>07 - Long Short Term Memory RNN</strong>: <a class="reference external" href="https://youtu.be/jVei1bWFXMc">Video 22mins</a><br/> Presentamos los principios de funcionamiento de las redes recurrentes de tipo LSTM y GRM, así como su implementación en TensorFlow.</p>
<p><strong>08 - Truncated BPTT</strong>: <a class="reference external" href="https://youtu.be/oSVbUKl2nYQ">Video 24mins</a> <br/> Presentamos una variante del algoritmo de Propagación hacia atrás en el tiempo que permite realizar actualizaciones de los parámetros de la red, a partir de propagaciones parciales de una secuencia y cómo se puede realizar su implementación utilizando el framework de tensorflow.</p>
</section>
<section id="laboratorio-1">
<h2>LABORATORIO 1<a class="headerlink" href="#laboratorio-1" title="Link to this heading">#</a></h2>
<p><strong>LAB 1 - Multivariate Time-series prediction</strong>: <a class="reference external" href="https://youtu.be/oK4pDy7Q1MQ">Video 6mins</a> <br/>En este laboratorio debes diseñar diferentes arquitecturas de redes RNN para predecir un sólo tiempo hacia adelante y varios tiempos hacia adelante en un problema de series de tiempo multivariado.</p>
</section>
<section id="procesamiento-de-texto">
<h2>Procesamiento de texto<a class="headerlink" href="#procesamiento-de-texto" title="Link to this heading">#</a></h2>
<p><strong>09 - Introducción al procesamiento de texto</strong>: <a class="reference external" href="https://youtu.be/IwEPJQEX-lc">Video 17mins</a> <br/> Describimos las principales etapas de preprocesamiento necesarias para el uso de modelos de Machine Learning en tareas de procesamiento de lenguaje natural.</p>
<p><strong>10 - Word embeddings</strong>: <a class="reference external" href="https://youtu.be/lqXdZOq9U_0">Video 25mins</a> <br/> Peresentamos las razones que inspiraron la creación de técnicas de embebimiento de palabras y discutimos diversas variantes, sus principios de funcionamiento y la estrategia de transfer learning que permite usar word embeddings pre-entrenados dentro de modelos de Deep Learning en tensorflow.</p>
<p><strong>11 - Generación de secuencias usando RNNs</strong>: <a class="reference external" href="https://youtu.be/VSswvuwTz-g">Video 9mins</a> <br/> Describimos el procedimiento que puede ser empleado para generar secuencias artificiales a partir de redes neuronales recurrentes pre-entrenadas.</p>
</section>
<section id="laboratorio-2">
<h2>LABORATORIO 2<a class="headerlink" href="#laboratorio-2" title="Link to this heading">#</a></h2>
<p><strong>LAB 2 - Sentiment analysis in text</strong>: <a class="reference external" href="https://youtu.be/tUkhHJTvE-o">Video 10mins</a> <br/>En este laboratorio debes diseñar diferentes arquitecturas de DL y estrategias de transfer learning para clasificar tweets como positivos o negativos.</p>
</section>
<section id="redes-neuronales-recurrentes-bidirecionales">
<h2>Redes Neuronales Recurrentes Bidirecionales<a class="headerlink" href="#redes-neuronales-recurrentes-bidirecionales" title="Link to this heading">#</a></h2>
<p><strong>12 - Redes RNN Bidirecionales</strong>: <a class="reference external" href="https://youtu.be/GneNfVlNq8E">Video 16mins</a> <br/> Presentamos las limitaciones que tienen las redes neuronales recurrentes para procesar secuencias en las que la predicción para una posición de la secuencia, depende no sólo de las observaciones anteriores de la secuencia sino también de observaciones futuras y cómo las redes neuronales bidireccionales resuelven ese problema.</p>
<p><strong>13 - Arquitectura Encoder-Decoder con mecanismo de atención</strong>: <a class="reference external" href="https://youtu.be/XsgF5bFWcew">Video 17mins</a> <br/> Describimos una arquitectura particular de red recurrente de tipo codificador-decodificador, en la que se dota a la capa del decodificador de la cpacidad para seleccionar qué información de la secuencia de entrada es relevante para realizar cada una de las predicciones en la secuencia de salida.</p>
<p><strong>14 - ELMo: Embeddings from Language Models</strong>: <a class="reference external" href="https://youtu.be/GC9zr2wPtZo">Video 23mins</a> <br/> Describimos una arquitectura de red conocida como ELMo que permite obtener vectores de embebimiento a partir de un procesamiento de secuencias a nivel de caracter, esto permite que el vector que representa a una palabra pueda depender del contexto y no sea siempre estático.</p>
</section>
<section id="el-modelo-transformer">
<h2>El modelo Transformer<a class="headerlink" href="#el-modelo-transformer" title="Link to this heading">#</a></h2>
<p><strong>15 - Mecanismo de auto-atención</strong>: <a class="reference external" href="https://youtu.be/p727fQCrw9c">Video 24mins</a> <br/> Describimos el modelo conocido como Transformer y su principal principio de funcionamiento: el mecanismo de auto-atención.</p>
<p><strong>16 - Modelo BERT</strong>: <a class="reference external" href="https://youtu.be/XTtcdIXskvY">Video 5mins</a> <br/> Describimos el modelo BERT (Bidirectional Encoder Representations from Transformers) muy usado como modelo base para diferentes aplicaciones de NLP entre otras.</p>
</section>
<section id="laboratorio-3">
<h2>LABORATORIO 3<a class="headerlink" href="#laboratorio-3" title="Link to this heading">#</a></h2>
<p><strong>LAB 3 - Sentiment analysis with a Self-Attention Layer</strong>: <a class="reference external" href="https://youtu.be/gvgjpkCAJcs">Video 15mins</a> <br/>En este laboratorio debes diseñar diferentes arquitecturas de DL basadas en el modelo de Transformer para clasificar tweets como positivos o negativos.</p>
</section>
<section id="arquitecturas-cnn-lstm">
<h2>Arquitecturas CNN-LSTM<a class="headerlink" href="#arquitecturas-cnn-lstm" title="Link to this heading">#</a></h2>
<p><strong>17 - Arquitecturas CNN-LSTM y ConvLSTM</strong>: <a class="reference external" href="https://youtu.be/deVW91RR_lQ">Video 22mins</a> <br/> Presentamos las arquitecturas de redes neuronales profundas que pueden ser usadas para procesar secuencias de matrices u objetos 3D. Este tipo de arquitecturas permiten resolver tareas de ML sobre videos.</p>
</section>
<section id="laboratorio">
<h2>LABORATORIO<a class="headerlink" href="#laboratorio" title="Link to this heading">#</a></h2>
<p><strong>NON-REQUIRED LAB</strong></p>
<p><strong>LAB 4 - Video classification</strong>: <br/>En este laboratorio debes diseñar arquitecturas de DL para clasificar videos de acuerdo con la acción que las personas están realizando en ellos. Este laboratorio no puede ser ejecutado en el colab, ya que la memorúa RAM disponible no es suficiente para cargar la BD que consiste de dos clases, cada una de 24 videos de 30 frames cada uno. Para quienes quieran desarrollar el ejercicio de construir una arquitectura para clasificación de videos con base en una arquitectura CNN pre-entrenada, el notebook puede ser consultado dentro del respositorio en el siguiente <a class="reference external" href="https://github.com/rramosp/2021.deeplearning/blob/main/content/U5%20LAB%2004%20-%20Video%20Classification.ipynb">enlace</a> y debe ser ejecutado en local para lo cual deben tener instalada toda la suite necesaria de librerías y paquetes.</p>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="U4%20LAB%2004%20-%20Semantic%20segmentation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">LAB 4.4 - Semantic segmentation</p>
      </div>
    </a>
    <a class="right-next"
       href="U5.00%20-%20Intro%20time%20series.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">5.0 Crossvalidation in time series</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduccion">Introducción</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-recurrentes">Redes Neuronales Recurrentes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitecturas-recurrentes">Arquitecturas recurrentes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio-1">LABORATORIO 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#procesamiento-de-texto">Procesamiento de texto</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio-2">LABORATORIO 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#redes-neuronales-recurrentes-bidirecionales">Redes Neuronales Recurrentes Bidirecionales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-modelo-transformer">El modelo Transformer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio-3">LABORATORIO 3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arquitecturas-cnn-lstm">Arquitecturas CNN-LSTM</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laboratorio">LABORATORIO</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Raúl Ramos, Julián Arias / Universidad de Antioquia
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>